{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librosa is our low-level audio processor\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "helpful-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import soundfile as sf # python's audio processor\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chicken-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPM and Key information of the tracks\n",
    "track_dict = {'Billy Kenny & Huxley - Sweat': {'BPM': 125, 'Key': 'F major'},\n",
    "              \"Camelphat - Drop it (Mason Maynard Remix)\": {'BPM': 125, 'Key': 'F# major'},\n",
    "              'ANOTR - Help (Extended Mix)': {'BPM': 124, 'Key': 'F# major'},\n",
    "              'Benihana – Quiero (Original Mix)': {'BPM': 125, 'Key': 'A# major'},\n",
    "              'Dennis Cruz - El Sueño (feat Martina Camargo)': {'BPM': 124, 'Key': 'B minor'},\n",
    "              'Dopamine Machine - Club Mix': {'BPM': 124, 'Key': 'D# minor'}\n",
    "}\n",
    "\n",
    "track_list = list(track_dict.keys())\n",
    "\n",
    "# extracted chorus start times (erroneous)\n",
    "chorus_secs = [257.91957462503075, 316.3291764290701, 324.42883654218963, 194.15972058622108, 345.998458556607, 215.5939096330522]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "injured-freeze",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\oguza\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "source": [
    "i = 0 # index of each track\n",
    "\n",
    "track_name = track_list[i]\n",
    "chorus_start_sec = chorus_secs[i]\n",
    "\n",
    "N_bars = 16 # chorus length in bars\n",
    "\n",
    "BPM = track_dict[track_name]['BPM']\n",
    "key, typ = track_dict[track_name]['Key'].split(' ')\n",
    "#scale = scales[key][typ]\n",
    "\n",
    "\n",
    "# buraları istersen konuşuruz basit aritmetik\n",
    "beat_length = 60 / BPM\n",
    "bar_length = 4 * beat_length \n",
    "chorus_length = N_bars * bar_length # sec\n",
    "\n",
    "input_path = os.path.join(\"data\",\"audio_clips\",track_name+\".mp3\")\n",
    "\n",
    "fs = 44100\n",
    "track, sr = librosa.load(input_path, sr=fs) # load the track\n",
    "\n",
    "#Beat Tracking\n",
    "beat_proc = RNNBeatProcessor()\n",
    "tracking_proc = BeatTrackingProcessor(fps=100)\n",
    "\n",
    "activations = beat_proc(input_path)\n",
    "beat_positions = tracking_proc(activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-december",
   "metadata": {},
   "source": [
    "**Align the chorus with the external beatgrid**\n",
    "\n",
    "**Deal with pirated adio later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "opening-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_grid_to_bar(chorus_start_sec, beat_positions, beat_length):\n",
    "    \"\"\"\n",
    "    Aligns the chorus to the nearest bar assuming the track contains only 4 beat long sections.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "            \n",
    "            chorus_start_sec (float): start second of the chorus given by pychorus\n",
    "            beat_positions (array, float): array of beat positions in seconds\n",
    "            beat_length (float): length of a beat in seconds\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        \n",
    "           idx (int): index of the nearest bar in the track\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the closest beats\n",
    "    indices = np.where(np.abs(chorus_start_sec-beat_positions)<beat_length)[0]\n",
    "    \n",
    "    if len(indices) > 2:\n",
    "        print(\"Too many beats returned!\")\n",
    "        \n",
    "    # Choose the even beat\n",
    "    if not indices[0]   % 2:\n",
    "        idx = indices[0]\n",
    "    elif not indices[1]  % 2:\n",
    "        idx = indices[1]\n",
    "        \n",
    "    # if the even idx is not a multiple of 4, make it, by moving to the next bar beginning    \n",
    "    if idx % 4:\n",
    "        idx += 2\n",
    "     \n",
    "    return idx\n",
    "\n",
    "def get_aligned_chorus_beats(bar_idx, N_bars, beat_positions):\n",
    "    \"\"\"\n",
    "    Gets N_bars worth of beats from the aligned chorus.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "        bar_idx (int): idx of the start beat in the beat grid for the chorus\n",
    "        N_bars (int): number of bars to return \n",
    "        beat_positions (array, float): array of beat positions in seconds\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        \n",
    "        chorus_beat_positions (array): array of beat positions in time (seconds)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    chorus_beat_positions = beat_positions[bar_idx:bar_idx+N_bars*4+1]\n",
    "    \n",
    "    return chorus_beat_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_idx = align_grid_to_bar(chorus_start_sec, beat_positions, beat_length)\n",
    "\n",
    "chorus_beat_positions = get_aligned_chorus_beats(bar_idx, N_bars, beat_positions)\n",
    "\n",
    "# find bar beginnings for plotting\n",
    "bar_times = [val for idx,val in enumerate(chorus_beat_positions) if not idx%4] \n",
    "\n",
    "# convert time boundaries to indices and align the chorus\n",
    "chorus_aligned = track[int(chorus_beat_positions[0]*fs):int(chorus_beat_positions[-1]*fs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-jaguar",
   "metadata": {},
   "source": [
    "**Plot the Aligned Chorus Spectrogram and Waveform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the spectrogram\n",
    "n_fft = 4096*8\n",
    "win_length = 4096*2\n",
    "hop_length = int(win_length/2) \n",
    "\n",
    "amplitude_spectrogram = np.abs(librosa.stft(chorus_aligned, n_fft=n_fft, win_length=win_length, hop_length=hop_length))\n",
    "\n",
    "dB_spectrogram = librosa.amplitude_to_db(amplitude_spectrogram, np.max(amplitude_spectrogram))\n",
    "\n",
    "#power_spectrogram = librosa.db_to_power(dB_spectrogram, ref=1.0)\n",
    "\n",
    "# plot the waveform and the spectrogram\n",
    "fig, ax = plt.subplots(figsize=(20,10), nrows=2, sharex=False)\n",
    "\n",
    "img = librosa.display.specshow(dB_spectrogram, sr=fs, hop_length=hop_length, x_axis='time', y_axis='log', ax=ax[0])\n",
    "ax[0].vlines(chorus_beat_positions-chorus_beat_positions[0], 0, 8192, alpha=0.8, color='w',linestyle='-')\n",
    "ax[0].vlines(bar_times-bar_times[0], 0, 16384, alpha=0.8, color='g',linestyle='-')\n",
    "ax[0].set_xlim([-0.2, chorus_length+0.2])\n",
    "ax[0].xaxis.set_ticks(np.arange(0, chorus_length+0.2, 1))\n",
    "\n",
    "librosa.display.waveplot(chorus_aligned, sr=fs, ax=ax[1])\n",
    "ax[1].vlines(chorus_beat_positions-chorus_beat_positions[0], -0.9, 0.9, alpha=0.8, color='r',linestyle='-')\n",
    "ax[1].vlines(bar_times-bar_times[0], -1.1, 1.1, alpha=0.8, color='g',linestyle='-')\n",
    "ax[1].set_xlim([-0.2, chorus_length+0.2])\n",
    "ax[1].xaxis.set_ticks(np.arange(0, chorus_length+0.2, 1))\n",
    "\n",
    "plt.savefig('{}_waveform_spectrogram.png'.format(track_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-insertion",
   "metadata": {},
   "source": [
    "# END OF CHORUS ALIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-brazilian",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "\n",
    "librosa.display.waveplot(chorus_aligned, sr=fs, ax=ax)\n",
    "ax.vlines(chorus_beats_time-chorus_beats_time[0], -1, 1, alpha=0.8, color='w',linestyle='-')\n",
    "ax.vlines(bar_times-bar_times[0], -1, 1, alpha=0.8, color='g',linestyle='-')\n",
    "ax.set_xlim([-0.2, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-campbell",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "img = librosa.display.specshow(dB_spectrogram, sr=fs, hop_length=hop_length, x_axis='time', y_axis='log', ax=ax)\n",
    "#fig.colorbar(img, ax=ax[0], format=\"%+2.f dB\")\n",
    "ax.vlines(chorus_beats_time-chorus_beats_time[0], 0, 16384, alpha=0.8, color='w',linestyle='-')\n",
    "ax.vlines(bar_times-bar_times[0], 0, 16384, alpha=0.8, color='g',linestyle='-')\n",
    "ax.set_xlim([-0.2, 32])\n",
    "#plt.savefig('Spec-Beats.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-gross",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8), nrows=2, sharex=True)\n",
    "img = librosa.display.specshow(dB_spectrogram, sr=fs, hop_length=hop_length, x_axis='time', y_axis='log', ax=ax[0])\n",
    "#fig.colorbar(img, ax=ax[0], format=\"%+2.f dB\")\n",
    "ax[1].vlines(beats_time, 0, 1, alpha=0.5, color='b',linestyle='--', label='Beats')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-jumping",
   "metadata": {},
   "source": [
    "**Separate to Stems**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = Separator('spleeter:4stems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "chorus_forced = np.expand_dims(chorus_forced,1) # required\n",
    "prediction = separator.separate(chorus_forced, audio_descriptor='') # WHAT IS AUDIO DESCRIPTOR??????\n",
    "\n",
    "bassline = prediction['bass']\n",
    "bassline_mono = np.mean(bassline,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out audio as 24bit PCM WAW\n",
    "output_name += \"_bassline\"\n",
    "output_path = os.path.join(output_dir, output_name+\".wav\")\n",
    "\n",
    "sf.write(output_path, bassline, sr, subtype='PCM_24')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-employee",
   "metadata": {},
   "source": [
    "**Cut High Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = max(scale['frequencies']['2']) # adaptive cutoff Hz\n",
    "\n",
    "print(\"Highest frequency in Bass Frequency Region: {} Hz\".format(fc))\n",
    "\n",
    "wc = fc / (fs/2) # cutoff radians\n",
    "\n",
    "lp = signal.firwin(5000, wc)\n",
    "\n",
    "bassline_cut = signal.convolve(bassline_mono, lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out audio as 24bit PCM WAV\n",
    "output_name += \"_LP\"\n",
    "output_path = os.path.join(output_dir, output_name+\".wav\")\n",
    "\n",
    "sf.write(output_path, bassline_cut, sr, subtype='PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 4096*8\n",
    "win_length = 4096*2\n",
    "hop_length = int(win_length/2) \n",
    "\n",
    "\n",
    "amplitude_spectrogram = np.abs(librosa.stft(bassline_cut, n_fft=n_fft, win_length=win_length, hop_length=hop_length))\n",
    "\n",
    "dB_spectrogram = librosa.amplitude_to_db(amplitude_spectrogram, np.max(amplitude_spectrogram))\n",
    "\n",
    "power_spectrogram = librosa.db_to_power(dB_spectrogram, ref=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-shooting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "img = librosa.display.specshow(dB_spectrogram, sr=fs, hop_length=hop_length, x_axis='time', y_axis='log', ax=ax)\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
