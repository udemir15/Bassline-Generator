{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data import get_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from nn_plotting import plot_loss_history\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils import save_nn_output_to_midi, now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_songs, X_train, test_songs, X_test, y_train, y_test, vocab_size = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = X_train.shape[0]\n",
    "num_test = X_test.shape[0]\n",
    "timesteps = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-3\n",
    "epochs = 1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a02d648e5e2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRNNAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoder_hidden_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdecoder_hidden_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "from models.ae.autoencoders import RNNAE\n",
    "\n",
    "encoder_hidden_units = 256\n",
    "decoder_hidden_units = 256\n",
    "\n",
    "rnn_ae = RNNAE(encoder_hidden_units, decoder_hidden_units, timesteps, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RNNEncoderRNNDecoder'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_ae.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"{rnn_ae.encoder.name}_{rnn_ae.decoder.name}\"\n",
    "\n",
    "\n",
    "mc = ModelCheckpoint(f'Models/{name}.hdf5', monitor='val_loss')\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "rnn_ae.compile(optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LSTM_Encoder_LSTM_Decoder'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 9s 24ms/step - loss: 2.2234 - val_loss: 1.9494\n"
     ]
    }
   ],
   "source": [
    "hist = rnn_ae.fit(X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GMM to distribution of encoding.\n",
      "(256,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_ae.sample(10, X_train, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNNEncoderRNNDecoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_Encoder (RNNEncoder)    multiple                  297152    \n",
      "_________________________________________________________________\n",
      "LSTM_Decoder (RNNDecoder)    multiple                  535078    \n",
      "=================================================================\n",
      "Total params: 832,230\n",
      "Trainable params: 832,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.autoencoders import RNNEncoderCNNDecoder\n",
    "\n",
    "encoder_hidden_units = (512, 256, 128)\n",
    "decoder_filter_sizes = (64, 32)\n",
    "\n",
    "rnne_cnnd = RNNEncoderCNNDecoder(encoder_hidden_units, decoder_filter_sizes, timesteps=timesteps, vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"{rnne_cnnd.encoder.name}_{rnne_cnnd.decoder.name}\"\n",
    "learning_rate = 5e-3\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "mc = ModelCheckpoint(f'Models/{name}.hdf5', monitor='val_loss')\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "rnne_cnnd.compile(optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/97 [==============================] - 7s 34ms/step - loss: 3.3571 - val_loss: 2.0136\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9917 - val_loss: 1.9437\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9618 - val_loss: 1.9418\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9720 - val_loss: 1.9408\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9618 - val_loss: 1.9425\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9783 - val_loss: 1.9398\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9563 - val_loss: 1.9405\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9717 - val_loss: 1.9384\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9609 - val_loss: 1.9347\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9577 - val_loss: 1.9290\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9446 - val_loss: 1.9224\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 2s 26ms/step - loss: 1.9475 - val_loss: 1.9202\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 2s 26ms/step - loss: 1.9394 - val_loss: 1.9227\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9433 - val_loss: 1.9185\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9581 - val_loss: 1.9187\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 1.9329 - val_loss: 1.9182\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 4s 37ms/step - loss: 1.9416 - val_loss: 1.9190\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 3s 29ms/step - loss: 1.9368 - val_loss: 1.9185\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 3s 27ms/step - loss: 1.9528 - val_loss: 1.9183\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 3s 27ms/step - loss: 1.9337 - val_loss: 1.9175\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 3s 28ms/step - loss: 1.9404 - val_loss: 1.9199\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 3s 26ms/step - loss: 1.9352 - val_loss: 1.9194\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 2s 26ms/step - loss: 1.9439 - val_loss: 1.9181\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 3s 26ms/step - loss: 1.9487 - val_loss: 1.9195\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9444 - val_loss: 1.9171\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9410 - val_loss: 1.9188\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9306 - val_loss: 1.9241\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9407 - val_loss: 1.9201\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 2s 26ms/step - loss: 1.9364 - val_loss: 1.9176\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9495 - val_loss: 1.9166\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9403 - val_loss: 1.9197\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9318 - val_loss: 1.9193\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9421 - val_loss: 1.9169\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9292 - val_loss: 1.9175\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9383 - val_loss: 1.9172\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9438 - val_loss: 1.9171\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9205 - val_loss: 1.9167\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9337 - val_loss: 1.9164\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9418 - val_loss: 1.9175\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9356 - val_loss: 1.9157\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 2s 26ms/step - loss: 1.9344 - val_loss: 1.9159\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9278 - val_loss: 1.9158\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9228 - val_loss: 1.9175\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9404 - val_loss: 1.9164\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9400 - val_loss: 1.9179\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9445 - val_loss: 1.9166\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9434 - val_loss: 1.9170\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9525 - val_loss: 1.9151\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9391 - val_loss: 1.9169\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 1.9321 - val_loss: 1.9183\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9422 - val_loss: 1.9180\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9229 - val_loss: 1.9173\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9299 - val_loss: 1.9173\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9328 - val_loss: 1.9164\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9466 - val_loss: 1.9182\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - 3s 26ms/step - loss: 1.9463 - val_loss: 1.9158\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9394 - val_loss: 1.9160\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 1.9416 - val_loss: 1.9156\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9423 - val_loss: 1.9171\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - 3s 26ms/step - loss: 1.9449 - val_loss: 1.9170\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - 2s 26ms/step - loss: 1.9228 - val_loss: 1.9160\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9412 - val_loss: 1.9152\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9311 - val_loss: 1.9152\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9454 - val_loss: 1.9152\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9417 - val_loss: 1.9157\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - 2s 26ms/step - loss: 1.9416 - val_loss: 1.9151\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9463 - val_loss: 1.9179\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - 2s 26ms/step - loss: 1.9413 - val_loss: 1.9161\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - 2s 26ms/step - loss: 1.9423 - val_loss: 1.9166\n",
      "Epoch 70/100\n",
      "97/97 [==============================] - 3s 27ms/step - loss: 1.9276 - val_loss: 1.9175\n",
      "Epoch 71/100\n",
      "97/97 [==============================] - 3s 26ms/step - loss: 1.9452 - val_loss: 1.9160\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9298 - val_loss: 1.9163\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9390 - val_loss: 1.9144\n",
      "Epoch 74/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9423 - val_loss: 1.9157\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9513 - val_loss: 1.9148\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9340 - val_loss: 1.9158\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 1.9350 - val_loss: 1.9152\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 1.9384 - val_loss: 1.9148\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9387 - val_loss: 1.9153\n",
      "Epoch 80/100\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 1.9536 - val_loss: 1.9140\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 1.9255 - val_loss: 1.9150\n",
      "Epoch 82/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9316 - val_loss: 1.9150\n",
      "Epoch 83/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9432 - val_loss: 1.9143\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9216 - val_loss: 1.9164\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.9443 - val_loss: 1.9140\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - 3s 27ms/step - loss: 1.9367 - val_loss: 1.9147\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - 3s 26ms/step - loss: 1.9381 - val_loss: 1.9147\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - 3s 27ms/step - loss: 1.9351 - val_loss: 1.9154\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9436 - val_loss: 1.9151\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - 3s 26ms/step - loss: 1.9406 - val_loss: 1.9146\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9383 - val_loss: 1.9164\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9523 - val_loss: 1.9163\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - 3s 26ms/step - loss: 1.9466 - val_loss: 1.9152\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9432 - val_loss: 1.9150\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9482 - val_loss: 1.9150\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9385 - val_loss: 1.9144\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9355 - val_loss: 1.9136\n",
      "Epoch 98/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9427 - val_loss: 1.9159\n",
      "Epoch 99/100\n",
      "97/97 [==============================] - 2s 25ms/step - loss: 1.9313 - val_loss: 1.9139\n",
      "Epoch 100/100\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.9340 - val_loss: 1.9144\n"
     ]
    }
   ],
   "source": [
    "hist = rnne_cnnd.fit(X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GMM to distribution of encoding.\n",
      "(128,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [ 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [ 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [ 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [ 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [ 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [ 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [ 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [ 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [ 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnne_cnnd.sample(10, X_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.autoencoders import CNNAE\n",
    "\n",
    "encoder_filter_sizes = (16, 8)\n",
    "decoder_filter_sizes = (8, 16)\n",
    "\n",
    "cnn_ae = CNNAE(encoder_filter_sizes, decoder_filter_sizes, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"{cnn_ae.encoder.name}_{cnn_ae.decoder.name}\"\n",
    "learning_rate = 5e-3\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "\n",
    "mc = ModelCheckpoint(f'Models/{name}.hdf5', monitor='val_loss')\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "cnn_ae.compile(optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 3s 13ms/step - loss: 2.9897 - val_loss: 1.7859\n"
     ]
    }
   ],
   "source": [
    "hist = cnn_ae.fit(X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GMM to distribution of encoding.\n",
      "(16, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37],\n",
       "       [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_ae.sample(10, X_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.autoencoders import CNNEncoderRNNDecoder\n",
    "\n",
    "encoder_filter_sizes = (16, 8)\n",
    "decoder_hidden_units = 256\n",
    "\n",
    "cnne_rnnd = CNNEncoderRNNDecoder(encoder_filter_sizes, decoder_hidden_units, timesteps, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"{cnne_rnnd.encoder.name}_{cnne_rnnd.decoder.name}\"\n",
    "learning_rate = 5e-3\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "\n",
    "mc = ModelCheckpoint(f'Models/{name}.hdf5', monitor='val_loss')\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "cnne_rnnd.compile(optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 64, 38) and (None, 16, 38) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c5d023e488d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 callbacks=[mc])\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /kuacc/users/udemir15/.local/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 64, 38) and (None, 16, 38) are incompatible\n"
     ]
    }
   ],
   "source": [
    "hist = cnne_rnnd.fit(X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_models.vae.variationalautoencoders import DenseVAE\n",
    "\n",
    "encoder_intermediate_dims = (256, 128, 64)\n",
    "latent_dim = 64\n",
    "decoder_intermediate_dims = encoder_intermediate_dims[::-1]\n",
    "\n",
    "dense_vae = DenseVAE(encoder_intermediate_dims, latent_dim, decoder_intermediate_dims, vocab_size, embed_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"{dense_vae.encoder.name}_{dense_vae.decoder.name}_{now()}\"\n",
    "learning_rate = 5e-3\n",
    "epochs = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_weights = f'keras_weights/{now()}_{name}.h5'\n",
    "mc = ModelCheckpoint(saved_weights, monitor='val_loss', save_weights_only=True)\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_vae.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "111/111 [==============================] - 3s 10ms/step - loss: 150.1580 - reconstruction_loss: 131.5843 - kl_loss: 0.8647 - val_loss: 108.5947 - val_reconstruction_loss: 107.1730 - val_kl_loss: 1.4217\n",
      "Epoch 2/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 98.0396 - reconstruction_loss: 87.2038 - kl_loss: 2.7023 - val_loss: 74.4175 - val_reconstruction_loss: 70.1364 - val_kl_loss: 4.2811\n",
      "Epoch 3/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 70.4630 - reconstruction_loss: 63.4064 - kl_loss: 4.9111 - val_loss: 64.6572 - val_reconstruction_loss: 59.0052 - val_kl_loss: 5.6520\n",
      "Epoch 4/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 60.1516 - reconstruction_loss: 53.1808 - kl_loss: 5.8828 - val_loss: 57.3505 - val_reconstruction_loss: 50.7366 - val_kl_loss: 6.6138\n",
      "Epoch 5/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 53.8709 - reconstruction_loss: 46.9041 - kl_loss: 6.4619 - val_loss: 54.0563 - val_reconstruction_loss: 47.5818 - val_kl_loss: 6.4745\n",
      "Epoch 6/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 49.2657 - reconstruction_loss: 42.3826 - kl_loss: 6.8328 - val_loss: 52.3679 - val_reconstruction_loss: 45.4345 - val_kl_loss: 6.9333\n",
      "Epoch 7/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 45.8190 - reconstruction_loss: 38.7943 - kl_loss: 6.9884 - val_loss: 50.3685 - val_reconstruction_loss: 43.4807 - val_kl_loss: 6.8877\n",
      "Epoch 8/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 42.4048 - reconstruction_loss: 35.2471 - kl_loss: 7.2308 - val_loss: 49.8940 - val_reconstruction_loss: 42.3207 - val_kl_loss: 7.5733\n",
      "Epoch 9/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 40.1896 - reconstruction_loss: 32.4512 - kl_loss: 7.4850 - val_loss: 48.3495 - val_reconstruction_loss: 41.2406 - val_kl_loss: 7.1089\n",
      "Epoch 10/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 37.0929 - reconstruction_loss: 30.1469 - kl_loss: 7.6890 - val_loss: 49.7750 - val_reconstruction_loss: 42.4048 - val_kl_loss: 7.3703\n",
      "Epoch 11/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 34.8632 - reconstruction_loss: 27.7592 - kl_loss: 7.7122 - val_loss: 50.9853 - val_reconstruction_loss: 43.5055 - val_kl_loss: 7.4799\n",
      "Epoch 12/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 33.4634 - reconstruction_loss: 26.2160 - kl_loss: 7.8757 - val_loss: 51.6055 - val_reconstruction_loss: 43.7141 - val_kl_loss: 7.8913\n",
      "Epoch 13/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 31.6269 - reconstruction_loss: 24.5630 - kl_loss: 7.9463 - val_loss: 52.1346 - val_reconstruction_loss: 43.8556 - val_kl_loss: 8.2790\n",
      "Epoch 14/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 29.9610 - reconstruction_loss: 22.7882 - kl_loss: 8.0303 - val_loss: 54.6919 - val_reconstruction_loss: 47.0042 - val_kl_loss: 7.6877\n",
      "Epoch 15/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 29.2202 - reconstruction_loss: 21.4873 - kl_loss: 8.1056 - val_loss: 55.4241 - val_reconstruction_loss: 47.3083 - val_kl_loss: 8.1158\n",
      "Epoch 16/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 28.0082 - reconstruction_loss: 20.3019 - kl_loss: 8.2118 - val_loss: 55.1876 - val_reconstruction_loss: 47.3789 - val_kl_loss: 7.8087\n",
      "Epoch 17/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 26.3100 - reconstruction_loss: 19.0096 - kl_loss: 8.1796 - val_loss: 58.9008 - val_reconstruction_loss: 50.7555 - val_kl_loss: 8.1453\n",
      "Epoch 18/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 25.4109 - reconstruction_loss: 17.9021 - kl_loss: 8.2875 - val_loss: 58.4275 - val_reconstruction_loss: 50.7033 - val_kl_loss: 7.7243\n",
      "Epoch 19/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 24.5922 - reconstruction_loss: 17.1895 - kl_loss: 8.2832 - val_loss: 61.1321 - val_reconstruction_loss: 53.0583 - val_kl_loss: 8.0738\n"
     ]
    }
   ],
   "source": [
    "hist = dense_vae.fit(X_train, X_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[mc, es]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DenseVAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "DenseEncoder (DenseEncoder)  multiple                  574848    \n",
      "_________________________________________________________________\n",
      "DenseDecoder (DenseDecoder)  multiple                  314266    \n",
      "=================================================================\n",
      "Total params: 889,120\n",
      "Trainable params: 889,114\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dense_vae(X_train[:4,:]).numpy().argmax(-1) != X_train[:4,:]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 25, 25, 25, 17, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  2, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 14, 25, 25, 25, 25],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 17,\n",
       "        25, 25, 25, 25, 25, 25, 25,  2, 25, 17, 25, 25, 25, 25, 25,  2,\n",
       "        25, 25, 25, 25, 25, 25,  0, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 17, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  0, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25,  0, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 17, 25, 25],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 17, 25, 25, 25, 25, 25, 25,\n",
       "         0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25,  0, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25,  0, 25, 25, 25, 25, 25, 25, 25, 17, 25, 25],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25,  4, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 13, 25,  4, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 15, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         0, 25, 25, 25, 25, 25,  2, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25,  2, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "       [ 0, 25, 25, 25, 17, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        17, 25, 25, 25, 25, 25, 25, 25, 25,  0, 25, 25, 25, 25, 25, 25,\n",
       "         0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 14, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 17, 25, 25, 25,\n",
       "        25, 25, 17, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 17, 25, 25, 25]])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = dense_vae.sample(10)\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_nn_output_to_midi(samples, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_vae.load_weights(f'/kuacc/users/udemir15/Bassline-Generator/generator/keras_weights/{name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = dense_vae.sample(1).reshape(-1)\n",
    "\n",
    "comparison = np.array([accuracy_score(x, s) for x in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4375"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_beat_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-ff724cad4798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_beat_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSUS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_beat_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "print_beat_matrix(s, 8, SIL=0, SUS=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIL: 0, SUS: 25\n",
      "\n",
      "       Beat 0           Beat 1       \n",
      "Bar 0: [ 0 25 25  9]   [25  9 25  8]\n",
      "Bar 1: [0 9 8 0]   [25  9 25  9]\n",
      "Bar 2: [25  9  9  9]   [21 25  0 21]\n",
      "Bar 3: [25  9  9  9]   [9 9 8 9]\n",
      "\n",
      "       Beat 2           Beat 3       \n",
      "Bar 0: [ 0 10  0  9]   [25  9 25  9]\n",
      "Bar 1: [ 9  9 17  7]   [25 10  0  9]\n",
      "Bar 2: [ 9 11  0  9]   [25 17 11 12]\n",
      "Bar 3: [9 8 9 8]   [25  8  0 12]\n"
     ]
    }
   ],
   "source": [
    "print_transposed_beat_matrix(s, 8, SIL=0, SUS=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856962316176471"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(X_train.reshape(-1), dense_vae(X_train).numpy().argmax(-1).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_models.vae.variationalautoencoders import RNNVAE\n",
    "\n",
    "encoder_hidden_units = (256, 128)\n",
    "last_dense_dim = 64\n",
    "latent_dim = 64\n",
    "decoder_hidden_units = encoder_hidden_units[::-1]\n",
    "\n",
    "rnn_vae = RNNVAE(encoder_hidden_units, last_dense_dim, latent_dim, decoder_hidden_units, timesteps, vocab_size, embed_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"{rnn_vae.encoder.name}_{rnn_vae.decoder.name}_{now()}\"\n",
    "learning_rate = 5e-3\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "mc = ModelCheckpoint(f'keras_weights/{name}.h5', monitor='val_loss')\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_vae.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "111/111 [==============================] - 9s 33ms/step - loss: 145.2954 - reconstruction_loss: 133.1578 - kl_loss: 0.5450 - val_loss: 125.2342 - val_reconstruction_loss: 124.8376 - val_kl_loss: 0.3966\n",
      "Epoch 2/1000\n",
      "111/111 [==============================] - 3s 28ms/step - loss: 124.8532 - reconstruction_loss: 122.7653 - kl_loss: 0.5889 - val_loss: 126.8762 - val_reconstruction_loss: 125.6987 - val_kl_loss: 1.1776\n",
      "Epoch 3/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 120.8020 - reconstruction_loss: 118.6369 - kl_loss: 0.6243 - val_loss: 118.0452 - val_reconstruction_loss: 117.5595 - val_kl_loss: 0.4856\n",
      "Epoch 4/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 117.3806 - reconstruction_loss: 117.6928 - kl_loss: 0.9239 - val_loss: 118.0723 - val_reconstruction_loss: 116.9844 - val_kl_loss: 1.0878\n",
      "Epoch 5/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 117.8264 - reconstruction_loss: 116.6447 - kl_loss: 0.8089 - val_loss: 115.9441 - val_reconstruction_loss: 115.3093 - val_kl_loss: 0.6348\n",
      "Epoch 6/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 115.2786 - reconstruction_loss: 114.2652 - kl_loss: 0.6774 - val_loss: 113.9426 - val_reconstruction_loss: 113.2594 - val_kl_loss: 0.6832\n",
      "Epoch 7/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 114.0692 - reconstruction_loss: 112.6355 - kl_loss: 0.7042 - val_loss: 112.5402 - val_reconstruction_loss: 111.7932 - val_kl_loss: 0.7469\n",
      "Epoch 8/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 111.8718 - reconstruction_loss: 111.2520 - kl_loss: 0.7556 - val_loss: 111.0702 - val_reconstruction_loss: 110.2756 - val_kl_loss: 0.7946\n",
      "Epoch 9/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 111.3073 - reconstruction_loss: 110.0420 - kl_loss: 0.7758 - val_loss: 110.1696 - val_reconstruction_loss: 109.4785 - val_kl_loss: 0.6910\n",
      "Epoch 10/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 110.0520 - reconstruction_loss: 109.1206 - kl_loss: 0.7867 - val_loss: 109.5277 - val_reconstruction_loss: 108.7180 - val_kl_loss: 0.8097\n",
      "Epoch 11/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 108.8839 - reconstruction_loss: 108.4904 - kl_loss: 0.7728 - val_loss: 109.0750 - val_reconstruction_loss: 108.1782 - val_kl_loss: 0.8968\n",
      "Epoch 12/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 109.2965 - reconstruction_loss: 107.6067 - kl_loss: 0.7966 - val_loss: 108.3324 - val_reconstruction_loss: 107.5134 - val_kl_loss: 0.8190\n",
      "Epoch 13/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 107.4643 - reconstruction_loss: 106.9007 - kl_loss: 0.7715 - val_loss: 108.0382 - val_reconstruction_loss: 107.2870 - val_kl_loss: 0.7512\n",
      "Epoch 14/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 107.5151 - reconstruction_loss: 106.2024 - kl_loss: 0.8281 - val_loss: 107.5551 - val_reconstruction_loss: 106.8155 - val_kl_loss: 0.7396\n",
      "Epoch 15/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 106.4360 - reconstruction_loss: 105.5784 - kl_loss: 0.8653 - val_loss: 106.4432 - val_reconstruction_loss: 105.5615 - val_kl_loss: 0.8817\n",
      "Epoch 16/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 105.6522 - reconstruction_loss: 104.8997 - kl_loss: 0.8915 - val_loss: 105.6830 - val_reconstruction_loss: 104.8397 - val_kl_loss: 0.8433\n",
      "Epoch 17/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 106.4902 - reconstruction_loss: 104.8230 - kl_loss: 0.9118 - val_loss: 105.9797 - val_reconstruction_loss: 105.0270 - val_kl_loss: 0.9527\n",
      "Epoch 18/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 105.6646 - reconstruction_loss: 104.3199 - kl_loss: 0.9192 - val_loss: 105.4674 - val_reconstruction_loss: 104.5647 - val_kl_loss: 0.9027\n",
      "Epoch 19/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 104.7255 - reconstruction_loss: 103.7478 - kl_loss: 0.9161 - val_loss: 104.9217 - val_reconstruction_loss: 104.0432 - val_kl_loss: 0.8785\n",
      "Epoch 20/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 104.0274 - reconstruction_loss: 103.4709 - kl_loss: 0.9293 - val_loss: 104.5701 - val_reconstruction_loss: 103.6835 - val_kl_loss: 0.8866\n",
      "Epoch 21/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 104.0563 - reconstruction_loss: 102.7258 - kl_loss: 0.9816 - val_loss: 104.1481 - val_reconstruction_loss: 103.1594 - val_kl_loss: 0.9887\n",
      "Epoch 22/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 102.9931 - reconstruction_loss: 102.2322 - kl_loss: 1.0321 - val_loss: 103.5128 - val_reconstruction_loss: 102.5317 - val_kl_loss: 0.9811\n",
      "Epoch 23/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 102.7337 - reconstruction_loss: 101.7051 - kl_loss: 1.0435 - val_loss: 103.1706 - val_reconstruction_loss: 102.1319 - val_kl_loss: 1.0387\n",
      "Epoch 24/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 102.7818 - reconstruction_loss: 101.2845 - kl_loss: 1.0139 - val_loss: 102.5915 - val_reconstruction_loss: 101.5759 - val_kl_loss: 1.0155\n",
      "Epoch 25/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 101.8967 - reconstruction_loss: 100.7130 - kl_loss: 1.0722 - val_loss: 102.3516 - val_reconstruction_loss: 101.2546 - val_kl_loss: 1.0970\n",
      "Epoch 26/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 101.4778 - reconstruction_loss: 100.3545 - kl_loss: 1.0867 - val_loss: 102.3090 - val_reconstruction_loss: 101.2866 - val_kl_loss: 1.0223\n",
      "Epoch 27/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 101.2904 - reconstruction_loss: 100.1716 - kl_loss: 1.0864 - val_loss: 102.1437 - val_reconstruction_loss: 101.1599 - val_kl_loss: 0.9839\n",
      "Epoch 28/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 101.1598 - reconstruction_loss: 99.8293 - kl_loss: 1.1019 - val_loss: 102.4443 - val_reconstruction_loss: 101.4564 - val_kl_loss: 0.9879\n",
      "Epoch 29/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 100.2027 - reconstruction_loss: 99.6658 - kl_loss: 1.1206 - val_loss: 102.3389 - val_reconstruction_loss: 101.2936 - val_kl_loss: 1.0452\n",
      "Epoch 30/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 100.2547 - reconstruction_loss: 99.3518 - kl_loss: 1.1607 - val_loss: 102.2856 - val_reconstruction_loss: 101.1184 - val_kl_loss: 1.1671\n",
      "Epoch 31/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 99.8808 - reconstruction_loss: 99.2015 - kl_loss: 1.1687 - val_loss: 102.3409 - val_reconstruction_loss: 101.2173 - val_kl_loss: 1.1235\n",
      "Epoch 32/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 100.2507 - reconstruction_loss: 99.0272 - kl_loss: 1.1773 - val_loss: 102.5300 - val_reconstruction_loss: 101.3798 - val_kl_loss: 1.1501\n",
      "Epoch 33/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 100.8310 - reconstruction_loss: 98.7853 - kl_loss: 1.1970 - val_loss: 103.0698 - val_reconstruction_loss: 101.8839 - val_kl_loss: 1.1859\n",
      "Epoch 34/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 99.4582 - reconstruction_loss: 98.7254 - kl_loss: 1.2217 - val_loss: 102.8517 - val_reconstruction_loss: 101.7417 - val_kl_loss: 1.1100\n",
      "Epoch 35/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 100.0496 - reconstruction_loss: 98.5833 - kl_loss: 1.2105 - val_loss: 102.4907 - val_reconstruction_loss: 101.2033 - val_kl_loss: 1.2875\n",
      "Epoch 36/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 99.2240 - reconstruction_loss: 98.1708 - kl_loss: 1.2388 - val_loss: 102.8500 - val_reconstruction_loss: 101.5315 - val_kl_loss: 1.3186\n",
      "Epoch 37/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 99.0741 - reconstruction_loss: 98.0094 - kl_loss: 1.2295 - val_loss: 102.2297 - val_reconstruction_loss: 101.0213 - val_kl_loss: 1.2083\n",
      "Epoch 38/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 99.6493 - reconstruction_loss: 98.2485 - kl_loss: 1.2581 - val_loss: 102.2806 - val_reconstruction_loss: 101.0538 - val_kl_loss: 1.2268\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 18ms/step - loss: 98.7810 - reconstruction_loss: 97.4157 - kl_loss: 1.2498 - val_loss: 102.4686 - val_reconstruction_loss: 101.2211 - val_kl_loss: 1.2475\n",
      "Epoch 40/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 97.6443 - reconstruction_loss: 97.1941 - kl_loss: 1.3138 - val_loss: 102.1631 - val_reconstruction_loss: 100.9265 - val_kl_loss: 1.2367\n",
      "Epoch 41/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 98.2229 - reconstruction_loss: 96.9306 - kl_loss: 1.3243 - val_loss: 101.8941 - val_reconstruction_loss: 100.7023 - val_kl_loss: 1.1918\n",
      "Epoch 42/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 97.4631 - reconstruction_loss: 96.6660 - kl_loss: 1.3150 - val_loss: 102.0284 - val_reconstruction_loss: 100.7001 - val_kl_loss: 1.3283\n",
      "Epoch 43/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 97.4860 - reconstruction_loss: 96.3326 - kl_loss: 1.3514 - val_loss: 101.5436 - val_reconstruction_loss: 100.2788 - val_kl_loss: 1.2648\n",
      "Epoch 44/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 97.4431 - reconstruction_loss: 96.1537 - kl_loss: 1.3631 - val_loss: 101.8938 - val_reconstruction_loss: 100.6091 - val_kl_loss: 1.2847\n",
      "Epoch 45/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 96.5455 - reconstruction_loss: 95.8949 - kl_loss: 1.3760 - val_loss: 101.7168 - val_reconstruction_loss: 100.2816 - val_kl_loss: 1.4352\n",
      "Epoch 46/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 96.4643 - reconstruction_loss: 95.6588 - kl_loss: 1.4051 - val_loss: 101.7196 - val_reconstruction_loss: 100.3855 - val_kl_loss: 1.3341\n",
      "Epoch 47/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 96.4384 - reconstruction_loss: 95.1481 - kl_loss: 1.4119 - val_loss: 101.7411 - val_reconstruction_loss: 100.4186 - val_kl_loss: 1.3226\n",
      "Epoch 48/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 95.9110 - reconstruction_loss: 94.8352 - kl_loss: 1.4218 - val_loss: 101.9071 - val_reconstruction_loss: 100.5420 - val_kl_loss: 1.3651\n",
      "Epoch 49/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 95.6535 - reconstruction_loss: 94.5801 - kl_loss: 1.4467 - val_loss: 101.7477 - val_reconstruction_loss: 100.2766 - val_kl_loss: 1.4711\n",
      "Epoch 50/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 96.8587 - reconstruction_loss: 95.1694 - kl_loss: 1.5098 - val_loss: 101.5080 - val_reconstruction_loss: 100.1194 - val_kl_loss: 1.3886\n",
      "Epoch 51/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 95.7445 - reconstruction_loss: 94.0993 - kl_loss: 1.4568 - val_loss: 101.6413 - val_reconstruction_loss: 100.2279 - val_kl_loss: 1.4134\n",
      "Epoch 52/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 95.0910 - reconstruction_loss: 94.8473 - kl_loss: 1.4519 - val_loss: 102.1669 - val_reconstruction_loss: 100.7629 - val_kl_loss: 1.4040\n",
      "Epoch 53/1000\n",
      "111/111 [==============================] - 3s 27ms/step - loss: 96.4770 - reconstruction_loss: 94.7113 - kl_loss: 1.5105 - val_loss: 101.0645 - val_reconstruction_loss: 99.5553 - val_kl_loss: 1.5092\n",
      "Epoch 54/1000\n",
      "111/111 [==============================] - 3s 26ms/step - loss: 96.5067 - reconstruction_loss: 94.9782 - kl_loss: 1.5564 - val_loss: 100.0137 - val_reconstruction_loss: 98.7215 - val_kl_loss: 1.2922\n",
      "Epoch 55/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 98.5582 - reconstruction_loss: 104.1014 - kl_loss: 3.6020 - val_loss: 113.1462 - val_reconstruction_loss: 111.6397 - val_kl_loss: 1.5065\n",
      "Epoch 56/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 114.5078 - reconstruction_loss: 109.8902 - kl_loss: 2.6417 - val_loss: 107.0380 - val_reconstruction_loss: 105.7022 - val_kl_loss: 1.3359\n",
      "Epoch 57/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 105.6044 - reconstruction_loss: 105.3793 - kl_loss: 1.8521 - val_loss: 129.9742 - val_reconstruction_loss: 117.1290 - val_kl_loss: 12.8452\n",
      "Epoch 58/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 115.7815 - reconstruction_loss: 108.1702 - kl_loss: 2.3420 - val_loss: 105.6957 - val_reconstruction_loss: 104.3040 - val_kl_loss: 1.3916\n",
      "Epoch 59/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 105.1537 - reconstruction_loss: 105.7037 - kl_loss: 1.5838 - val_loss: 108.8406 - val_reconstruction_loss: 107.2410 - val_kl_loss: 1.5995\n",
      "Epoch 60/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 107.9770 - reconstruction_loss: 105.3470 - kl_loss: 1.5623 - val_loss: 104.7784 - val_reconstruction_loss: 103.4635 - val_kl_loss: 1.3149\n",
      "Epoch 61/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 104.8250 - reconstruction_loss: 104.3807 - kl_loss: 1.6804 - val_loss: 104.8641 - val_reconstruction_loss: 103.4071 - val_kl_loss: 1.4570\n",
      "Epoch 62/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 103.4239 - reconstruction_loss: 101.6475 - kl_loss: 1.3510 - val_loss: 102.7130 - val_reconstruction_loss: 101.5651 - val_kl_loss: 1.1478\n",
      "Epoch 63/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 101.0405 - reconstruction_loss: 99.6360 - kl_loss: 1.2330 - val_loss: 101.9266 - val_reconstruction_loss: 100.7294 - val_kl_loss: 1.1972\n",
      "Epoch 64/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 100.0939 - reconstruction_loss: 98.5493 - kl_loss: 1.2215 - val_loss: 101.4280 - val_reconstruction_loss: 100.1714 - val_kl_loss: 1.2566\n",
      "Epoch 65/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 99.2863 - reconstruction_loss: 97.7517 - kl_loss: 1.2495 - val_loss: 100.3076 - val_reconstruction_loss: 99.0476 - val_kl_loss: 1.2600\n",
      "Epoch 66/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 97.8530 - reconstruction_loss: 96.6592 - kl_loss: 1.2683 - val_loss: 99.7684 - val_reconstruction_loss: 98.5417 - val_kl_loss: 1.2267\n",
      "Epoch 67/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 97.2272 - reconstruction_loss: 95.9313 - kl_loss: 1.2669 - val_loss: 98.8596 - val_reconstruction_loss: 97.6105 - val_kl_loss: 1.2491\n",
      "Epoch 68/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 96.1936 - reconstruction_loss: 94.8520 - kl_loss: 1.3004 - val_loss: 99.0039 - val_reconstruction_loss: 97.7215 - val_kl_loss: 1.2824\n",
      "Epoch 69/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 105.8876 - reconstruction_loss: 100.7757 - kl_loss: 2.2486 - val_loss: 100.1834 - val_reconstruction_loss: 98.7402 - val_kl_loss: 1.4432\n",
      "Epoch 70/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 97.5907 - reconstruction_loss: 95.8717 - kl_loss: 1.4145 - val_loss: 99.1688 - val_reconstruction_loss: 97.7869 - val_kl_loss: 1.3818\n",
      "Epoch 71/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 95.9621 - reconstruction_loss: 94.7356 - kl_loss: 1.4042 - val_loss: 98.4417 - val_reconstruction_loss: 97.0430 - val_kl_loss: 1.3988\n",
      "Epoch 72/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 94.9214 - reconstruction_loss: 93.4896 - kl_loss: 1.3839 - val_loss: 97.8649 - val_reconstruction_loss: 96.5184 - val_kl_loss: 1.3465\n",
      "Epoch 73/1000\n",
      "111/111 [==============================] - 3s 28ms/step - loss: 93.5670 - reconstruction_loss: 92.6809 - kl_loss: 1.4012 - val_loss: 97.5068 - val_reconstruction_loss: 96.1267 - val_kl_loss: 1.3802\n",
      "Epoch 74/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 93.3237 - reconstruction_loss: 92.0366 - kl_loss: 1.4384 - val_loss: 97.5996 - val_reconstruction_loss: 96.1694 - val_kl_loss: 1.4302\n",
      "Epoch 75/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 92.6009 - reconstruction_loss: 92.1152 - kl_loss: 1.4828 - val_loss: 98.7110 - val_reconstruction_loss: 97.2162 - val_kl_loss: 1.4949\n",
      "Epoch 76/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 93.0409 - reconstruction_loss: 91.5435 - kl_loss: 1.5035 - val_loss: 97.2799 - val_reconstruction_loss: 95.8407 - val_kl_loss: 1.4392\n",
      "Epoch 77/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 91.7636 - reconstruction_loss: 90.6034 - kl_loss: 1.5210 - val_loss: 97.8911 - val_reconstruction_loss: 96.2540 - val_kl_loss: 1.6372\n",
      "Epoch 78/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 91.3510 - reconstruction_loss: 90.2134 - kl_loss: 1.5426 - val_loss: 97.2037 - val_reconstruction_loss: 95.6268 - val_kl_loss: 1.5770\n",
      "Epoch 79/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 90.8516 - reconstruction_loss: 89.6645 - kl_loss: 1.5847 - val_loss: 97.9895 - val_reconstruction_loss: 96.4056 - val_kl_loss: 1.5838\n",
      "Epoch 80/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 91.0430 - reconstruction_loss: 89.5910 - kl_loss: 1.6327 - val_loss: 98.1007 - val_reconstruction_loss: 96.5015 - val_kl_loss: 1.5992\n",
      "Epoch 81/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 91.2515 - reconstruction_loss: 89.1744 - kl_loss: 1.6519 - val_loss: 97.9784 - val_reconstruction_loss: 96.2695 - val_kl_loss: 1.7089\n",
      "Epoch 82/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 89.7655 - reconstruction_loss: 88.1594 - kl_loss: 1.6572 - val_loss: 97.7724 - val_reconstruction_loss: 96.1252 - val_kl_loss: 1.6472\n",
      "Epoch 83/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 90.0115 - reconstruction_loss: 88.3598 - kl_loss: 1.7345 - val_loss: 98.0712 - val_reconstruction_loss: 96.3195 - val_kl_loss: 1.7517\n",
      "Epoch 84/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 89.1712 - reconstruction_loss: 87.0968 - kl_loss: 1.7298 - val_loss: 97.5626 - val_reconstruction_loss: 95.8402 - val_kl_loss: 1.7223\n",
      "Epoch 85/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 89.1592 - reconstruction_loss: 86.6487 - kl_loss: 1.7961 - val_loss: 97.8974 - val_reconstruction_loss: 96.0926 - val_kl_loss: 1.8047\n",
      "Epoch 86/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 88.6557 - reconstruction_loss: 86.9579 - kl_loss: 1.8172 - val_loss: 98.2262 - val_reconstruction_loss: 96.3593 - val_kl_loss: 1.8669\n",
      "Epoch 87/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 86.5982 - reconstruction_loss: 85.9511 - kl_loss: 1.8072 - val_loss: 98.1024 - val_reconstruction_loss: 96.3382 - val_kl_loss: 1.7643\n",
      "Epoch 88/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 87.5584 - reconstruction_loss: 85.1997 - kl_loss: 1.8680 - val_loss: 98.6758 - val_reconstruction_loss: 96.8231 - val_kl_loss: 1.8527\n",
      "Epoch 89/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 86.4973 - reconstruction_loss: 85.7971 - kl_loss: 1.9175 - val_loss: 99.6103 - val_reconstruction_loss: 97.7035 - val_kl_loss: 1.9068\n",
      "Epoch 90/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 87.7937 - reconstruction_loss: 86.0505 - kl_loss: 1.9017 - val_loss: 98.5215 - val_reconstruction_loss: 96.5845 - val_kl_loss: 1.9370\n",
      "Epoch 91/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 86.5824 - reconstruction_loss: 84.2266 - kl_loss: 1.9081 - val_loss: 100.7121 - val_reconstruction_loss: 98.7363 - val_kl_loss: 1.9758\n",
      "Epoch 92/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 86.7842 - reconstruction_loss: 86.3610 - kl_loss: 1.9515 - val_loss: 99.3041 - val_reconstruction_loss: 97.5754 - val_kl_loss: 1.7287\n",
      "Epoch 93/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 87.9854 - reconstruction_loss: 85.4710 - kl_loss: 1.9202 - val_loss: 99.5495 - val_reconstruction_loss: 97.6104 - val_kl_loss: 1.9391\n",
      "Epoch 94/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 85.4718 - reconstruction_loss: 84.0873 - kl_loss: 1.9691 - val_loss: 99.2011 - val_reconstruction_loss: 97.2908 - val_kl_loss: 1.9103\n",
      "Epoch 95/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 86.4420 - reconstruction_loss: 84.4510 - kl_loss: 1.9953 - val_loss: 101.3391 - val_reconstruction_loss: 99.3851 - val_kl_loss: 1.9540\n",
      "Epoch 96/1000\n",
      "111/111 [==============================] - 4s 37ms/step - loss: 85.8426 - reconstruction_loss: 83.4963 - kl_loss: 2.0261 - val_loss: 99.0912 - val_reconstruction_loss: 97.0774 - val_kl_loss: 2.0138\n",
      "Epoch 97/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 84.6146 - reconstruction_loss: 82.7143 - kl_loss: 2.0675 - val_loss: 99.0444 - val_reconstruction_loss: 97.0494 - val_kl_loss: 1.9950\n",
      "Epoch 98/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 84.2843 - reconstruction_loss: 83.6446 - kl_loss: 2.0850 - val_loss: 100.4079 - val_reconstruction_loss: 98.4314 - val_kl_loss: 1.9765\n",
      "Epoch 99/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 84.8095 - reconstruction_loss: 82.7583 - kl_loss: 2.0661 - val_loss: 99.6687 - val_reconstruction_loss: 97.6232 - val_kl_loss: 2.0455\n",
      "Epoch 100/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 84.3705 - reconstruction_loss: 82.0629 - kl_loss: 2.0883 - val_loss: 100.0725 - val_reconstruction_loss: 97.9908 - val_kl_loss: 2.0817\n",
      "Epoch 101/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 82.4013 - reconstruction_loss: 81.2768 - kl_loss: 2.1036 - val_loss: 100.9987 - val_reconstruction_loss: 98.8387 - val_kl_loss: 2.1600\n",
      "Epoch 102/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 82.6448 - reconstruction_loss: 80.8105 - kl_loss: 2.1271 - val_loss: 100.8719 - val_reconstruction_loss: 98.8064 - val_kl_loss: 2.0655\n",
      "Epoch 103/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 84.2174 - reconstruction_loss: 83.7164 - kl_loss: 2.2035 - val_loss: 100.6225 - val_reconstruction_loss: 98.5070 - val_kl_loss: 2.1155\n",
      "Epoch 104/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 85.8812 - reconstruction_loss: 88.9611 - kl_loss: 2.5281 - val_loss: 102.0377 - val_reconstruction_loss: 99.9604 - val_kl_loss: 2.0772\n",
      "Epoch 105/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 91.6051 - reconstruction_loss: 87.8953 - kl_loss: 2.0575 - val_loss: 100.1413 - val_reconstruction_loss: 98.1375 - val_kl_loss: 2.0038\n",
      "Epoch 106/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 85.8439 - reconstruction_loss: 83.5753 - kl_loss: 2.0621 - val_loss: 100.7935 - val_reconstruction_loss: 98.7366 - val_kl_loss: 2.0569\n",
      "Epoch 107/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 84.8019 - reconstruction_loss: 82.3780 - kl_loss: 2.1003 - val_loss: 100.4405 - val_reconstruction_loss: 98.2600 - val_kl_loss: 2.1805\n",
      "Epoch 108/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 82.7565 - reconstruction_loss: 81.2384 - kl_loss: 2.1178 - val_loss: 100.3235 - val_reconstruction_loss: 98.2968 - val_kl_loss: 2.0267\n",
      "Epoch 109/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 82.0490 - reconstruction_loss: 80.0369 - kl_loss: 2.1555 - val_loss: 100.8189 - val_reconstruction_loss: 98.6801 - val_kl_loss: 2.1388\n",
      "Epoch 110/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 80.6544 - reconstruction_loss: 79.2779 - kl_loss: 2.1666 - val_loss: 101.5985 - val_reconstruction_loss: 99.4557 - val_kl_loss: 2.1428\n",
      "Epoch 111/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 81.3210 - reconstruction_loss: 79.5845 - kl_loss: 2.2413 - val_loss: 101.3781 - val_reconstruction_loss: 99.1721 - val_kl_loss: 2.2059\n",
      "Epoch 112/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 81.0824 - reconstruction_loss: 79.5450 - kl_loss: 2.2624 - val_loss: 102.6913 - val_reconstruction_loss: 100.3746 - val_kl_loss: 2.3167\n",
      "Epoch 113/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 82.0434 - reconstruction_loss: 80.3612 - kl_loss: 2.2731 - val_loss: 101.6745 - val_reconstruction_loss: 99.5257 - val_kl_loss: 2.1488\n",
      "Epoch 114/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 82.3771 - reconstruction_loss: 79.9893 - kl_loss: 2.2202 - val_loss: 101.9128 - val_reconstruction_loss: 99.8131 - val_kl_loss: 2.0997\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 17ms/step - loss: 80.7950 - reconstruction_loss: 78.6263 - kl_loss: 2.2108 - val_loss: 101.6074 - val_reconstruction_loss: 99.3979 - val_kl_loss: 2.2094\n",
      "Epoch 116/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 79.5112 - reconstruction_loss: 77.4281 - kl_loss: 2.2604 - val_loss: 102.6738 - val_reconstruction_loss: 100.3856 - val_kl_loss: 2.2882\n",
      "Epoch 117/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 79.2351 - reconstruction_loss: 77.2767 - kl_loss: 2.3190 - val_loss: 102.9054 - val_reconstruction_loss: 100.6382 - val_kl_loss: 2.2672\n",
      "Epoch 118/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 79.5805 - reconstruction_loss: 76.9842 - kl_loss: 2.3212 - val_loss: 104.0684 - val_reconstruction_loss: 101.7235 - val_kl_loss: 2.3449\n",
      "Epoch 119/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 80.2505 - reconstruction_loss: 77.2551 - kl_loss: 2.3564 - val_loss: 102.8271 - val_reconstruction_loss: 100.5249 - val_kl_loss: 2.3022\n",
      "Epoch 120/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 79.1585 - reconstruction_loss: 77.0016 - kl_loss: 2.3908 - val_loss: 102.4268 - val_reconstruction_loss: 100.0918 - val_kl_loss: 2.3350\n",
      "Epoch 121/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 77.3071 - reconstruction_loss: 75.6843 - kl_loss: 2.3764 - val_loss: 104.6701 - val_reconstruction_loss: 102.1725 - val_kl_loss: 2.4976\n",
      "Epoch 122/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 79.2238 - reconstruction_loss: 80.5464 - kl_loss: 2.4847 - val_loss: 103.3511 - val_reconstruction_loss: 101.0640 - val_kl_loss: 2.2871\n",
      "Epoch 123/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 83.6643 - reconstruction_loss: 80.0195 - kl_loss: 2.3063 - val_loss: 103.4684 - val_reconstruction_loss: 101.1228 - val_kl_loss: 2.3456\n",
      "Epoch 124/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 79.2031 - reconstruction_loss: 76.9918 - kl_loss: 2.3556 - val_loss: 102.9568 - val_reconstruction_loss: 100.6439 - val_kl_loss: 2.3130\n",
      "Epoch 125/1000\n",
      "111/111 [==============================] - 3s 27ms/step - loss: 78.0036 - reconstruction_loss: 75.7094 - kl_loss: 2.4043 - val_loss: 103.7599 - val_reconstruction_loss: 101.4439 - val_kl_loss: 2.3161\n",
      "Epoch 126/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 76.9040 - reconstruction_loss: 74.8935 - kl_loss: 2.3750 - val_loss: 104.5608 - val_reconstruction_loss: 102.1716 - val_kl_loss: 2.3892\n",
      "Epoch 127/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 77.4414 - reconstruction_loss: 76.4422 - kl_loss: 2.4431 - val_loss: 103.6608 - val_reconstruction_loss: 101.3013 - val_kl_loss: 2.3594\n",
      "Epoch 128/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 77.8378 - reconstruction_loss: 75.0893 - kl_loss: 2.4164 - val_loss: 104.3176 - val_reconstruction_loss: 101.9509 - val_kl_loss: 2.3667\n",
      "Epoch 129/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 77.5079 - reconstruction_loss: 75.3999 - kl_loss: 2.4331 - val_loss: 105.1281 - val_reconstruction_loss: 102.7233 - val_kl_loss: 2.4048\n",
      "Epoch 130/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 76.7208 - reconstruction_loss: 74.3936 - kl_loss: 2.4446 - val_loss: 104.5571 - val_reconstruction_loss: 102.2087 - val_kl_loss: 2.3484\n",
      "Epoch 131/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 75.7141 - reconstruction_loss: 73.2693 - kl_loss: 2.4532 - val_loss: 104.2531 - val_reconstruction_loss: 101.9406 - val_kl_loss: 2.3125\n",
      "Epoch 132/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 75.5018 - reconstruction_loss: 73.2978 - kl_loss: 2.4933 - val_loss: 104.7029 - val_reconstruction_loss: 102.3216 - val_kl_loss: 2.3813\n",
      "Epoch 133/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 75.5613 - reconstruction_loss: 73.5789 - kl_loss: 2.5381 - val_loss: 106.3747 - val_reconstruction_loss: 103.9176 - val_kl_loss: 2.4571\n",
      "Epoch 134/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 79.6389 - reconstruction_loss: 77.8769 - kl_loss: 2.6020 - val_loss: 104.9033 - val_reconstruction_loss: 102.3399 - val_kl_loss: 2.5635\n",
      "Epoch 135/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 77.1333 - reconstruction_loss: 74.8937 - kl_loss: 2.5401 - val_loss: 105.1879 - val_reconstruction_loss: 102.7254 - val_kl_loss: 2.4624\n",
      "Epoch 136/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 76.2720 - reconstruction_loss: 79.0009 - kl_loss: 2.8317 - val_loss: 107.0491 - val_reconstruction_loss: 104.0292 - val_kl_loss: 3.0200\n",
      "Epoch 137/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 88.8694 - reconstruction_loss: 82.4979 - kl_loss: 2.6144 - val_loss: 104.1940 - val_reconstruction_loss: 101.7481 - val_kl_loss: 2.4459\n",
      "Epoch 138/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 78.8811 - reconstruction_loss: 75.8964 - kl_loss: 2.5432 - val_loss: 104.8624 - val_reconstruction_loss: 102.4036 - val_kl_loss: 2.4587\n",
      "Epoch 139/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 75.7452 - reconstruction_loss: 74.0589 - kl_loss: 2.5450 - val_loss: 105.3123 - val_reconstruction_loss: 102.8269 - val_kl_loss: 2.4854\n",
      "Epoch 140/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 75.7960 - reconstruction_loss: 73.6589 - kl_loss: 2.5664 - val_loss: 104.9473 - val_reconstruction_loss: 102.5321 - val_kl_loss: 2.4152\n",
      "Epoch 141/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 75.0488 - reconstruction_loss: 72.5419 - kl_loss: 2.5542 - val_loss: 106.7933 - val_reconstruction_loss: 104.2184 - val_kl_loss: 2.5749\n",
      "Epoch 142/1000\n",
      "111/111 [==============================] - 4s 38ms/step - loss: 74.0725 - reconstruction_loss: 72.0584 - kl_loss: 2.6069 - val_loss: 106.9243 - val_reconstruction_loss: 104.3397 - val_kl_loss: 2.5846\n",
      "Epoch 143/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 74.0210 - reconstruction_loss: 71.4084 - kl_loss: 2.5963 - val_loss: 107.2678 - val_reconstruction_loss: 104.8038 - val_kl_loss: 2.4640\n",
      "Epoch 144/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 74.0199 - reconstruction_loss: 72.5027 - kl_loss: 2.6629 - val_loss: 107.6133 - val_reconstruction_loss: 104.9899 - val_kl_loss: 2.6233\n",
      "Epoch 145/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 79.0176 - reconstruction_loss: 77.2294 - kl_loss: 2.8466 - val_loss: 106.1224 - val_reconstruction_loss: 103.4602 - val_kl_loss: 2.6622\n",
      "Epoch 146/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 76.0061 - reconstruction_loss: 73.2943 - kl_loss: 2.6202 - val_loss: 107.5889 - val_reconstruction_loss: 104.9213 - val_kl_loss: 2.6675\n",
      "Epoch 147/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 75.1218 - reconstruction_loss: 72.6802 - kl_loss: 2.5935 - val_loss: 107.3537 - val_reconstruction_loss: 104.8037 - val_kl_loss: 2.5500\n",
      "Epoch 148/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 74.1587 - reconstruction_loss: 71.6397 - kl_loss: 2.6168 - val_loss: 107.0335 - val_reconstruction_loss: 104.4442 - val_kl_loss: 2.5893\n",
      "Epoch 149/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 76.1846 - reconstruction_loss: 77.2462 - kl_loss: 2.7599 - val_loss: 108.2314 - val_reconstruction_loss: 105.5153 - val_kl_loss: 2.7161\n",
      "Epoch 150/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 76.9773 - reconstruction_loss: 73.8242 - kl_loss: 2.6099 - val_loss: 107.1426 - val_reconstruction_loss: 104.6049 - val_kl_loss: 2.5377\n",
      "Epoch 151/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 73.7817 - reconstruction_loss: 71.1422 - kl_loss: 2.6278 - val_loss: 107.9185 - val_reconstruction_loss: 105.2826 - val_kl_loss: 2.6359\n",
      "Epoch 152/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 72.4990 - reconstruction_loss: 70.5338 - kl_loss: 2.6466 - val_loss: 107.5621 - val_reconstruction_loss: 105.0205 - val_kl_loss: 2.5417\n",
      "Epoch 153/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 72.9818 - reconstruction_loss: 70.1909 - kl_loss: 2.6823 - val_loss: 109.4860 - val_reconstruction_loss: 106.7996 - val_kl_loss: 2.6863\n",
      "Epoch 154/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 80.0924 - reconstruction_loss: 80.0642 - kl_loss: 3.1373 - val_loss: 106.0059 - val_reconstruction_loss: 103.4737 - val_kl_loss: 2.5321\n",
      "Epoch 155/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 77.7181 - reconstruction_loss: 73.9786 - kl_loss: 2.6893 - val_loss: 106.0993 - val_reconstruction_loss: 103.5865 - val_kl_loss: 2.5129\n",
      "Epoch 156/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 74.0668 - reconstruction_loss: 73.8019 - kl_loss: 2.8538 - val_loss: 109.0365 - val_reconstruction_loss: 105.8848 - val_kl_loss: 3.1516\n",
      "Epoch 157/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 78.9832 - reconstruction_loss: 74.3753 - kl_loss: 2.7860 - val_loss: 105.9470 - val_reconstruction_loss: 103.3880 - val_kl_loss: 2.5590\n",
      "Epoch 158/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 73.3799 - reconstruction_loss: 70.7161 - kl_loss: 2.7127 - val_loss: 106.2650 - val_reconstruction_loss: 103.7070 - val_kl_loss: 2.5580\n",
      "Epoch 159/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 71.5552 - reconstruction_loss: 69.2453 - kl_loss: 2.6793 - val_loss: 109.2764 - val_reconstruction_loss: 106.5393 - val_kl_loss: 2.7371\n",
      "Epoch 160/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 71.6224 - reconstruction_loss: 69.5739 - kl_loss: 2.6948 - val_loss: 108.3006 - val_reconstruction_loss: 105.6343 - val_kl_loss: 2.6664\n",
      "Epoch 161/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 120.4483 - reconstruction_loss: 121.8066 - kl_loss: 9.7877 - val_loss: 121.0134 - val_reconstruction_loss: 118.1806 - val_kl_loss: 2.8329\n",
      "Epoch 162/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 117.9312 - reconstruction_loss: 113.5800 - kl_loss: 2.0646 - val_loss: 112.5462 - val_reconstruction_loss: 111.1355 - val_kl_loss: 1.4107\n",
      "Epoch 163/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 111.1695 - reconstruction_loss: 108.9010 - kl_loss: 1.3991 - val_loss: 109.2494 - val_reconstruction_loss: 107.9207 - val_kl_loss: 1.3287\n",
      "Epoch 164/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 108.4739 - reconstruction_loss: 106.7366 - kl_loss: 1.3093 - val_loss: 111.0413 - val_reconstruction_loss: 109.4309 - val_kl_loss: 1.6104\n",
      "Epoch 165/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 108.0424 - reconstruction_loss: 105.7109 - kl_loss: 1.3247 - val_loss: 107.1000 - val_reconstruction_loss: 105.8701 - val_kl_loss: 1.2299\n",
      "Epoch 166/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 105.2405 - reconstruction_loss: 103.6456 - kl_loss: 1.1809 - val_loss: 105.3932 - val_reconstruction_loss: 104.2828 - val_kl_loss: 1.1105\n",
      "Epoch 167/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 111.1126 - reconstruction_loss: 107.8664 - kl_loss: 2.4049 - val_loss: 107.6176 - val_reconstruction_loss: 105.8797 - val_kl_loss: 1.7379\n",
      "Epoch 168/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 105.8465 - reconstruction_loss: 103.4081 - kl_loss: 1.4372 - val_loss: 104.6742 - val_reconstruction_loss: 103.4048 - val_kl_loss: 1.2694\n",
      "Epoch 169/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 106.4613 - reconstruction_loss: 112.1925 - kl_loss: 5.9660 - val_loss: 130.0992 - val_reconstruction_loss: 123.5253 - val_kl_loss: 6.5740\n",
      "Epoch 170/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 123.5849 - reconstruction_loss: 117.3532 - kl_loss: 2.6908 - val_loss: 114.9902 - val_reconstruction_loss: 113.5048 - val_kl_loss: 1.4854\n",
      "Epoch 171/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 113.8637 - reconstruction_loss: 111.0004 - kl_loss: 1.3836 - val_loss: 110.4428 - val_reconstruction_loss: 109.0436 - val_kl_loss: 1.3992\n",
      "Epoch 172/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 109.4701 - reconstruction_loss: 107.8891 - kl_loss: 1.2990 - val_loss: 108.7676 - val_reconstruction_loss: 107.5849 - val_kl_loss: 1.1827\n",
      "Epoch 173/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 107.2598 - reconstruction_loss: 106.2204 - kl_loss: 1.2647 - val_loss: 106.6979 - val_reconstruction_loss: 105.4616 - val_kl_loss: 1.2363\n",
      "Epoch 174/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 105.7352 - reconstruction_loss: 104.0606 - kl_loss: 1.2098 - val_loss: 106.0190 - val_reconstruction_loss: 104.8322 - val_kl_loss: 1.1867\n",
      "Epoch 175/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 104.8014 - reconstruction_loss: 103.0525 - kl_loss: 1.2632 - val_loss: 104.0069 - val_reconstruction_loss: 102.7559 - val_kl_loss: 1.2510\n",
      "Epoch 176/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 102.6774 - reconstruction_loss: 101.5403 - kl_loss: 1.2517 - val_loss: 103.9735 - val_reconstruction_loss: 102.6490 - val_kl_loss: 1.3245\n",
      "Epoch 177/1000\n",
      "111/111 [==============================] - 4s 36ms/step - loss: 102.1360 - reconstruction_loss: 100.5317 - kl_loss: 1.2865 - val_loss: 102.1122 - val_reconstruction_loss: 100.8312 - val_kl_loss: 1.2810\n",
      "Epoch 178/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 100.2703 - reconstruction_loss: 98.8909 - kl_loss: 1.3165 - val_loss: 101.2132 - val_reconstruction_loss: 99.8634 - val_kl_loss: 1.3499\n",
      "Epoch 179/1000\n",
      "111/111 [==============================] - 3s 27ms/step - loss: 99.3754 - reconstruction_loss: 97.8720 - kl_loss: 1.3120 - val_loss: 100.4609 - val_reconstruction_loss: 99.1963 - val_kl_loss: 1.2646\n",
      "Epoch 180/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 98.0343 - reconstruction_loss: 97.2482 - kl_loss: 1.3287 - val_loss: 100.0954 - val_reconstruction_loss: 98.7036 - val_kl_loss: 1.3917\n",
      "Epoch 181/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 97.9538 - reconstruction_loss: 96.4670 - kl_loss: 1.4026 - val_loss: 99.9589 - val_reconstruction_loss: 98.5083 - val_kl_loss: 1.4506\n",
      "Epoch 182/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 99.1893 - reconstruction_loss: 98.9775 - kl_loss: 1.6498 - val_loss: 100.3295 - val_reconstruction_loss: 98.9334 - val_kl_loss: 1.3962\n",
      "Epoch 183/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 97.7171 - reconstruction_loss: 95.9389 - kl_loss: 1.3764 - val_loss: 99.5284 - val_reconstruction_loss: 98.0612 - val_kl_loss: 1.4672\n",
      "Epoch 184/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 95.8407 - reconstruction_loss: 94.6148 - kl_loss: 1.3678 - val_loss: 98.8294 - val_reconstruction_loss: 97.4056 - val_kl_loss: 1.4238\n",
      "Epoch 185/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 95.2533 - reconstruction_loss: 93.7103 - kl_loss: 1.4120 - val_loss: 98.4944 - val_reconstruction_loss: 97.0406 - val_kl_loss: 1.4539\n",
      "Epoch 186/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 94.1806 - reconstruction_loss: 93.0375 - kl_loss: 1.4244 - val_loss: 98.3926 - val_reconstruction_loss: 96.9208 - val_kl_loss: 1.4718\n",
      "Epoch 187/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 93.4925 - reconstruction_loss: 92.3502 - kl_loss: 1.4708 - val_loss: 97.9080 - val_reconstruction_loss: 96.3825 - val_kl_loss: 1.5255\n",
      "Epoch 188/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 93.3977 - reconstruction_loss: 92.2369 - kl_loss: 1.5280 - val_loss: 102.3665 - val_reconstruction_loss: 100.3563 - val_kl_loss: 2.0102\n",
      "Epoch 189/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 106.0633 - reconstruction_loss: 100.5247 - kl_loss: 2.8157 - val_loss: 101.8462 - val_reconstruction_loss: 99.8032 - val_kl_loss: 2.0430\n",
      "Epoch 190/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 96.5504 - reconstruction_loss: 94.5242 - kl_loss: 1.6803 - val_loss: 98.4785 - val_reconstruction_loss: 96.9239 - val_kl_loss: 1.5545\n",
      "Epoch 191/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 20ms/step - loss: 94.0958 - reconstruction_loss: 92.2057 - kl_loss: 1.5393 - val_loss: 98.0534 - val_reconstruction_loss: 96.6230 - val_kl_loss: 1.4304\n",
      "Epoch 192/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 110.2501 - reconstruction_loss: 114.1228 - kl_loss: 12.5992 - val_loss: 123.5590 - val_reconstruction_loss: 117.8829 - val_kl_loss: 5.6761\n",
      "Epoch 193/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 119.7698 - reconstruction_loss: 112.8447 - kl_loss: 3.5479 - val_loss: 110.8268 - val_reconstruction_loss: 108.3082 - val_kl_loss: 2.5185\n",
      "Epoch 194/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 110.0643 - reconstruction_loss: 106.4210 - kl_loss: 2.1878 - val_loss: 106.2942 - val_reconstruction_loss: 104.4530 - val_kl_loss: 1.8412\n",
      "Epoch 195/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 105.0603 - reconstruction_loss: 102.8626 - kl_loss: 1.6972 - val_loss: 103.3828 - val_reconstruction_loss: 101.7995 - val_kl_loss: 1.5832\n",
      "Epoch 196/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 102.3237 - reconstruction_loss: 100.5131 - kl_loss: 1.5008 - val_loss: 102.3083 - val_reconstruction_loss: 100.7381 - val_kl_loss: 1.5702\n",
      "Epoch 197/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 99.9998 - reconstruction_loss: 98.6296 - kl_loss: 1.4237 - val_loss: 101.0530 - val_reconstruction_loss: 99.6242 - val_kl_loss: 1.4288\n",
      "Epoch 198/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 99.0729 - reconstruction_loss: 97.2230 - kl_loss: 1.4124 - val_loss: 99.8129 - val_reconstruction_loss: 98.2782 - val_kl_loss: 1.5347\n",
      "Epoch 199/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 98.1623 - reconstruction_loss: 96.0631 - kl_loss: 1.4490 - val_loss: 98.9145 - val_reconstruction_loss: 97.5109 - val_kl_loss: 1.4036\n",
      "Epoch 200/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 96.6688 - reconstruction_loss: 94.8811 - kl_loss: 1.4646 - val_loss: 98.4867 - val_reconstruction_loss: 97.0377 - val_kl_loss: 1.4490\n",
      "Epoch 201/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 95.6142 - reconstruction_loss: 93.9267 - kl_loss: 1.4673 - val_loss: 98.4293 - val_reconstruction_loss: 96.9837 - val_kl_loss: 1.4456\n",
      "Epoch 202/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 94.2685 - reconstruction_loss: 93.1313 - kl_loss: 1.5040 - val_loss: 98.7356 - val_reconstruction_loss: 97.1549 - val_kl_loss: 1.5807\n",
      "Epoch 203/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 94.1826 - reconstruction_loss: 92.5252 - kl_loss: 1.5260 - val_loss: 98.0925 - val_reconstruction_loss: 96.5579 - val_kl_loss: 1.5346\n",
      "Epoch 204/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 94.0543 - reconstruction_loss: 97.6722 - kl_loss: 2.2634 - val_loss: 113.5540 - val_reconstruction_loss: 111.0383 - val_kl_loss: 2.5157\n",
      "Epoch 205/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 102.8890 - reconstruction_loss: 97.4039 - kl_loss: 1.7385 - val_loss: 98.4231 - val_reconstruction_loss: 96.8346 - val_kl_loss: 1.5885\n",
      "Epoch 206/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 94.0109 - reconstruction_loss: 91.8275 - kl_loss: 1.5588 - val_loss: 97.9530 - val_reconstruction_loss: 96.4014 - val_kl_loss: 1.5515\n",
      "Epoch 207/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 91.9200 - reconstruction_loss: 90.8107 - kl_loss: 1.5863 - val_loss: 97.7839 - val_reconstruction_loss: 96.2623 - val_kl_loss: 1.5216\n",
      "Epoch 208/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 91.6389 - reconstruction_loss: 90.1358 - kl_loss: 1.6087 - val_loss: 97.9458 - val_reconstruction_loss: 96.4030 - val_kl_loss: 1.5428\n",
      "Epoch 209/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 91.0419 - reconstruction_loss: 89.5238 - kl_loss: 1.6322 - val_loss: 98.1598 - val_reconstruction_loss: 96.5202 - val_kl_loss: 1.6395\n",
      "Epoch 210/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 89.7055 - reconstruction_loss: 88.7490 - kl_loss: 1.6683 - val_loss: 97.8295 - val_reconstruction_loss: 96.0890 - val_kl_loss: 1.7405\n",
      "Epoch 211/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 88.9923 - reconstruction_loss: 89.2057 - kl_loss: 1.7048 - val_loss: 99.8648 - val_reconstruction_loss: 98.2038 - val_kl_loss: 1.6610\n",
      "Epoch 212/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 90.7745 - reconstruction_loss: 88.6465 - kl_loss: 1.7146 - val_loss: 98.4276 - val_reconstruction_loss: 96.7075 - val_kl_loss: 1.7200\n",
      "Epoch 213/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 88.3815 - reconstruction_loss: 87.6886 - kl_loss: 1.7431 - val_loss: 100.3920 - val_reconstruction_loss: 98.5710 - val_kl_loss: 1.8211\n",
      "Epoch 214/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 89.0280 - reconstruction_loss: 87.6521 - kl_loss: 1.7828 - val_loss: 98.7310 - val_reconstruction_loss: 96.9877 - val_kl_loss: 1.7433\n",
      "Epoch 215/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 87.8707 - reconstruction_loss: 86.4644 - kl_loss: 1.8095 - val_loss: 98.5356 - val_reconstruction_loss: 96.7740 - val_kl_loss: 1.7616\n",
      "Epoch 216/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 87.9588 - reconstruction_loss: 87.0536 - kl_loss: 1.8385 - val_loss: 98.5631 - val_reconstruction_loss: 96.6631 - val_kl_loss: 1.9000\n",
      "Epoch 217/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 86.2728 - reconstruction_loss: 85.7128 - kl_loss: 1.8529 - val_loss: 98.9458 - val_reconstruction_loss: 97.1140 - val_kl_loss: 1.8318\n",
      "Epoch 218/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 87.1058 - reconstruction_loss: 85.7820 - kl_loss: 1.8519 - val_loss: 99.7349 - val_reconstruction_loss: 97.8648 - val_kl_loss: 1.8701\n",
      "Epoch 219/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 87.3266 - reconstruction_loss: 87.8116 - kl_loss: 1.9033 - val_loss: 99.3039 - val_reconstruction_loss: 97.6005 - val_kl_loss: 1.7034\n",
      "Epoch 220/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 89.1226 - reconstruction_loss: 86.7776 - kl_loss: 1.8424 - val_loss: 99.6412 - val_reconstruction_loss: 97.7114 - val_kl_loss: 1.9299\n",
      "Epoch 221/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 86.0309 - reconstruction_loss: 84.9027 - kl_loss: 1.9119 - val_loss: 99.4118 - val_reconstruction_loss: 97.4377 - val_kl_loss: 1.9741\n",
      "Epoch 222/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 85.9742 - reconstruction_loss: 84.0110 - kl_loss: 1.9499 - val_loss: 99.9754 - val_reconstruction_loss: 98.0381 - val_kl_loss: 1.9373\n",
      "Epoch 223/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 93.3976 - reconstruction_loss: 96.3201 - kl_loss: 2.4613 - val_loss: 100.6604 - val_reconstruction_loss: 98.7036 - val_kl_loss: 1.9568\n",
      "Epoch 224/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 92.6503 - reconstruction_loss: 89.5141 - kl_loss: 1.8252 - val_loss: 98.4405 - val_reconstruction_loss: 96.6732 - val_kl_loss: 1.7673\n",
      "Epoch 225/1000\n",
      "111/111 [==============================] - 2s 23ms/step - loss: 87.9397 - reconstruction_loss: 86.2304 - kl_loss: 1.8899 - val_loss: 99.1380 - val_reconstruction_loss: 97.2629 - val_kl_loss: 1.8751\n",
      "Epoch 226/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 86.0051 - reconstruction_loss: 84.6204 - kl_loss: 1.9157 - val_loss: 98.9753 - val_reconstruction_loss: 97.0646 - val_kl_loss: 1.9107\n",
      "Epoch 227/1000\n",
      "111/111 [==============================] - 3s 26ms/step - loss: 85.9395 - reconstruction_loss: 84.0688 - kl_loss: 1.9645 - val_loss: 100.0688 - val_reconstruction_loss: 98.0543 - val_kl_loss: 2.0146\n",
      "Epoch 228/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 87.3762 - reconstruction_loss: 96.4293 - kl_loss: 5.8731 - val_loss: 120.5732 - val_reconstruction_loss: 116.9885 - val_kl_loss: 3.5847\n",
      "Epoch 229/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 113.7764 - reconstruction_loss: 108.6380 - kl_loss: 1.7364 - val_loss: 107.1681 - val_reconstruction_loss: 105.7229 - val_kl_loss: 1.4451\n",
      "Epoch 230/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 104.1147 - reconstruction_loss: 101.8956 - kl_loss: 1.4295 - val_loss: 104.2807 - val_reconstruction_loss: 102.8669 - val_kl_loss: 1.4138\n",
      "Epoch 231/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 100.7790 - reconstruction_loss: 98.4615 - kl_loss: 1.4859 - val_loss: 102.8851 - val_reconstruction_loss: 101.4547 - val_kl_loss: 1.4304\n",
      "Epoch 232/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 98.3060 - reconstruction_loss: 96.3034 - kl_loss: 1.5524 - val_loss: 101.9201 - val_reconstruction_loss: 100.3058 - val_kl_loss: 1.6143\n",
      "Epoch 233/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 95.8131 - reconstruction_loss: 94.1677 - kl_loss: 1.6849 - val_loss: 100.9265 - val_reconstruction_loss: 99.3338 - val_kl_loss: 1.5927\n",
      "Epoch 234/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 93.6239 - reconstruction_loss: 91.8102 - kl_loss: 1.7202 - val_loss: 100.7574 - val_reconstruction_loss: 98.9746 - val_kl_loss: 1.7828\n",
      "Epoch 235/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 92.0207 - reconstruction_loss: 90.2453 - kl_loss: 1.8006 - val_loss: 100.3896 - val_reconstruction_loss: 98.6039 - val_kl_loss: 1.7857\n",
      "Epoch 236/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 91.7939 - reconstruction_loss: 89.7656 - kl_loss: 1.8162 - val_loss: 100.5912 - val_reconstruction_loss: 98.7704 - val_kl_loss: 1.8208\n",
      "Epoch 237/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 89.7660 - reconstruction_loss: 87.8543 - kl_loss: 1.8606 - val_loss: 100.4217 - val_reconstruction_loss: 98.5131 - val_kl_loss: 1.9086\n",
      "Epoch 238/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 89.0546 - reconstruction_loss: 88.5142 - kl_loss: 1.9757 - val_loss: 100.7619 - val_reconstruction_loss: 98.8407 - val_kl_loss: 1.9213\n",
      "Epoch 239/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 89.1113 - reconstruction_loss: 86.8770 - kl_loss: 1.9694 - val_loss: 100.5472 - val_reconstruction_loss: 98.6693 - val_kl_loss: 1.8779\n",
      "Epoch 240/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 87.2374 - reconstruction_loss: 85.8431 - kl_loss: 1.9437 - val_loss: 100.2619 - val_reconstruction_loss: 98.3664 - val_kl_loss: 1.8954\n",
      "Epoch 241/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 87.6777 - reconstruction_loss: 84.8157 - kl_loss: 2.0183 - val_loss: 100.2528 - val_reconstruction_loss: 98.2666 - val_kl_loss: 1.9862\n",
      "Epoch 242/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 85.3326 - reconstruction_loss: 84.7746 - kl_loss: 2.0339 - val_loss: 100.6563 - val_reconstruction_loss: 98.7326 - val_kl_loss: 1.9236\n",
      "Epoch 243/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 86.3177 - reconstruction_loss: 84.4411 - kl_loss: 2.0367 - val_loss: 99.9380 - val_reconstruction_loss: 97.9496 - val_kl_loss: 1.9885\n",
      "Epoch 244/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 85.7461 - reconstruction_loss: 83.6132 - kl_loss: 2.0845 - val_loss: 100.9914 - val_reconstruction_loss: 98.8653 - val_kl_loss: 2.1261\n",
      "Epoch 245/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 85.1704 - reconstruction_loss: 89.6098 - kl_loss: 2.8885 - val_loss: 126.8903 - val_reconstruction_loss: 118.0758 - val_kl_loss: 8.8145\n",
      "Epoch 246/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 116.1678 - reconstruction_loss: 106.3020 - kl_loss: 3.7571 - val_loss: 103.3906 - val_reconstruction_loss: 101.4498 - val_kl_loss: 1.9408\n",
      "Epoch 247/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 101.2450 - reconstruction_loss: 98.4779 - kl_loss: 1.7611 - val_loss: 100.7845 - val_reconstruction_loss: 99.1280 - val_kl_loss: 1.6566\n",
      "Epoch 248/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 99.3918 - reconstruction_loss: 102.6688 - kl_loss: 2.3248 - val_loss: 114.6760 - val_reconstruction_loss: 112.0113 - val_kl_loss: 2.6647\n",
      "Epoch 249/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 108.6991 - reconstruction_loss: 103.1965 - kl_loss: 1.6474 - val_loss: 101.1122 - val_reconstruction_loss: 99.6857 - val_kl_loss: 1.4265\n",
      "Epoch 250/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 98.1657 - reconstruction_loss: 96.3892 - kl_loss: 1.5266 - val_loss: 99.7189 - val_reconstruction_loss: 98.1026 - val_kl_loss: 1.6164\n",
      "Epoch 251/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 99.3011 - reconstruction_loss: 102.9997 - kl_loss: 4.9188 - val_loss: 108.8621 - val_reconstruction_loss: 106.1748 - val_kl_loss: 2.6873\n",
      "Epoch 252/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 110.6799 - reconstruction_loss: 111.6724 - kl_loss: 4.9270 - val_loss: 114.7984 - val_reconstruction_loss: 110.8725 - val_kl_loss: 3.9259\n",
      "Epoch 253/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 110.5378 - reconstruction_loss: 105.7520 - kl_loss: 2.4281 - val_loss: 104.4193 - val_reconstruction_loss: 102.7966 - val_kl_loss: 1.6226\n",
      "Epoch 254/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 101.4125 - reconstruction_loss: 99.5017 - kl_loss: 1.5288 - val_loss: 100.5217 - val_reconstruction_loss: 99.0528 - val_kl_loss: 1.4689\n",
      "Epoch 255/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 97.5967 - reconstruction_loss: 95.5455 - kl_loss: 1.4412 - val_loss: 99.3070 - val_reconstruction_loss: 97.7758 - val_kl_loss: 1.5312\n",
      "Epoch 256/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 95.2504 - reconstruction_loss: 93.1114 - kl_loss: 1.5217 - val_loss: 98.5132 - val_reconstruction_loss: 96.9410 - val_kl_loss: 1.5722\n",
      "Epoch 257/1000\n",
      "111/111 [==============================] - 3s 26ms/step - loss: 92.9117 - reconstruction_loss: 91.2029 - kl_loss: 1.5981 - val_loss: 98.7298 - val_reconstruction_loss: 97.1474 - val_kl_loss: 1.5824\n",
      "Epoch 258/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 91.1151 - reconstruction_loss: 89.8221 - kl_loss: 1.6650 - val_loss: 99.6643 - val_reconstruction_loss: 97.8741 - val_kl_loss: 1.7901\n",
      "Epoch 259/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 90.1606 - reconstruction_loss: 88.4173 - kl_loss: 1.7151 - val_loss: 98.5037 - val_reconstruction_loss: 96.7736 - val_kl_loss: 1.7300\n",
      "Epoch 260/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 88.6664 - reconstruction_loss: 87.3823 - kl_loss: 1.7457 - val_loss: 99.0827 - val_reconstruction_loss: 97.2358 - val_kl_loss: 1.8469\n",
      "Epoch 261/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 88.6582 - reconstruction_loss: 88.0642 - kl_loss: 1.9811 - val_loss: 172.2112 - val_reconstruction_loss: 157.6946 - val_kl_loss: 14.5165\n",
      "Epoch 262/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 138.1714 - reconstruction_loss: 119.3076 - kl_loss: 6.1986 - val_loss: 113.3136 - val_reconstruction_loss: 111.2189 - val_kl_loss: 2.0947\n",
      "Epoch 263/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 110.6927 - reconstruction_loss: 107.4712 - kl_loss: 1.5448 - val_loss: 106.1824 - val_reconstruction_loss: 104.9096 - val_kl_loss: 1.2728\n",
      "Epoch 264/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 105.3854 - reconstruction_loss: 106.4548 - kl_loss: 1.9714 - val_loss: 113.8742 - val_reconstruction_loss: 111.2779 - val_kl_loss: 2.5963\n",
      "Epoch 265/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 109.6426 - reconstruction_loss: 109.9438 - kl_loss: 10.6720 - val_loss: 391.6800 - val_reconstruction_loss: 150.1957 - val_kl_loss: 241.4844\n",
      "Epoch 266/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 180.8116 - reconstruction_loss: 125.1362 - kl_loss: 15.9249 - val_loss: 117.9728 - val_reconstruction_loss: 115.9524 - val_kl_loss: 2.0205\n",
      "Epoch 267/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 19ms/step - loss: 116.6286 - reconstruction_loss: 114.0661 - kl_loss: 1.9573 - val_loss: 115.3013 - val_reconstruction_loss: 113.0660 - val_kl_loss: 2.2353\n",
      "Epoch 268/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 113.3083 - reconstruction_loss: 110.3902 - kl_loss: 1.6688 - val_loss: 110.9459 - val_reconstruction_loss: 109.5138 - val_kl_loss: 1.4321\n",
      "Epoch 269/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 109.4654 - reconstruction_loss: 107.9233 - kl_loss: 1.3918 - val_loss: 108.7775 - val_reconstruction_loss: 107.4926 - val_kl_loss: 1.2850\n",
      "Epoch 270/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 108.0893 - reconstruction_loss: 106.4158 - kl_loss: 1.3299 - val_loss: 107.6136 - val_reconstruction_loss: 106.3111 - val_kl_loss: 1.3025\n",
      "Epoch 271/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 107.2067 - reconstruction_loss: 105.3479 - kl_loss: 1.3708 - val_loss: 106.5553 - val_reconstruction_loss: 105.2260 - val_kl_loss: 1.3293\n",
      "Epoch 272/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 105.9599 - reconstruction_loss: 103.8972 - kl_loss: 1.3151 - val_loss: 105.3926 - val_reconstruction_loss: 104.1087 - val_kl_loss: 1.2839\n",
      "Epoch 273/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 104.2664 - reconstruction_loss: 102.8273 - kl_loss: 1.3106 - val_loss: 104.5073 - val_reconstruction_loss: 103.2463 - val_kl_loss: 1.2610\n",
      "Epoch 274/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 103.4799 - reconstruction_loss: 101.9669 - kl_loss: 1.3308 - val_loss: 103.6368 - val_reconstruction_loss: 102.3152 - val_kl_loss: 1.3216\n",
      "Epoch 275/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 102.5717 - reconstruction_loss: 101.0133 - kl_loss: 1.3409 - val_loss: 102.7479 - val_reconstruction_loss: 101.4165 - val_kl_loss: 1.3315\n",
      "Epoch 276/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 101.9456 - reconstruction_loss: 100.2936 - kl_loss: 1.3568 - val_loss: 103.1224 - val_reconstruction_loss: 101.6737 - val_kl_loss: 1.4487\n",
      "Epoch 277/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 101.6441 - reconstruction_loss: 100.0759 - kl_loss: 1.4521 - val_loss: 101.9528 - val_reconstruction_loss: 100.6618 - val_kl_loss: 1.2910\n",
      "Epoch 278/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 100.3163 - reconstruction_loss: 98.7694 - kl_loss: 1.3668 - val_loss: 102.1317 - val_reconstruction_loss: 100.6929 - val_kl_loss: 1.4388\n",
      "Epoch 279/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 99.8768 - reconstruction_loss: 98.1718 - kl_loss: 1.4128 - val_loss: 100.6987 - val_reconstruction_loss: 99.3507 - val_kl_loss: 1.3480\n",
      "Epoch 280/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 98.3207 - reconstruction_loss: 97.2779 - kl_loss: 1.3652 - val_loss: 101.7945 - val_reconstruction_loss: 100.3477 - val_kl_loss: 1.4468\n",
      "Epoch 281/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 98.8881 - reconstruction_loss: 97.7916 - kl_loss: 1.4257 - val_loss: 100.5986 - val_reconstruction_loss: 99.2356 - val_kl_loss: 1.3630\n",
      "Epoch 282/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 97.1647 - reconstruction_loss: 96.4346 - kl_loss: 1.4321 - val_loss: 99.7463 - val_reconstruction_loss: 98.3112 - val_kl_loss: 1.4351\n",
      "Epoch 283/1000\n",
      "111/111 [==============================] - 3s 26ms/step - loss: 96.3880 - reconstruction_loss: 95.6391 - kl_loss: 1.4468 - val_loss: 99.3504 - val_reconstruction_loss: 97.9300 - val_kl_loss: 1.4205\n",
      "Epoch 284/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 96.4918 - reconstruction_loss: 95.0030 - kl_loss: 1.4775 - val_loss: 99.5079 - val_reconstruction_loss: 97.9621 - val_kl_loss: 1.5458\n",
      "Epoch 285/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 96.0678 - reconstruction_loss: 94.4639 - kl_loss: 1.4862 - val_loss: 99.4360 - val_reconstruction_loss: 97.9874 - val_kl_loss: 1.4485\n",
      "Epoch 286/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 95.4338 - reconstruction_loss: 93.8510 - kl_loss: 1.5141 - val_loss: 99.0955 - val_reconstruction_loss: 97.5255 - val_kl_loss: 1.5700\n",
      "Epoch 287/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 94.4343 - reconstruction_loss: 93.4240 - kl_loss: 1.5382 - val_loss: 98.7029 - val_reconstruction_loss: 97.1339 - val_kl_loss: 1.5691\n",
      "Epoch 288/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 94.5117 - reconstruction_loss: 93.0295 - kl_loss: 1.5858 - val_loss: 98.9507 - val_reconstruction_loss: 97.4305 - val_kl_loss: 1.5203\n",
      "Epoch 289/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 94.4933 - reconstruction_loss: 92.6397 - kl_loss: 1.6090 - val_loss: 98.6209 - val_reconstruction_loss: 97.1263 - val_kl_loss: 1.4946\n",
      "Epoch 290/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 93.8447 - reconstruction_loss: 92.3323 - kl_loss: 1.6314 - val_loss: 99.1611 - val_reconstruction_loss: 97.5288 - val_kl_loss: 1.6323\n",
      "Epoch 291/1000\n",
      "111/111 [==============================] - 3s 26ms/step - loss: 94.5903 - reconstruction_loss: 93.2200 - kl_loss: 1.7346 - val_loss: 99.6979 - val_reconstruction_loss: 98.0620 - val_kl_loss: 1.6360\n",
      "Epoch 292/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 92.4452 - reconstruction_loss: 91.0732 - kl_loss: 1.6689 - val_loss: 98.3361 - val_reconstruction_loss: 96.7264 - val_kl_loss: 1.6097\n",
      "Epoch 293/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 91.5203 - reconstruction_loss: 90.4019 - kl_loss: 1.7017 - val_loss: 98.8765 - val_reconstruction_loss: 97.2428 - val_kl_loss: 1.6338\n",
      "Epoch 294/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 92.1465 - reconstruction_loss: 90.5707 - kl_loss: 1.7307 - val_loss: 99.1179 - val_reconstruction_loss: 97.3994 - val_kl_loss: 1.7185\n",
      "Epoch 295/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 91.0253 - reconstruction_loss: 89.4024 - kl_loss: 1.7244 - val_loss: 98.1755 - val_reconstruction_loss: 96.4888 - val_kl_loss: 1.6866\n",
      "Epoch 296/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 91.2995 - reconstruction_loss: 89.1192 - kl_loss: 1.7570 - val_loss: 99.0938 - val_reconstruction_loss: 97.3057 - val_kl_loss: 1.7881\n",
      "Epoch 297/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 90.4636 - reconstruction_loss: 89.4235 - kl_loss: 1.8212 - val_loss: 99.1331 - val_reconstruction_loss: 97.2838 - val_kl_loss: 1.8493\n",
      "Epoch 298/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 90.7135 - reconstruction_loss: 88.4356 - kl_loss: 1.8545 - val_loss: 98.7261 - val_reconstruction_loss: 96.9044 - val_kl_loss: 1.8217\n",
      "Epoch 299/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 88.9523 - reconstruction_loss: 88.2447 - kl_loss: 1.8324 - val_loss: 99.1910 - val_reconstruction_loss: 97.3816 - val_kl_loss: 1.8094\n",
      "Epoch 300/1000\n",
      "111/111 [==============================] - 4s 38ms/step - loss: 98.1391 - reconstruction_loss: 99.6614 - kl_loss: 3.1311 - val_loss: 105.8963 - val_reconstruction_loss: 103.2519 - val_kl_loss: 2.6444\n",
      "Epoch 301/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 99.4772 - reconstruction_loss: 94.6398 - kl_loss: 1.8781 - val_loss: 99.2726 - val_reconstruction_loss: 97.5113 - val_kl_loss: 1.7612\n",
      "Epoch 302/1000\n",
      "111/111 [==============================] - 3s 27ms/step - loss: 91.2956 - reconstruction_loss: 89.7164 - kl_loss: 1.7621 - val_loss: 99.3664 - val_reconstruction_loss: 97.6854 - val_kl_loss: 1.6810\n",
      "Epoch 303/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 90.5918 - reconstruction_loss: 88.2983 - kl_loss: 1.7739 - val_loss: 98.5596 - val_reconstruction_loss: 96.7630 - val_kl_loss: 1.7966\n",
      "Epoch 304/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 89.1224 - reconstruction_loss: 87.2521 - kl_loss: 1.8540 - val_loss: 99.5301 - val_reconstruction_loss: 97.6013 - val_kl_loss: 1.9288\n",
      "Epoch 305/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 89.0036 - reconstruction_loss: 86.8614 - kl_loss: 1.8478 - val_loss: 99.0298 - val_reconstruction_loss: 97.1231 - val_kl_loss: 1.9067\n",
      "Epoch 306/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 87.9632 - reconstruction_loss: 85.9601 - kl_loss: 1.9078 - val_loss: 99.4470 - val_reconstruction_loss: 97.5447 - val_kl_loss: 1.9024\n",
      "Epoch 307/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 88.4434 - reconstruction_loss: 85.7771 - kl_loss: 1.9615 - val_loss: 99.2331 - val_reconstruction_loss: 97.3436 - val_kl_loss: 1.8895\n",
      "Epoch 308/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 86.4442 - reconstruction_loss: 85.2604 - kl_loss: 1.9949 - val_loss: 99.7578 - val_reconstruction_loss: 97.7841 - val_kl_loss: 1.9737\n",
      "Epoch 309/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 86.2058 - reconstruction_loss: 84.8324 - kl_loss: 2.0145 - val_loss: 100.2109 - val_reconstruction_loss: 98.2331 - val_kl_loss: 1.9778\n",
      "Epoch 310/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 88.0826 - reconstruction_loss: 85.7542 - kl_loss: 2.0018 - val_loss: 99.6633 - val_reconstruction_loss: 97.6983 - val_kl_loss: 1.9650\n",
      "Epoch 311/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 85.5931 - reconstruction_loss: 83.8611 - kl_loss: 2.0372 - val_loss: 101.0054 - val_reconstruction_loss: 98.8929 - val_kl_loss: 2.1125\n",
      "Epoch 312/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 92.3585 - reconstruction_loss: 89.9092 - kl_loss: 2.0448 - val_loss: 100.1378 - val_reconstruction_loss: 98.1648 - val_kl_loss: 1.9730\n",
      "Epoch 313/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 86.8191 - reconstruction_loss: 84.8285 - kl_loss: 2.0235 - val_loss: 99.9599 - val_reconstruction_loss: 98.0338 - val_kl_loss: 1.9261\n",
      "Epoch 314/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 85.6183 - reconstruction_loss: 84.1455 - kl_loss: 2.0287 - val_loss: 100.2796 - val_reconstruction_loss: 98.2300 - val_kl_loss: 2.0496\n",
      "Epoch 315/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 85.0172 - reconstruction_loss: 82.8851 - kl_loss: 2.0912 - val_loss: 99.9893 - val_reconstruction_loss: 98.0349 - val_kl_loss: 1.9545\n",
      "Epoch 316/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 84.3020 - reconstruction_loss: 82.6266 - kl_loss: 2.1394 - val_loss: 101.9377 - val_reconstruction_loss: 99.8321 - val_kl_loss: 2.1056\n",
      "Epoch 317/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 85.3763 - reconstruction_loss: 84.6295 - kl_loss: 2.2108 - val_loss: 100.4990 - val_reconstruction_loss: 98.4196 - val_kl_loss: 2.0794\n",
      "Epoch 318/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 85.4552 - reconstruction_loss: 83.3237 - kl_loss: 2.1693 - val_loss: 101.3556 - val_reconstruction_loss: 99.2106 - val_kl_loss: 2.1450\n",
      "Epoch 319/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 83.9246 - reconstruction_loss: 81.9006 - kl_loss: 2.1519 - val_loss: 101.6585 - val_reconstruction_loss: 99.5437 - val_kl_loss: 2.1147\n",
      "Epoch 320/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 83.2602 - reconstruction_loss: 81.2975 - kl_loss: 2.2137 - val_loss: 103.0321 - val_reconstruction_loss: 100.7857 - val_kl_loss: 2.2464\n",
      "Epoch 321/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 84.6103 - reconstruction_loss: 81.5294 - kl_loss: 2.2453 - val_loss: 101.2660 - val_reconstruction_loss: 99.1533 - val_kl_loss: 2.1127\n",
      "Epoch 322/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 82.4406 - reconstruction_loss: 80.6922 - kl_loss: 2.2901 - val_loss: 101.9129 - val_reconstruction_loss: 99.5929 - val_kl_loss: 2.3201\n",
      "Epoch 323/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 82.6423 - reconstruction_loss: 80.9659 - kl_loss: 2.3175 - val_loss: 101.9322 - val_reconstruction_loss: 99.6982 - val_kl_loss: 2.2341\n",
      "Epoch 324/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 82.0449 - reconstruction_loss: 80.1271 - kl_loss: 2.3095 - val_loss: 102.4751 - val_reconstruction_loss: 100.2231 - val_kl_loss: 2.2520\n",
      "Epoch 325/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 82.3778 - reconstruction_loss: 80.6616 - kl_loss: 2.3609 - val_loss: 104.1709 - val_reconstruction_loss: 101.7821 - val_kl_loss: 2.3889\n",
      "Epoch 326/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 82.7391 - reconstruction_loss: 80.6152 - kl_loss: 2.3324 - val_loss: 104.2399 - val_reconstruction_loss: 101.7906 - val_kl_loss: 2.4493\n",
      "Epoch 327/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 82.6346 - reconstruction_loss: 79.7038 - kl_loss: 2.3682 - val_loss: 102.9608 - val_reconstruction_loss: 100.6586 - val_kl_loss: 2.3023\n",
      "Epoch 328/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 81.3563 - reconstruction_loss: 78.9109 - kl_loss: 2.3525 - val_loss: 103.3575 - val_reconstruction_loss: 100.9849 - val_kl_loss: 2.3726\n",
      "Epoch 329/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 79.9002 - reconstruction_loss: 78.6463 - kl_loss: 2.4209 - val_loss: 104.5106 - val_reconstruction_loss: 101.9437 - val_kl_loss: 2.5668\n",
      "Epoch 330/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 82.7124 - reconstruction_loss: 80.9716 - kl_loss: 2.4822 - val_loss: 104.8309 - val_reconstruction_loss: 102.3564 - val_kl_loss: 2.4745\n",
      "Epoch 331/1000\n",
      "111/111 [==============================] - 3s 29ms/step - loss: 82.4455 - reconstruction_loss: 79.9496 - kl_loss: 2.4834 - val_loss: 104.7878 - val_reconstruction_loss: 102.4454 - val_kl_loss: 2.3424\n",
      "Epoch 332/1000\n",
      "111/111 [==============================] - 3s 28ms/step - loss: 81.0569 - reconstruction_loss: 78.9830 - kl_loss: 2.4810 - val_loss: 103.6785 - val_reconstruction_loss: 101.3181 - val_kl_loss: 2.3605\n",
      "Epoch 333/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 88.3565 - reconstruction_loss: 88.1210 - kl_loss: 2.4481 - val_loss: 102.1298 - val_reconstruction_loss: 99.9337 - val_kl_loss: 2.1960\n",
      "Epoch 334/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 83.2611 - reconstruction_loss: 81.1903 - kl_loss: 2.4007 - val_loss: 115.5237 - val_reconstruction_loss: 111.2307 - val_kl_loss: 4.2929\n",
      "Epoch 335/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 97.7398 - reconstruction_loss: 89.8030 - kl_loss: 2.5443 - val_loss: 102.9461 - val_reconstruction_loss: 100.7419 - val_kl_loss: 2.2042\n",
      "Epoch 336/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 83.0869 - reconstruction_loss: 81.2230 - kl_loss: 2.3244 - val_loss: 102.7403 - val_reconstruction_loss: 100.4741 - val_kl_loss: 2.2662\n",
      "Epoch 337/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 81.9361 - reconstruction_loss: 79.1495 - kl_loss: 2.3534 - val_loss: 107.8733 - val_reconstruction_loss: 105.3735 - val_kl_loss: 2.4999\n",
      "Epoch 338/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 89.5208 - reconstruction_loss: 82.7857 - kl_loss: 2.5083 - val_loss: 102.3170 - val_reconstruction_loss: 99.9058 - val_kl_loss: 2.4112\n",
      "Epoch 339/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 80.9347 - reconstruction_loss: 78.2138 - kl_loss: 2.4358 - val_loss: 103.5390 - val_reconstruction_loss: 101.1488 - val_kl_loss: 2.3902\n",
      "Epoch 340/1000\n",
      "111/111 [==============================] - 3s 26ms/step - loss: 79.2994 - reconstruction_loss: 77.0674 - kl_loss: 2.5154 - val_loss: 105.2049 - val_reconstruction_loss: 102.7641 - val_kl_loss: 2.4408\n",
      "Epoch 341/1000\n",
      "111/111 [==============================] - 3s 27ms/step - loss: 79.3763 - reconstruction_loss: 76.9450 - kl_loss: 2.5190 - val_loss: 105.8287 - val_reconstruction_loss: 103.2104 - val_kl_loss: 2.6183\n",
      "Epoch 342/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 81.3495 - reconstruction_loss: 87.4681 - kl_loss: 4.8518 - val_loss: 124.8425 - val_reconstruction_loss: 116.4722 - val_kl_loss: 8.3703\n",
      "Epoch 343/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 20ms/step - loss: 112.8185 - reconstruction_loss: 103.3306 - kl_loss: 2.6000 - val_loss: 104.2162 - val_reconstruction_loss: 102.4070 - val_kl_loss: 1.8092\n",
      "Epoch 344/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 95.0840 - reconstruction_loss: 91.5522 - kl_loss: 1.9619 - val_loss: 103.1463 - val_reconstruction_loss: 101.0436 - val_kl_loss: 2.1027\n",
      "Epoch 345/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 90.0207 - reconstruction_loss: 86.9223 - kl_loss: 2.1837 - val_loss: 102.2305 - val_reconstruction_loss: 100.0178 - val_kl_loss: 2.2127\n",
      "Epoch 346/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 85.5199 - reconstruction_loss: 82.5766 - kl_loss: 2.3432 - val_loss: 104.7258 - val_reconstruction_loss: 102.3282 - val_kl_loss: 2.3976\n",
      "Epoch 347/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 105.5407 - reconstruction_loss: 110.2223 - kl_loss: 8.1117 - val_loss: 118.6473 - val_reconstruction_loss: 114.7445 - val_kl_loss: 3.9027\n",
      "Epoch 348/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 114.0448 - reconstruction_loss: 107.5999 - kl_loss: 2.6067 - val_loss: 106.4354 - val_reconstruction_loss: 104.8930 - val_kl_loss: 1.5424\n",
      "Epoch 349/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 133.5169 - reconstruction_loss: 120.8077 - kl_loss: 22.3000 - val_loss: 119.4365 - val_reconstruction_loss: 118.0066 - val_kl_loss: 1.4299\n",
      "Epoch 350/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 116.9620 - reconstruction_loss: 114.3486 - kl_loss: 1.2878 - val_loss: 113.1399 - val_reconstruction_loss: 111.9179 - val_kl_loss: 1.2220\n",
      "Epoch 351/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 111.6190 - reconstruction_loss: 109.5009 - kl_loss: 1.1494 - val_loss: 109.3074 - val_reconstruction_loss: 108.2446 - val_kl_loss: 1.0629\n",
      "Epoch 352/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 108.2475 - reconstruction_loss: 106.1866 - kl_loss: 1.1786 - val_loss: 106.7290 - val_reconstruction_loss: 105.6828 - val_kl_loss: 1.0462\n",
      "Epoch 353/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 104.7043 - reconstruction_loss: 103.3719 - kl_loss: 1.2076 - val_loss: 104.1147 - val_reconstruction_loss: 102.8966 - val_kl_loss: 1.2181\n",
      "Epoch 354/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 103.1182 - reconstruction_loss: 101.2596 - kl_loss: 1.2242 - val_loss: 103.2905 - val_reconstruction_loss: 102.1067 - val_kl_loss: 1.1838\n",
      "Epoch 355/1000\n",
      "111/111 [==============================] - 2s 23ms/step - loss: 100.8517 - reconstruction_loss: 99.5906 - kl_loss: 1.2795 - val_loss: 102.6187 - val_reconstruction_loss: 101.3177 - val_kl_loss: 1.3009\n",
      "Epoch 356/1000\n",
      "111/111 [==============================] - 3s 28ms/step - loss: 99.6616 - reconstruction_loss: 98.0823 - kl_loss: 1.3584 - val_loss: 101.1315 - val_reconstruction_loss: 99.8193 - val_kl_loss: 1.3122\n",
      "Epoch 357/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 97.2948 - reconstruction_loss: 96.5103 - kl_loss: 1.3761 - val_loss: 101.9479 - val_reconstruction_loss: 100.5576 - val_kl_loss: 1.3903\n",
      "Epoch 358/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 97.1779 - reconstruction_loss: 95.9331 - kl_loss: 1.4841 - val_loss: 101.4678 - val_reconstruction_loss: 99.9808 - val_kl_loss: 1.4870\n",
      "Epoch 359/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 95.9401 - reconstruction_loss: 94.2193 - kl_loss: 1.4936 - val_loss: 101.5657 - val_reconstruction_loss: 100.0628 - val_kl_loss: 1.5029\n",
      "Epoch 360/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 94.7230 - reconstruction_loss: 93.0039 - kl_loss: 1.5787 - val_loss: 101.1193 - val_reconstruction_loss: 99.4901 - val_kl_loss: 1.6293\n",
      "Epoch 361/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 93.1057 - reconstruction_loss: 91.4832 - kl_loss: 1.6779 - val_loss: 100.6898 - val_reconstruction_loss: 98.9408 - val_kl_loss: 1.7490\n",
      "Epoch 362/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 91.7503 - reconstruction_loss: 90.2390 - kl_loss: 1.7583 - val_loss: 102.3493 - val_reconstruction_loss: 100.3854 - val_kl_loss: 1.9639\n",
      "Epoch 363/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 91.2483 - reconstruction_loss: 89.7721 - kl_loss: 1.8757 - val_loss: 101.0946 - val_reconstruction_loss: 99.3463 - val_kl_loss: 1.7483\n",
      "Epoch 364/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 91.7794 - reconstruction_loss: 91.7137 - kl_loss: 1.9935 - val_loss: 101.5576 - val_reconstruction_loss: 99.5535 - val_kl_loss: 2.0041\n",
      "Epoch 365/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 89.8367 - reconstruction_loss: 87.9169 - kl_loss: 1.9176 - val_loss: 101.3198 - val_reconstruction_loss: 99.4509 - val_kl_loss: 1.8689\n",
      "Epoch 366/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 88.6757 - reconstruction_loss: 86.4932 - kl_loss: 1.9935 - val_loss: 101.5767 - val_reconstruction_loss: 99.5449 - val_kl_loss: 2.0318\n",
      "Epoch 367/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 86.8934 - reconstruction_loss: 85.6901 - kl_loss: 2.0357 - val_loss: 101.0942 - val_reconstruction_loss: 99.0889 - val_kl_loss: 2.0052\n",
      "Epoch 368/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 85.8573 - reconstruction_loss: 84.4524 - kl_loss: 2.0809 - val_loss: 102.4855 - val_reconstruction_loss: 100.3991 - val_kl_loss: 2.0864\n",
      "Epoch 369/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 86.0373 - reconstruction_loss: 84.6049 - kl_loss: 2.1308 - val_loss: 101.7876 - val_reconstruction_loss: 99.8839 - val_kl_loss: 1.9037\n",
      "Epoch 370/1000\n",
      "111/111 [==============================] - 3s 30ms/step - loss: 88.4136 - reconstruction_loss: 86.4247 - kl_loss: 2.2399 - val_loss: 108.6976 - val_reconstruction_loss: 106.1965 - val_kl_loss: 2.5010\n",
      "Epoch 371/1000\n",
      "111/111 [==============================] - 3s 30ms/step - loss: 91.0508 - reconstruction_loss: 86.8448 - kl_loss: 2.2401 - val_loss: 103.0742 - val_reconstruction_loss: 100.9575 - val_kl_loss: 2.1167\n",
      "Epoch 372/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 85.6642 - reconstruction_loss: 83.2833 - kl_loss: 2.2347 - val_loss: 102.7285 - val_reconstruction_loss: 100.5161 - val_kl_loss: 2.2124\n",
      "Epoch 373/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 83.8904 - reconstruction_loss: 81.6789 - kl_loss: 2.2409 - val_loss: 102.4774 - val_reconstruction_loss: 100.3016 - val_kl_loss: 2.1758\n",
      "Epoch 374/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 83.7234 - reconstruction_loss: 82.6044 - kl_loss: 2.3019 - val_loss: 104.0398 - val_reconstruction_loss: 101.3830 - val_kl_loss: 2.6567\n",
      "Epoch 375/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 87.1396 - reconstruction_loss: 82.7710 - kl_loss: 2.3454 - val_loss: 103.2199 - val_reconstruction_loss: 100.9950 - val_kl_loss: 2.2249\n",
      "Epoch 376/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 83.0268 - reconstruction_loss: 81.5082 - kl_loss: 2.2885 - val_loss: 103.5715 - val_reconstruction_loss: 101.2172 - val_kl_loss: 2.3543\n",
      "Epoch 377/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 82.1412 - reconstruction_loss: 80.6837 - kl_loss: 2.3432 - val_loss: 104.4245 - val_reconstruction_loss: 101.9706 - val_kl_loss: 2.4540\n",
      "Epoch 378/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 81.2804 - reconstruction_loss: 79.7099 - kl_loss: 2.4262 - val_loss: 105.4878 - val_reconstruction_loss: 103.0207 - val_kl_loss: 2.4672\n",
      "Epoch 379/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 81.3962 - reconstruction_loss: 79.2601 - kl_loss: 2.4097 - val_loss: 103.8309 - val_reconstruction_loss: 101.4425 - val_kl_loss: 2.3884\n",
      "Epoch 380/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 80.8389 - reconstruction_loss: 78.7414 - kl_loss: 2.4300 - val_loss: 104.6353 - val_reconstruction_loss: 102.1707 - val_kl_loss: 2.4647\n",
      "Epoch 381/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 80.3061 - reconstruction_loss: 78.1356 - kl_loss: 2.4654 - val_loss: 105.0862 - val_reconstruction_loss: 102.6151 - val_kl_loss: 2.4710\n",
      "Epoch 382/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 81.1260 - reconstruction_loss: 78.6305 - kl_loss: 2.5249 - val_loss: 105.0661 - val_reconstruction_loss: 102.5345 - val_kl_loss: 2.5316\n",
      "Epoch 383/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 80.2651 - reconstruction_loss: 77.5727 - kl_loss: 2.5225 - val_loss: 107.4864 - val_reconstruction_loss: 104.8321 - val_kl_loss: 2.6543\n",
      "Epoch 384/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 78.9360 - reconstruction_loss: 76.5641 - kl_loss: 2.5509 - val_loss: 107.2768 - val_reconstruction_loss: 104.7351 - val_kl_loss: 2.5417\n",
      "Epoch 385/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 79.1150 - reconstruction_loss: 76.7598 - kl_loss: 2.5879 - val_loss: 105.2246 - val_reconstruction_loss: 102.7073 - val_kl_loss: 2.5173\n",
      "Epoch 386/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 79.1033 - reconstruction_loss: 76.9094 - kl_loss: 2.6710 - val_loss: 106.8861 - val_reconstruction_loss: 104.1926 - val_kl_loss: 2.6936\n",
      "Epoch 387/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 78.4542 - reconstruction_loss: 76.3062 - kl_loss: 2.6464 - val_loss: 105.0585 - val_reconstruction_loss: 102.5532 - val_kl_loss: 2.5053\n",
      "Epoch 388/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 78.1475 - reconstruction_loss: 75.8475 - kl_loss: 2.6545 - val_loss: 107.1399 - val_reconstruction_loss: 104.4625 - val_kl_loss: 2.6773\n",
      "Epoch 389/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 94.5900 - reconstruction_loss: 94.9379 - kl_loss: 2.6667 - val_loss: 103.6194 - val_reconstruction_loss: 101.3553 - val_kl_loss: 2.2641\n",
      "Epoch 390/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 89.1630 - reconstruction_loss: 85.5422 - kl_loss: 2.3416 - val_loss: 103.4379 - val_reconstruction_loss: 101.1075 - val_kl_loss: 2.3304\n",
      "Epoch 391/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 84.2643 - reconstruction_loss: 81.2891 - kl_loss: 2.5148 - val_loss: 106.2624 - val_reconstruction_loss: 103.7104 - val_kl_loss: 2.5520\n",
      "Epoch 392/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 82.8930 - reconstruction_loss: 80.0695 - kl_loss: 2.5723 - val_loss: 105.7098 - val_reconstruction_loss: 103.1721 - val_kl_loss: 2.5377\n",
      "Epoch 393/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 84.5523 - reconstruction_loss: 80.8472 - kl_loss: 2.6258 - val_loss: 105.3607 - val_reconstruction_loss: 102.8793 - val_kl_loss: 2.4813\n",
      "Epoch 394/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 89.0318 - reconstruction_loss: 87.5643 - kl_loss: 2.5524 - val_loss: 106.5969 - val_reconstruction_loss: 103.9490 - val_kl_loss: 2.6479\n",
      "Epoch 395/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 83.1880 - reconstruction_loss: 80.6177 - kl_loss: 2.6296 - val_loss: 105.4655 - val_reconstruction_loss: 102.8849 - val_kl_loss: 2.5806\n",
      "Epoch 396/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 82.7193 - reconstruction_loss: 79.9531 - kl_loss: 2.6378 - val_loss: 106.1797 - val_reconstruction_loss: 103.5555 - val_kl_loss: 2.6242\n",
      "Epoch 397/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 78.1402 - reconstruction_loss: 75.9075 - kl_loss: 2.6250 - val_loss: 106.5723 - val_reconstruction_loss: 104.0633 - val_kl_loss: 2.5090\n",
      "Epoch 398/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 79.4106 - reconstruction_loss: 79.3692 - kl_loss: 2.6994 - val_loss: 106.5097 - val_reconstruction_loss: 103.8195 - val_kl_loss: 2.6902\n",
      "Epoch 399/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 78.5541 - reconstruction_loss: 75.8966 - kl_loss: 2.6730 - val_loss: 107.4003 - val_reconstruction_loss: 104.6441 - val_kl_loss: 2.7563\n",
      "Epoch 400/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 76.4268 - reconstruction_loss: 75.6070 - kl_loss: 2.7308 - val_loss: 105.3394 - val_reconstruction_loss: 102.7513 - val_kl_loss: 2.5881\n",
      "Epoch 401/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 79.6675 - reconstruction_loss: 75.2550 - kl_loss: 2.7094 - val_loss: 106.9861 - val_reconstruction_loss: 104.2574 - val_kl_loss: 2.7287\n",
      "Epoch 402/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 85.7271 - reconstruction_loss: 79.0037 - kl_loss: 2.9245 - val_loss: 107.5717 - val_reconstruction_loss: 104.6710 - val_kl_loss: 2.9007\n",
      "Epoch 403/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 75.8204 - reconstruction_loss: 74.3541 - kl_loss: 2.7665 - val_loss: 108.4215 - val_reconstruction_loss: 105.4980 - val_kl_loss: 2.9235\n",
      "Epoch 404/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 76.4184 - reconstruction_loss: 73.4931 - kl_loss: 2.7376 - val_loss: 107.3700 - val_reconstruction_loss: 104.6577 - val_kl_loss: 2.7123\n",
      "Epoch 405/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 74.8198 - reconstruction_loss: 72.1610 - kl_loss: 2.7508 - val_loss: 107.8733 - val_reconstruction_loss: 105.1165 - val_kl_loss: 2.7569\n",
      "Epoch 406/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 74.3816 - reconstruction_loss: 72.2167 - kl_loss: 2.7403 - val_loss: 107.5772 - val_reconstruction_loss: 104.7268 - val_kl_loss: 2.8504\n",
      "Epoch 407/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 74.8502 - reconstruction_loss: 74.7369 - kl_loss: 2.8874 - val_loss: 108.3670 - val_reconstruction_loss: 105.2109 - val_kl_loss: 3.1561\n",
      "Epoch 408/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 86.4473 - reconstruction_loss: 79.8842 - kl_loss: 2.8526 - val_loss: 107.7125 - val_reconstruction_loss: 104.8832 - val_kl_loss: 2.8293\n",
      "Epoch 409/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 79.3183 - reconstruction_loss: 80.9767 - kl_loss: 3.2194 - val_loss: 122.1307 - val_reconstruction_loss: 114.9832 - val_kl_loss: 7.1475\n",
      "Epoch 410/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 104.5231 - reconstruction_loss: 93.0679 - kl_loss: 2.9196 - val_loss: 104.5510 - val_reconstruction_loss: 102.0959 - val_kl_loss: 2.4551\n",
      "Epoch 411/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 81.4060 - reconstruction_loss: 78.6105 - kl_loss: 2.5833 - val_loss: 107.1271 - val_reconstruction_loss: 104.3697 - val_kl_loss: 2.7574\n",
      "Epoch 412/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 79.3660 - reconstruction_loss: 78.2958 - kl_loss: 2.6529 - val_loss: 106.3906 - val_reconstruction_loss: 103.8245 - val_kl_loss: 2.5662\n",
      "Epoch 413/1000\n",
      "111/111 [==============================] - 3s 26ms/step - loss: 77.9205 - reconstruction_loss: 74.7349 - kl_loss: 2.6775 - val_loss: 107.4674 - val_reconstruction_loss: 104.7803 - val_kl_loss: 2.6870\n",
      "Epoch 414/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 75.0910 - reconstruction_loss: 72.3152 - kl_loss: 2.7699 - val_loss: 109.1187 - val_reconstruction_loss: 106.3079 - val_kl_loss: 2.8108\n",
      "Epoch 415/1000\n",
      "111/111 [==============================] - 3s 26ms/step - loss: 74.9775 - reconstruction_loss: 71.6892 - kl_loss: 2.7623 - val_loss: 109.4047 - val_reconstruction_loss: 106.6939 - val_kl_loss: 2.7109\n",
      "Epoch 416/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 73.3761 - reconstruction_loss: 71.5491 - kl_loss: 2.8135 - val_loss: 109.9570 - val_reconstruction_loss: 107.0516 - val_kl_loss: 2.9054\n",
      "Epoch 417/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 72.2965 - reconstruction_loss: 70.3190 - kl_loss: 2.8441 - val_loss: 109.0189 - val_reconstruction_loss: 106.1902 - val_kl_loss: 2.8288\n",
      "Epoch 418/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 71.6445 - reconstruction_loss: 69.8774 - kl_loss: 2.8500 - val_loss: 110.3320 - val_reconstruction_loss: 107.4482 - val_kl_loss: 2.8837\n",
      "Epoch 419/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 19ms/step - loss: 73.0040 - reconstruction_loss: 71.1083 - kl_loss: 2.8627 - val_loss: 109.7438 - val_reconstruction_loss: 107.0494 - val_kl_loss: 2.6944\n",
      "Epoch 420/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 73.1616 - reconstruction_loss: 70.1209 - kl_loss: 2.8619 - val_loss: 111.9443 - val_reconstruction_loss: 108.9788 - val_kl_loss: 2.9655\n",
      "Epoch 421/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 71.5876 - reconstruction_loss: 68.9577 - kl_loss: 2.9208 - val_loss: 110.5594 - val_reconstruction_loss: 107.6516 - val_kl_loss: 2.9078\n",
      "Epoch 422/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 71.3417 - reconstruction_loss: 74.9685 - kl_loss: 3.7581 - val_loss: 148.7545 - val_reconstruction_loss: 129.1980 - val_kl_loss: 19.5566\n",
      "Epoch 423/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 121.2505 - reconstruction_loss: 105.4703 - kl_loss: 5.2242 - val_loss: 102.1421 - val_reconstruction_loss: 100.0116 - val_kl_loss: 2.1305\n",
      "Epoch 424/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 92.0906 - reconstruction_loss: 87.4425 - kl_loss: 2.3010 - val_loss: 110.5450 - val_reconstruction_loss: 107.5785 - val_kl_loss: 2.9666\n",
      "Epoch 425/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 85.0209 - reconstruction_loss: 81.0102 - kl_loss: 2.6542 - val_loss: 107.6364 - val_reconstruction_loss: 104.9636 - val_kl_loss: 2.6727\n",
      "Epoch 426/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 78.9335 - reconstruction_loss: 76.0440 - kl_loss: 2.7025 - val_loss: 108.0704 - val_reconstruction_loss: 105.4378 - val_kl_loss: 2.6326\n",
      "Epoch 427/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 75.3187 - reconstruction_loss: 72.1445 - kl_loss: 2.7678 - val_loss: 108.9375 - val_reconstruction_loss: 106.1467 - val_kl_loss: 2.7908\n",
      "Epoch 428/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 73.0371 - reconstruction_loss: 70.4871 - kl_loss: 2.8041 - val_loss: 109.6871 - val_reconstruction_loss: 106.8541 - val_kl_loss: 2.8330\n",
      "Epoch 429/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 71.8071 - reconstruction_loss: 69.8548 - kl_loss: 2.8536 - val_loss: 110.2648 - val_reconstruction_loss: 107.3732 - val_kl_loss: 2.8916\n",
      "Epoch 430/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 71.8131 - reconstruction_loss: 69.3597 - kl_loss: 2.8704 - val_loss: 111.4057 - val_reconstruction_loss: 108.5009 - val_kl_loss: 2.9049\n",
      "Epoch 431/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 71.2801 - reconstruction_loss: 68.8428 - kl_loss: 2.9045 - val_loss: 111.4393 - val_reconstruction_loss: 108.5252 - val_kl_loss: 2.9141\n",
      "Epoch 432/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 71.0169 - reconstruction_loss: 68.3623 - kl_loss: 2.9560 - val_loss: 112.7975 - val_reconstruction_loss: 109.7216 - val_kl_loss: 3.0759\n",
      "Epoch 433/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 70.6916 - reconstruction_loss: 68.7274 - kl_loss: 2.9735 - val_loss: 121.7732 - val_reconstruction_loss: 117.8846 - val_kl_loss: 3.8887\n",
      "Epoch 434/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 81.5930 - reconstruction_loss: 79.8768 - kl_loss: 3.3607 - val_loss: 108.5070 - val_reconstruction_loss: 105.3426 - val_kl_loss: 3.1644\n",
      "Epoch 435/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 76.4347 - reconstruction_loss: 71.8316 - kl_loss: 3.0120 - val_loss: 110.8912 - val_reconstruction_loss: 107.9177 - val_kl_loss: 2.9734\n",
      "Epoch 436/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 71.4199 - reconstruction_loss: 68.4803 - kl_loss: 2.9694 - val_loss: 111.3678 - val_reconstruction_loss: 108.4289 - val_kl_loss: 2.9389\n",
      "Epoch 437/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 76.6786 - reconstruction_loss: 78.6963 - kl_loss: 3.0867 - val_loss: 109.0082 - val_reconstruction_loss: 106.0819 - val_kl_loss: 2.9263\n",
      "Epoch 438/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 79.4086 - reconstruction_loss: 76.7242 - kl_loss: 3.0606 - val_loss: 109.9314 - val_reconstruction_loss: 107.0542 - val_kl_loss: 2.8773\n",
      "Epoch 439/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 72.5922 - reconstruction_loss: 69.7612 - kl_loss: 2.9448 - val_loss: 110.1175 - val_reconstruction_loss: 107.2330 - val_kl_loss: 2.8844\n",
      "Epoch 440/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 70.4516 - reconstruction_loss: 68.3929 - kl_loss: 2.9279 - val_loss: 114.2800 - val_reconstruction_loss: 111.2062 - val_kl_loss: 3.0738\n",
      "Epoch 441/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 73.3657 - reconstruction_loss: 68.9461 - kl_loss: 2.9754 - val_loss: 111.8728 - val_reconstruction_loss: 108.9359 - val_kl_loss: 2.9369\n",
      "Epoch 442/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 70.7294 - reconstruction_loss: 68.1976 - kl_loss: 2.9497 - val_loss: 112.4674 - val_reconstruction_loss: 109.4871 - val_kl_loss: 2.9803\n",
      "Epoch 443/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 69.9383 - reconstruction_loss: 70.3208 - kl_loss: 3.1265 - val_loss: 112.3167 - val_reconstruction_loss: 109.0509 - val_kl_loss: 3.2659\n",
      "Epoch 444/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 72.9753 - reconstruction_loss: 68.4712 - kl_loss: 3.0968 - val_loss: 112.1406 - val_reconstruction_loss: 109.0870 - val_kl_loss: 3.0536\n",
      "Epoch 445/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 70.3701 - reconstruction_loss: 66.6965 - kl_loss: 3.0363 - val_loss: 111.6433 - val_reconstruction_loss: 108.7522 - val_kl_loss: 2.8910\n",
      "Epoch 446/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 82.2887 - reconstruction_loss: 79.3618 - kl_loss: 3.2564 - val_loss: 110.9173 - val_reconstruction_loss: 107.8946 - val_kl_loss: 3.0228\n",
      "Epoch 447/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 77.4625 - reconstruction_loss: 72.0631 - kl_loss: 3.1783 - val_loss: 110.1506 - val_reconstruction_loss: 107.2335 - val_kl_loss: 2.9170\n",
      "Epoch 448/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 70.7107 - reconstruction_loss: 68.0808 - kl_loss: 3.0380 - val_loss: 113.5743 - val_reconstruction_loss: 110.2746 - val_kl_loss: 3.2997\n",
      "Epoch 449/1000\n",
      "111/111 [==============================] - 3s 29ms/step - loss: 71.6146 - reconstruction_loss: 67.8063 - kl_loss: 3.0466 - val_loss: 112.4928 - val_reconstruction_loss: 109.5231 - val_kl_loss: 2.9697\n",
      "Epoch 450/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 69.8320 - reconstruction_loss: 71.8254 - kl_loss: 3.0805 - val_loss: 109.7185 - val_reconstruction_loss: 106.9013 - val_kl_loss: 2.8172\n",
      "Epoch 451/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 72.2488 - reconstruction_loss: 68.2808 - kl_loss: 3.0039 - val_loss: 112.3100 - val_reconstruction_loss: 109.4235 - val_kl_loss: 2.8865\n",
      "Epoch 452/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 68.6798 - reconstruction_loss: 65.6300 - kl_loss: 3.0363 - val_loss: 112.8425 - val_reconstruction_loss: 109.7997 - val_kl_loss: 3.0428\n",
      "Epoch 453/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 67.4665 - reconstruction_loss: 64.6968 - kl_loss: 3.0718 - val_loss: 114.2214 - val_reconstruction_loss: 111.0918 - val_kl_loss: 3.1297\n",
      "Epoch 454/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 66.8094 - reconstruction_loss: 63.9065 - kl_loss: 3.0619 - val_loss: 114.5739 - val_reconstruction_loss: 111.4789 - val_kl_loss: 3.0950\n",
      "Epoch 455/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 66.6742 - reconstruction_loss: 64.1342 - kl_loss: 3.1056 - val_loss: 114.5817 - val_reconstruction_loss: 111.4514 - val_kl_loss: 3.1303\n",
      "Epoch 456/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 65.9981 - reconstruction_loss: 63.5776 - kl_loss: 3.1371 - val_loss: 114.0078 - val_reconstruction_loss: 110.9289 - val_kl_loss: 3.0789\n",
      "Epoch 457/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 65.9591 - reconstruction_loss: 63.7250 - kl_loss: 3.1189 - val_loss: 115.9483 - val_reconstruction_loss: 112.7362 - val_kl_loss: 3.2121\n",
      "Epoch 458/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 128.7275 - reconstruction_loss: 134.0053 - kl_loss: 224.0586 - val_loss: 564.8698 - val_reconstruction_loss: 214.9317 - val_kl_loss: 349.9381\n",
      "Epoch 459/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 825.9397 - reconstruction_loss: 286.5532 - kl_loss: 1295.0366 - val_loss: 3131.7876 - val_reconstruction_loss: 200.3616 - val_kl_loss: 2931.4258\n",
      "Epoch 460/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 2598.1832 - reconstruction_loss: 180.8105 - kl_loss: 2269.9702 - val_loss: 2329.7776 - val_reconstruction_loss: 157.8051 - val_kl_loss: 2171.9729\n",
      "Epoch 461/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 2273.0809 - reconstruction_loss: 154.0306 - kl_loss: 2097.7380 - val_loss: 2238.8269 - val_reconstruction_loss: 151.3151 - val_kl_loss: 2087.5115\n",
      "Epoch 462/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 2176.1639 - reconstruction_loss: 150.1325 - kl_loss: 2007.2621 - val_loss: 2140.9832 - val_reconstruction_loss: 147.0218 - val_kl_loss: 1993.9611\n",
      "Epoch 463/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 2105.9351 - reconstruction_loss: 146.6718 - kl_loss: 1950.8517 - val_loss: 2108.8123 - val_reconstruction_loss: 144.0327 - val_kl_loss: 1964.7792\n",
      "Epoch 464/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 2077.0616 - reconstruction_loss: 141.5809 - kl_loss: 1909.4896 - val_loss: 2044.2333 - val_reconstruction_loss: 141.8493 - val_kl_loss: 1902.3840\n",
      "Epoch 465/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 1993.3073 - reconstruction_loss: 139.7454 - kl_loss: 1824.5509 - val_loss: 1935.7010 - val_reconstruction_loss: 137.9519 - val_kl_loss: 1797.7489\n",
      "Epoch 466/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 1899.2549 - reconstruction_loss: 138.0480 - kl_loss: 1752.6816 - val_loss: 1879.5693 - val_reconstruction_loss: 137.5086 - val_kl_loss: 1742.0607\n",
      "Epoch 467/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 1835.8272 - reconstruction_loss: 137.4308 - kl_loss: 1685.5516 - val_loss: 1799.4578 - val_reconstruction_loss: 137.1364 - val_kl_loss: 1662.3214\n",
      "Epoch 468/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 1771.9437 - reconstruction_loss: 136.5074 - kl_loss: 1602.0652 - val_loss: 1714.5992 - val_reconstruction_loss: 135.9208 - val_kl_loss: 1578.6781\n",
      "Epoch 469/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 1680.2087 - reconstruction_loss: 141.0854 - kl_loss: 1608.3928 - val_loss: 1912.4545 - val_reconstruction_loss: 140.7017 - val_kl_loss: 1771.7527\n",
      "Epoch 470/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 1897.7320 - reconstruction_loss: 138.0516 - kl_loss: 1754.1106 - val_loss: 1884.2350 - val_reconstruction_loss: 136.7924 - val_kl_loss: 1747.4421\n",
      "Epoch 471/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 1878.0446 - reconstruction_loss: 135.6868 - kl_loss: 1742.0684 - val_loss: 1867.0071 - val_reconstruction_loss: 134.3597 - val_kl_loss: 1732.6475\n",
      "Epoch 472/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 1903.3491 - reconstruction_loss: 155.6109 - kl_loss: 1932.3243 - val_loss: 3061.5325 - val_reconstruction_loss: 244.4226 - val_kl_loss: 2817.1094\n",
      "Epoch 473/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3206.8439 - reconstruction_loss: 194.6534 - kl_loss: 3008.9209 - val_loss: 3242.7488 - val_reconstruction_loss: 152.5365 - val_kl_loss: 3090.2124\n",
      "Epoch 474/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3197.6401 - reconstruction_loss: 146.7092 - kl_loss: 3036.7925 - val_loss: 3211.1985 - val_reconstruction_loss: 144.0600 - val_kl_loss: 3067.1379\n",
      "Epoch 475/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3175.4249 - reconstruction_loss: 142.5829 - kl_loss: 3024.0103 - val_loss: 3153.6980 - val_reconstruction_loss: 140.4751 - val_kl_loss: 3013.2227\n",
      "Epoch 476/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3127.6687 - reconstruction_loss: 140.3484 - kl_loss: 2979.4731 - val_loss: 3122.7075 - val_reconstruction_loss: 139.1823 - val_kl_loss: 2983.5256\n",
      "Epoch 477/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 3111.0379 - reconstruction_loss: 141.5299 - kl_loss: 2960.0208 - val_loss: 3208.9153 - val_reconstruction_loss: 149.4443 - val_kl_loss: 3059.4712\n",
      "Epoch 478/1000\n",
      "111/111 [==============================] - 3s 26ms/step - loss: 3225.1217 - reconstruction_loss: 141.6187 - kl_loss: 3067.8992 - val_loss: 3150.8691 - val_reconstruction_loss: 135.9920 - val_kl_loss: 3014.8767\n",
      "Epoch 479/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 3123.2122 - reconstruction_loss: 135.1332 - kl_loss: 2974.9133 - val_loss: 3069.6741 - val_reconstruction_loss: 133.3994 - val_kl_loss: 2936.2751\n",
      "Epoch 480/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 3051.6161 - reconstruction_loss: 133.5339 - kl_loss: 2916.6636 - val_loss: 3029.0020 - val_reconstruction_loss: 132.3020 - val_kl_loss: 2896.6997\n",
      "Epoch 481/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 3018.7715 - reconstruction_loss: 132.5348 - kl_loss: 2883.5454 - val_loss: 3000.8743 - val_reconstruction_loss: 131.7890 - val_kl_loss: 2869.0854\n",
      "Epoch 482/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 2994.9582 - reconstruction_loss: 131.8421 - kl_loss: 2860.6377 - val_loss: 2979.2417 - val_reconstruction_loss: 131.5492 - val_kl_loss: 2847.6921\n",
      "Epoch 483/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 2976.1442 - reconstruction_loss: 131.3527 - kl_loss: 2839.6211 - val_loss: 2963.4802 - val_reconstruction_loss: 131.0610 - val_kl_loss: 2832.4194\n",
      "Epoch 484/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 2956.4866 - reconstruction_loss: 131.1599 - kl_loss: 2823.8560 - val_loss: 2946.4683 - val_reconstruction_loss: 130.7865 - val_kl_loss: 2815.6816\n",
      "Epoch 485/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 2941.9988 - reconstruction_loss: 130.9193 - kl_loss: 2807.8267 - val_loss: 2934.4141 - val_reconstruction_loss: 130.7164 - val_kl_loss: 2803.6980\n",
      "Epoch 486/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 2931.3529 - reconstruction_loss: 130.5828 - kl_loss: 2794.9011 - val_loss: 2921.6140 - val_reconstruction_loss: 130.1145 - val_kl_loss: 2791.5000\n",
      "Epoch 487/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 2917.1372 - reconstruction_loss: 130.3138 - kl_loss: 2782.9507 - val_loss: 2910.2737 - val_reconstruction_loss: 130.2547 - val_kl_loss: 2780.0193\n",
      "Epoch 488/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 2907.6931 - reconstruction_loss: 130.2460 - kl_loss: 2771.5647 - val_loss: 2898.4924 - val_reconstruction_loss: 129.9059 - val_kl_loss: 2768.5864\n",
      "Epoch 489/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 2897.4924 - reconstruction_loss: 130.1024 - kl_loss: 2759.0234 - val_loss: 2881.3909 - val_reconstruction_loss: 129.9224 - val_kl_loss: 2751.4688\n",
      "Epoch 490/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 2809.6716 - reconstruction_loss: 131.0405 - kl_loss: 2335.3237 - val_loss: 1204.3756 - val_reconstruction_loss: 134.4888 - val_kl_loss: 1069.8870\n",
      "Epoch 491/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 1873.6388 - reconstruction_loss: 152.4202 - kl_loss: 2473.0300 - val_loss: 1428.8718 - val_reconstruction_loss: 151.6059 - val_kl_loss: 1277.2660\n",
      "Epoch 492/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 1353.4960 - reconstruction_loss: 149.0562 - kl_loss: 1249.0099 - val_loss: 1464.0592 - val_reconstruction_loss: 139.6777 - val_kl_loss: 1324.3811\n",
      "Epoch 493/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 19ms/step - loss: 1437.3106 - reconstruction_loss: 138.1829 - kl_loss: 1283.8219 - val_loss: 1408.6012 - val_reconstruction_loss: 134.9503 - val_kl_loss: 1273.6508\n",
      "Epoch 494/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 1395.9133 - reconstruction_loss: 134.4092 - kl_loss: 1240.1373 - val_loss: 1248.7266 - val_reconstruction_loss: 135.2906 - val_kl_loss: 1113.4362\n",
      "Epoch 495/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 128522639253.9440 - reconstruction_loss: 259.2481 - kl_loss: 329054420992.0000 - val_loss: 151864590336.0000 - val_reconstruction_loss: 251.2307 - val_kl_loss: 151864590336.0000\n",
      "Epoch 496/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 232757509046.8571 - reconstruction_loss: 203.3487 - kl_loss: 303521628160.0000 - val_loss: 4568360960.0000 - val_reconstruction_loss: 230.5953 - val_kl_loss: 4568360448.0000\n",
      "Epoch 497/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 1521548517762.2856 - reconstruction_loss: 198.5500 - kl_loss: 661028077568.0000 - val_loss: 48609255424.0000 - val_reconstruction_loss: 164.6389 - val_kl_loss: 48609255424.0000\n",
      "Epoch 498/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 166821981641.1429 - reconstruction_loss: 166.1270 - kl_loss: 509084237824.0000 - val_loss: 196385680.0000 - val_reconstruction_loss: 169.3141 - val_kl_loss: 196385456.0000\n",
      "Epoch 499/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 103658083.8929 - reconstruction_loss: 157.7812 - kl_loss: 195486416.0000 - val_loss: 172949968.0000 - val_reconstruction_loss: 150.2441 - val_kl_loss: 172949808.0000\n",
      "Epoch 500/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 40262231.6161 - reconstruction_loss: 150.8437 - kl_loss: 11208697.0000 - val_loss: 160380.6406 - val_reconstruction_loss: 147.4097 - val_kl_loss: 160233.2344\n",
      "Epoch 501/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 151785.9584 - reconstruction_loss: 144.2364 - kl_loss: 153361.0312 - val_loss: 169458.5781 - val_reconstruction_loss: 142.5907 - val_kl_loss: 169315.9844\n",
      "Epoch 502/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 15349756.7884 - reconstruction_loss: 150.3195 - kl_loss: 17035510.0000 - val_loss: 4242831.0000 - val_reconstruction_loss: 144.3559 - val_kl_loss: 4242687.0000\n",
      "Epoch 503/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 5102202.7121 - reconstruction_loss: 142.7767 - kl_loss: 8591945.0000 - val_loss: 36948200.0000 - val_reconstruction_loss: 141.3368 - val_kl_loss: 36948060.0000\n",
      "Epoch 504/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 20662607.0714 - reconstruction_loss: 141.9526 - kl_loss: 10450508.0000 - val_loss: 3581428.7500 - val_reconstruction_loss: 141.8340 - val_kl_loss: 3581286.5000\n",
      "Epoch 505/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 3703835.1049 - reconstruction_loss: 140.4124 - kl_loss: 3409054.7500 - val_loss: 3135099.2500 - val_reconstruction_loss: 138.4479 - val_kl_loss: 3134960.5000\n",
      "Epoch 506/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3175855.9263 - reconstruction_loss: 138.2308 - kl_loss: 3271768.0000 - val_loss: 3240341.7500 - val_reconstruction_loss: 136.3477 - val_kl_loss: 3240206.0000\n",
      "Epoch 507/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 3056994.4531 - reconstruction_loss: 136.6940 - kl_loss: 3044550.7500 - val_loss: 3315413.2500 - val_reconstruction_loss: 135.1617 - val_kl_loss: 3315277.5000\n",
      "Epoch 508/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 3400667.5982 - reconstruction_loss: 135.4935 - kl_loss: 3416363.7500 - val_loss: 3632608.7500 - val_reconstruction_loss: 134.1082 - val_kl_loss: 3632475.2500\n",
      "Epoch 509/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 3642110.1585 - reconstruction_loss: 134.5045 - kl_loss: 3622707.2500 - val_loss: 4286715.0000 - val_reconstruction_loss: 134.1343 - val_kl_loss: 4286581.5000\n",
      "Epoch 510/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 4520223.6652 - reconstruction_loss: 134.1329 - kl_loss: 4501810.0000 - val_loss: 4543791.5000 - val_reconstruction_loss: 133.6295 - val_kl_loss: 4543657.5000\n",
      "Epoch 511/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4394795.6205 - reconstruction_loss: 133.8893 - kl_loss: 4347321.5000 - val_loss: 4278753.0000 - val_reconstruction_loss: 133.0320 - val_kl_loss: 4278619.5000\n",
      "Epoch 512/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4321079.4955 - reconstruction_loss: 133.3261 - kl_loss: 4317208.0000 - val_loss: 4337911.0000 - val_reconstruction_loss: 132.6409 - val_kl_loss: 4337778.5000\n",
      "Epoch 513/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4428245.4353 - reconstruction_loss: 132.9824 - kl_loss: 4458564.5000 - val_loss: 4517580.5000 - val_reconstruction_loss: 132.1678 - val_kl_loss: 4517448.0000\n",
      "Epoch 514/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 4350101.6942 - reconstruction_loss: 132.7210 - kl_loss: 4455725.0000 - val_loss: 4381416.5000 - val_reconstruction_loss: 131.4623 - val_kl_loss: 4381285.0000\n",
      "Epoch 515/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4381277.2768 - reconstruction_loss: 132.3909 - kl_loss: 4380831.0000 - val_loss: 4379370.5000 - val_reconstruction_loss: 131.3359 - val_kl_loss: 4379239.5000\n",
      "Epoch 516/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 4389965.6295 - reconstruction_loss: 131.9411 - kl_loss: 4296433.5000 - val_loss: 4112833.5000 - val_reconstruction_loss: 131.3289 - val_kl_loss: 4112702.0000\n",
      "Epoch 517/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 4029377.2232 - reconstruction_loss: 131.7864 - kl_loss: 4037718.7500 - val_loss: 3709282.2500 - val_reconstruction_loss: 131.3796 - val_kl_loss: 3709150.2500\n",
      "Epoch 518/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 3566449.1830 - reconstruction_loss: 131.5698 - kl_loss: 3630963.5000 - val_loss: 3633212.7500 - val_reconstruction_loss: 131.0324 - val_kl_loss: 3633081.7500\n",
      "Epoch 519/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 3552929.0022 - reconstruction_loss: 131.2755 - kl_loss: 3627194.0000 - val_loss: 3629765.2500 - val_reconstruction_loss: 130.8421 - val_kl_loss: 3629634.5000\n",
      "Epoch 520/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 3516338.9196 - reconstruction_loss: 131.1091 - kl_loss: 3708768.7500 - val_loss: 3902075.5000 - val_reconstruction_loss: 130.8393 - val_kl_loss: 3901945.2500\n",
      "Epoch 521/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 3799417.4721 - reconstruction_loss: 131.0991 - kl_loss: 3859570.7500 - val_loss: 3856564.5000 - val_reconstruction_loss: 130.6579 - val_kl_loss: 3856433.7500\n",
      "Epoch 522/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3831410.7612 - reconstruction_loss: 130.9957 - kl_loss: 3841726.7500 - val_loss: 3852822.0000 - val_reconstruction_loss: 130.4322 - val_kl_loss: 3852692.2500\n",
      "Epoch 523/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 3738131.3504 - reconstruction_loss: 130.8203 - kl_loss: 3838362.7500 - val_loss: 3845454.2500 - val_reconstruction_loss: 130.2182 - val_kl_loss: 3845324.5000\n",
      "Epoch 524/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 3953614.2344 - reconstruction_loss: 130.7594 - kl_loss: 4083179.5000 - val_loss: 4589494.5000 - val_reconstruction_loss: 130.2769 - val_kl_loss: 4589364.0000\n",
      "Epoch 525/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 4560133.8080 - reconstruction_loss: 130.5950 - kl_loss: 4563041.5000 - val_loss: 4355911.0000 - val_reconstruction_loss: 129.8994 - val_kl_loss: 4355781.0000\n",
      "Epoch 526/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 4275742.0335 - reconstruction_loss: 130.4370 - kl_loss: 4290486.5000 - val_loss: 4070983.5000 - val_reconstruction_loss: 130.1131 - val_kl_loss: 4070853.7500\n",
      "Epoch 527/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 3860192.5134 - reconstruction_loss: 130.2322 - kl_loss: 3712267.5000 - val_loss: 3626779.7500 - val_reconstruction_loss: 130.1434 - val_kl_loss: 3626649.7500\n",
      "Epoch 528/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 3611993.4576 - reconstruction_loss: 130.2818 - kl_loss: 3630670.7500 - val_loss: 3602173.2500 - val_reconstruction_loss: 129.7579 - val_kl_loss: 3602042.7500\n",
      "Epoch 529/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 3558296.0357 - reconstruction_loss: 130.3820 - kl_loss: 3584245.2500 - val_loss: 3601748.7500 - val_reconstruction_loss: 130.0375 - val_kl_loss: 3601618.2500\n",
      "Epoch 530/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 3408726.4118 - reconstruction_loss: 130.3695 - kl_loss: 3502012.0000 - val_loss: 3444506.7500 - val_reconstruction_loss: 130.0996 - val_kl_loss: 3444377.2500\n",
      "Epoch 531/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 3326225.3884 - reconstruction_loss: 130.2348 - kl_loss: 3405378.2500 - val_loss: 3535991.2500 - val_reconstruction_loss: 129.9537 - val_kl_loss: 3535861.2500\n",
      "Epoch 532/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 3570069.7299 - reconstruction_loss: 130.3524 - kl_loss: 3443255.0000 - val_loss: 3227305.5000 - val_reconstruction_loss: 129.5583 - val_kl_loss: 3227176.2500\n",
      "Epoch 533/1000\n",
      "111/111 [==============================] - 2s 23ms/step - loss: 3192425.3616 - reconstruction_loss: 130.0480 - kl_loss: 3317935.7500 - val_loss: 3411760.5000 - val_reconstruction_loss: 129.8321 - val_kl_loss: 3411630.5000\n",
      "Epoch 534/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3307349.5737 - reconstruction_loss: 130.1264 - kl_loss: 3302606.2500 - val_loss: 3189848.5000 - val_reconstruction_loss: 129.5953 - val_kl_loss: 3189719.5000\n",
      "Epoch 535/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3022462.8348 - reconstruction_loss: 130.0856 - kl_loss: 3146058.5000 - val_loss: 3139957.7500 - val_reconstruction_loss: 129.5628 - val_kl_loss: 3139828.0000\n",
      "Epoch 536/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3096600.4397 - reconstruction_loss: 129.9923 - kl_loss: 3171802.7500 - val_loss: 3168179.5000 - val_reconstruction_loss: 129.9967 - val_kl_loss: 3168050.0000\n",
      "Epoch 537/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3136491.6908 - reconstruction_loss: 130.0508 - kl_loss: 3239678.7500 - val_loss: 3375217.7500 - val_reconstruction_loss: 129.5288 - val_kl_loss: 3375088.0000\n",
      "Epoch 538/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 3417740.5558 - reconstruction_loss: 129.9508 - kl_loss: 3293603.0000 - val_loss: 3074418.5000 - val_reconstruction_loss: 129.4866 - val_kl_loss: 3074288.7500\n",
      "Epoch 539/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3173708.6942 - reconstruction_loss: 129.8900 - kl_loss: 3131250.5000 - val_loss: 3485886.7500 - val_reconstruction_loss: 129.7966 - val_kl_loss: 3485757.2500\n",
      "Epoch 540/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 3424041.4978 - reconstruction_loss: 129.9948 - kl_loss: 3039025.7500 - val_loss: 2330403.5000 - val_reconstruction_loss: 129.6937 - val_kl_loss: 2330273.5000\n",
      "Epoch 541/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 2314065.6920 - reconstruction_loss: 130.0466 - kl_loss: 2389059.7500 - val_loss: 2429559.5000 - val_reconstruction_loss: 129.7745 - val_kl_loss: 2429429.5000\n",
      "Epoch 542/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 2019441.6350 - reconstruction_loss: 130.1494 - kl_loss: 1949627.1250 - val_loss: 1860046.6250 - val_reconstruction_loss: 129.9420 - val_kl_loss: 1859916.3750\n",
      "Epoch 543/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 1896558.6295 - reconstruction_loss: 130.1645 - kl_loss: 1883911.5000 - val_loss: 1948205.1250 - val_reconstruction_loss: 129.5184 - val_kl_loss: 1948075.6250\n",
      "Epoch 544/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 1941050.9319 - reconstruction_loss: 130.0047 - kl_loss: 1960294.2500 - val_loss: 1981664.0000 - val_reconstruction_loss: 129.9962 - val_kl_loss: 1981533.7500\n",
      "Epoch 545/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 1930088.7846 - reconstruction_loss: 130.0592 - kl_loss: 2026649.1250 - val_loss: 2788811.5000 - val_reconstruction_loss: 129.6608 - val_kl_loss: 2788682.0000\n",
      "Epoch 546/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 3133863.5647 - reconstruction_loss: 129.9846 - kl_loss: 3137259.5000 - val_loss: 255339.2812 - val_reconstruction_loss: 130.2230 - val_kl_loss: 255209.0781\n",
      "Epoch 547/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 160244.1011 - reconstruction_loss: 130.5439 - kl_loss: 153664.9219 - val_loss: 149157.1562 - val_reconstruction_loss: 129.6745 - val_kl_loss: 149027.4688\n",
      "Epoch 548/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 147941.3734 - reconstruction_loss: 130.1213 - kl_loss: 145560.1562 - val_loss: 139788.1406 - val_reconstruction_loss: 129.7567 - val_kl_loss: 139658.3906\n",
      "Epoch 549/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 142282.8013 - reconstruction_loss: 130.1565 - kl_loss: 141099.3438 - val_loss: 140046.4688 - val_reconstruction_loss: 129.7009 - val_kl_loss: 139916.7812\n",
      "Epoch 550/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 142325.3881 - reconstruction_loss: 130.1036 - kl_loss: 144447.1406 - val_loss: 146617.7969 - val_reconstruction_loss: 129.4043 - val_kl_loss: 146488.4062\n",
      "Epoch 551/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 149337.0428 - reconstruction_loss: 129.7878 - kl_loss: 148919.6562 - val_loss: 147898.8281 - val_reconstruction_loss: 129.6497 - val_kl_loss: 147769.1406\n",
      "Epoch 552/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 146388.3773 - reconstruction_loss: 130.0615 - kl_loss: 150108.6094 - val_loss: 148232.1562 - val_reconstruction_loss: 129.7623 - val_kl_loss: 148102.3906\n",
      "Epoch 553/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 152790.5617 - reconstruction_loss: 130.0418 - kl_loss: 149754.5312 - val_loss: 148147.7812 - val_reconstruction_loss: 129.5753 - val_kl_loss: 148018.2031\n",
      "Epoch 554/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 152051.7188 - reconstruction_loss: 129.9777 - kl_loss: 149364.7344 - val_loss: 145685.8438 - val_reconstruction_loss: 129.7332 - val_kl_loss: 145556.0938\n",
      "Epoch 555/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 84746.0146 - reconstruction_loss: 129.8652 - kl_loss: 69641.5859 - val_loss: 63977.4062 - val_reconstruction_loss: 129.6404 - val_kl_loss: 63847.7695\n",
      "Epoch 556/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 63297.1253 - reconstruction_loss: 129.6329 - kl_loss: 63321.3906 - val_loss: 64192.1250 - val_reconstruction_loss: 129.4825 - val_kl_loss: 64062.6445\n",
      "Epoch 557/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 63488.3876 - reconstruction_loss: 129.9347 - kl_loss: 63477.5781 - val_loss: 64059.5430 - val_reconstruction_loss: 129.4843 - val_kl_loss: 63930.0625\n",
      "Epoch 558/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 63441.4642 - reconstruction_loss: 129.7527 - kl_loss: 63519.6719 - val_loss: 65300.8398 - val_reconstruction_loss: 129.7636 - val_kl_loss: 65171.0742\n",
      "Epoch 559/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 64533.6847 - reconstruction_loss: 129.7356 - kl_loss: 64815.6875 - val_loss: 65522.7227 - val_reconstruction_loss: 129.2291 - val_kl_loss: 65393.4883\n",
      "Epoch 560/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 64535.0891 - reconstruction_loss: 129.5608 - kl_loss: 64718.6367 - val_loss: 65804.5703 - val_reconstruction_loss: 129.5427 - val_kl_loss: 65675.0391\n",
      "Epoch 561/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 64655.0807 - reconstruction_loss: 129.7443 - kl_loss: 65070.4727 - val_loss: 65763.6875 - val_reconstruction_loss: 129.3811 - val_kl_loss: 65634.3203\n",
      "Epoch 562/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 18ms/step - loss: 65232.5695 - reconstruction_loss: 129.7350 - kl_loss: 65054.3906 - val_loss: 65781.2812 - val_reconstruction_loss: 129.1841 - val_kl_loss: 65652.0859\n",
      "Epoch 563/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 64863.2214 - reconstruction_loss: 129.5549 - kl_loss: 65105.5078 - val_loss: 65687.7734 - val_reconstruction_loss: 129.1334 - val_kl_loss: 65558.6562\n",
      "Epoch 564/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 65857.0492 - reconstruction_loss: 129.6045 - kl_loss: 64989.4609 - val_loss: 65428.5352 - val_reconstruction_loss: 129.2087 - val_kl_loss: 65299.3242\n",
      "Epoch 565/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 63670.8758 - reconstruction_loss: 129.6930 - kl_loss: 63752.9883 - val_loss: 64326.8438 - val_reconstruction_loss: 129.3720 - val_kl_loss: 64197.4609\n",
      "Epoch 566/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 62055.4316 - reconstruction_loss: 129.5623 - kl_loss: 62644.4883 - val_loss: 63857.1758 - val_reconstruction_loss: 129.2895 - val_kl_loss: 63727.8828\n",
      "Epoch 567/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 62335.8993 - reconstruction_loss: 129.6294 - kl_loss: 61089.2148 - val_loss: 58408.3477 - val_reconstruction_loss: 129.2090 - val_kl_loss: 58279.1484\n",
      "Epoch 568/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 57127.4954 - reconstruction_loss: 129.6585 - kl_loss: 57613.3555 - val_loss: 58908.6758 - val_reconstruction_loss: 129.3804 - val_kl_loss: 58779.2891\n",
      "Epoch 569/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 58755.7431 - reconstruction_loss: 129.7576 - kl_loss: 60954.5508 - val_loss: 65354.8047 - val_reconstruction_loss: 129.6309 - val_kl_loss: 65225.1758\n",
      "Epoch 570/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 62741.4578 - reconstruction_loss: 129.8215 - kl_loss: 63224.1211 - val_loss: 63336.9727 - val_reconstruction_loss: 129.4293 - val_kl_loss: 63207.5430\n",
      "Epoch 571/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 63241.6384 - reconstruction_loss: 129.7405 - kl_loss: 63350.8203 - val_loss: 65754.2891 - val_reconstruction_loss: 129.2831 - val_kl_loss: 65625.0078\n",
      "Epoch 572/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 65297.2560 - reconstruction_loss: 129.6136 - kl_loss: 63748.0469 - val_loss: 58197.0625 - val_reconstruction_loss: 129.0582 - val_kl_loss: 58068.0117\n",
      "Epoch 573/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 56922.3826 - reconstruction_loss: 129.5630 - kl_loss: 55862.8125 - val_loss: 55422.7617 - val_reconstruction_loss: 129.2248 - val_kl_loss: 55293.5391\n",
      "Epoch 574/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 51276.7725 - reconstruction_loss: 129.5130 - kl_loss: 42225.5703 - val_loss: 33540.4258 - val_reconstruction_loss: 129.2434 - val_kl_loss: 33411.1797\n",
      "Epoch 575/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 32949.7565 - reconstruction_loss: 129.4091 - kl_loss: 32781.8594 - val_loss: 33738.2422 - val_reconstruction_loss: 129.0806 - val_kl_loss: 33609.1602\n",
      "Epoch 576/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 33341.9933 - reconstruction_loss: 129.5826 - kl_loss: 33176.3203 - val_loss: 34323.7305 - val_reconstruction_loss: 129.1246 - val_kl_loss: 34194.6016\n",
      "Epoch 577/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 33814.6471 - reconstruction_loss: 129.5127 - kl_loss: 33410.7461 - val_loss: 34391.0273 - val_reconstruction_loss: 129.0041 - val_kl_loss: 34262.0273\n",
      "Epoch 578/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 33390.5269 - reconstruction_loss: 129.4741 - kl_loss: 33796.7266 - val_loss: 35050.3203 - val_reconstruction_loss: 128.9275 - val_kl_loss: 34921.3867\n",
      "Epoch 579/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 33801.2773 - reconstruction_loss: 129.4601 - kl_loss: 33865.7461 - val_loss: 36868.0039 - val_reconstruction_loss: 128.9710 - val_kl_loss: 36739.0391\n",
      "Epoch 580/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 38169.0531 - reconstruction_loss: 129.5722 - kl_loss: 41689.1680 - val_loss: 55438.3008 - val_reconstruction_loss: 129.5189 - val_kl_loss: 55308.7773\n",
      "Epoch 581/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 54273.2136 - reconstruction_loss: 129.7815 - kl_loss: 53980.4727 - val_loss: 54648.6172 - val_reconstruction_loss: 129.5247 - val_kl_loss: 54519.0977\n",
      "Epoch 582/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 60738.9652 - reconstruction_loss: 129.9500 - kl_loss: 71911.1641 - val_loss: 89652.9922 - val_reconstruction_loss: 129.5727 - val_kl_loss: 89523.4297\n",
      "Epoch 583/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 93480.5687 - reconstruction_loss: 130.0546 - kl_loss: 105756.8125 - val_loss: 215678.2500 - val_reconstruction_loss: 130.3226 - val_kl_loss: 215547.9688\n",
      "Epoch 584/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 3383448141.6533 - reconstruction_loss: 131.9700 - kl_loss: 10743897088.0000 - val_loss: 3006052.2500 - val_reconstruction_loss: 132.3048 - val_kl_loss: 3005919.7500\n",
      "Epoch 585/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4370839.4621 - reconstruction_loss: 132.0200 - kl_loss: 4679253.0000 - val_loss: 4697235.0000 - val_reconstruction_loss: 130.9062 - val_kl_loss: 4697104.5000\n",
      "Epoch 586/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 6859108.5357 - reconstruction_loss: 131.1598 - kl_loss: 8296275.5000 - val_loss: 3501053.2500 - val_reconstruction_loss: 130.7412 - val_kl_loss: 3500922.5000\n",
      "Epoch 587/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 14225456743.6808 - reconstruction_loss: 132.3703 - kl_loss: 22282504192.0000 - val_loss: 13498196992.0000 - val_reconstruction_loss: 132.3440 - val_kl_loss: 13498196992.0000\n",
      "Epoch 588/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 8247233606.8571 - reconstruction_loss: 132.5737 - kl_loss: 167828979712.0000 - val_loss: 1720988991488.0000 - val_reconstruction_loss: 131.6189 - val_kl_loss: 1720988991488.0000\n",
      "Epoch 589/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 125514096091.4286 - reconstruction_loss: 132.9749 - kl_loss: 54134763520.0000 - val_loss: 507320640.0000 - val_reconstruction_loss: 131.3428 - val_kl_loss: 507320384.0000\n",
      "Epoch 590/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 8903247092.3571 - reconstruction_loss: 132.4700 - kl_loss: 39427055616.0000 - val_loss: 8364129280.0000 - val_reconstruction_loss: 132.7373 - val_kl_loss: 8364129280.0000\n",
      "Epoch 591/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 23200914289.1429 - reconstruction_loss: 133.4683 - kl_loss: 40050712576.0000 - val_loss: 246576896.0000 - val_reconstruction_loss: 131.3040 - val_kl_loss: 246576784.0000\n",
      "Epoch 592/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 8297581139795.4287 - reconstruction_loss: 131.5731 - kl_loss: 5150217863168.0000 - val_loss: 5823880.0000 - val_reconstruction_loss: 130.8645 - val_kl_loss: 5823748.5000\n",
      "Epoch 593/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 1310722.2600 - reconstruction_loss: 130.8903 - kl_loss: 932428.7500 - val_loss: 1141276.1250 - val_reconstruction_loss: 130.4480 - val_kl_loss: 1141145.7500\n",
      "Epoch 594/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 1278117.5725 - reconstruction_loss: 130.6137 - kl_loss: 1394077.0000 - val_loss: 5104573.0000 - val_reconstruction_loss: 132.7731 - val_kl_loss: 5104440.5000\n",
      "Epoch 595/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 1281350.9732 - reconstruction_loss: 130.4912 - kl_loss: 1319138.8750 - val_loss: 1027791.0625 - val_reconstruction_loss: 130.0860 - val_kl_loss: 1027660.8750\n",
      "Epoch 596/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 822087.5965 - reconstruction_loss: 130.5644 - kl_loss: 1071798.3750 - val_loss: 1205269.8750 - val_reconstruction_loss: 130.5087 - val_kl_loss: 1205139.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 597/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 1244548.7768 - reconstruction_loss: 130.4147 - kl_loss: 1240755.0000 - val_loss: 1250945.0000 - val_reconstruction_loss: 129.8387 - val_kl_loss: 1250815.0000\n",
      "Epoch 598/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 1232600.9621 - reconstruction_loss: 130.2530 - kl_loss: 1249031.7500 - val_loss: 1208328.6250 - val_reconstruction_loss: 130.0373 - val_kl_loss: 1208198.6250\n",
      "Epoch 599/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 1191789.3588 - reconstruction_loss: 130.3112 - kl_loss: 1241482.3750 - val_loss: 1310816.2500 - val_reconstruction_loss: 129.8182 - val_kl_loss: 1310686.3750\n",
      "Epoch 600/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 1236115.2645 - reconstruction_loss: 130.1887 - kl_loss: 1099853.8750 - val_loss: 1226979.7500 - val_reconstruction_loss: 129.8853 - val_kl_loss: 1226849.7500\n",
      "Epoch 601/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 1256075.6886 - reconstruction_loss: 130.2838 - kl_loss: 1281869.0000 - val_loss: 1300826.0000 - val_reconstruction_loss: 129.8342 - val_kl_loss: 1300696.1250\n",
      "Epoch 602/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 1331635.2054 - reconstruction_loss: 130.1426 - kl_loss: 1380583.8750 - val_loss: 1464011.6250 - val_reconstruction_loss: 129.8726 - val_kl_loss: 1463881.7500\n",
      "Epoch 603/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 1454640.4799 - reconstruction_loss: 130.2382 - kl_loss: 1511134.7500 - val_loss: 1532144.0000 - val_reconstruction_loss: 130.0537 - val_kl_loss: 1532014.1250\n",
      "Epoch 604/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 1430074.6741 - reconstruction_loss: 130.2234 - kl_loss: 1368675.3750 - val_loss: 1254992.2500 - val_reconstruction_loss: 129.9558 - val_kl_loss: 1254862.3750\n",
      "Epoch 605/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 1251772.6987 - reconstruction_loss: 130.1159 - kl_loss: 1228941.0000 - val_loss: 1223764.7500 - val_reconstruction_loss: 129.9681 - val_kl_loss: 1223634.6250\n",
      "Epoch 606/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 1210487.0201 - reconstruction_loss: 130.1916 - kl_loss: 1212043.8750 - val_loss: 1232776.6250 - val_reconstruction_loss: 129.9945 - val_kl_loss: 1232646.2500\n",
      "Epoch 607/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 1250391.4520 - reconstruction_loss: 130.2504 - kl_loss: 1203805.3750 - val_loss: 937551.4375 - val_reconstruction_loss: 129.9076 - val_kl_loss: 937421.5000\n",
      "Epoch 608/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 929693.8689 - reconstruction_loss: 130.1014 - kl_loss: 932771.8125 - val_loss: 907815.3125 - val_reconstruction_loss: 129.7943 - val_kl_loss: 907685.5000\n",
      "Epoch 609/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 8922209.6406 - reconstruction_loss: 130.5219 - kl_loss: 165127072.0000 - val_loss: 4209688576.0000 - val_reconstruction_loss: 130.5200 - val_kl_loss: 4209688064.0000\n",
      "Epoch 610/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 1037190348.0000 - reconstruction_loss: 130.4767 - kl_loss: 395008064.0000 - val_loss: 32793764.0000 - val_reconstruction_loss: 130.0097 - val_kl_loss: 32793636.0000\n",
      "Epoch 611/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 29047694.2143 - reconstruction_loss: 130.4143 - kl_loss: 27317258.0000 - val_loss: 26526464.0000 - val_reconstruction_loss: 130.0751 - val_kl_loss: 26526332.0000\n",
      "Epoch 612/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 66448220.5000 - reconstruction_loss: 131.1681 - kl_loss: 86731480.0000 - val_loss: 18678.4219 - val_reconstruction_loss: 130.0241 - val_kl_loss: 18548.3926\n",
      "Epoch 613/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 18546.3698 - reconstruction_loss: 129.3985 - kl_loss: 16422.0977 - val_loss: 14511.3799 - val_reconstruction_loss: 128.6009 - val_kl_loss: 14382.7783\n",
      "Epoch 614/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 13878.5929 - reconstruction_loss: 129.0337 - kl_loss: 14684.2402 - val_loss: 14403.3516 - val_reconstruction_loss: 128.4578 - val_kl_loss: 14274.8906\n",
      "Epoch 615/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 15975.3922 - reconstruction_loss: 128.6573 - kl_loss: 14334.8662 - val_loss: 14429.8252 - val_reconstruction_loss: 128.3107 - val_kl_loss: 14301.5156\n",
      "Epoch 616/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 43002128136.3173 - reconstruction_loss: 130.2834 - kl_loss: 484049813504.0000 - val_loss: 341333920.0000 - val_reconstruction_loss: 141.3298 - val_kl_loss: 341333760.0000\n",
      "Epoch 617/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 1471023177.2857 - reconstruction_loss: 132.6664 - kl_loss: 1602776960.0000 - val_loss: 375459.9688 - val_reconstruction_loss: 130.6248 - val_kl_loss: 375329.3438\n",
      "Epoch 618/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 2807030.0466 - reconstruction_loss: 130.8909 - kl_loss: 5480697.0000 - val_loss: 586160.8125 - val_reconstruction_loss: 130.5762 - val_kl_loss: 586030.3125\n",
      "Epoch 619/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 536922.3298 - reconstruction_loss: 130.4954 - kl_loss: 475425.0312 - val_loss: 492714.2500 - val_reconstruction_loss: 130.0421 - val_kl_loss: 492584.2188\n",
      "Epoch 620/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 635591.4344 - reconstruction_loss: 130.2489 - kl_loss: 580937.8750 - val_loss: 245138.5938 - val_reconstruction_loss: 129.6548 - val_kl_loss: 245008.8906\n",
      "Epoch 621/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 4230119215.4622 - reconstruction_loss: 131.4773 - kl_loss: 4486387200.0000 - val_loss: 1652744192.0000 - val_reconstruction_loss: 130.7559 - val_kl_loss: 1652743936.0000\n",
      "Epoch 622/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 5475252484.5714 - reconstruction_loss: 131.3471 - kl_loss: 4565936128.0000 - val_loss: 1610905.0000 - val_reconstruction_loss: 131.6673 - val_kl_loss: 1610773.2500\n",
      "Epoch 623/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 11311429410.7578 - reconstruction_loss: 131.2610 - kl_loss: 19573037056.0000 - val_loss: 60032364.0000 - val_reconstruction_loss: 130.5955 - val_kl_loss: 60032232.0000\n",
      "Epoch 624/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 20008591.6964 - reconstruction_loss: 130.3364 - kl_loss: 7519964.5000 - val_loss: 57148.1328 - val_reconstruction_loss: 128.8864 - val_kl_loss: 57019.2500\n",
      "Epoch 625/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 49036.1046 - reconstruction_loss: 129.0776 - kl_loss: 47179.5469 - val_loss: 53242.9258 - val_reconstruction_loss: 128.6499 - val_kl_loss: 53114.2773\n",
      "Epoch 626/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 152441.6648 - reconstruction_loss: 129.7085 - kl_loss: 347342.3750 - val_loss: 829428.5625 - val_reconstruction_loss: 129.4543 - val_kl_loss: 829299.3125\n",
      "Epoch 627/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 650618.9210 - reconstruction_loss: 129.7460 - kl_loss: 732638.7500 - val_loss: 1355877.3750 - val_reconstruction_loss: 129.5991 - val_kl_loss: 1355747.8750\n",
      "Epoch 628/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 1198082.9609 - reconstruction_loss: 129.7551 - kl_loss: 1170182.2500 - val_loss: 1350821.7500 - val_reconstruction_loss: 129.3893 - val_kl_loss: 1350692.2500\n",
      "Epoch 629/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 1457925.1261 - reconstruction_loss: 129.6599 - kl_loss: 2055753.1250 - val_loss: 5486336.5000 - val_reconstruction_loss: 129.9952 - val_kl_loss: 5486207.0000\n",
      "Epoch 630/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 1095096059981.8214 - reconstruction_loss: 130.8683 - kl_loss: 673134804992.0000 - val_loss: 5633.5688 - val_reconstruction_loss: 129.6942 - val_kl_loss: 5503.8745\n",
      "Epoch 631/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 5516.9500 - reconstruction_loss: 129.3312 - kl_loss: 5121.4512 - val_loss: 5179.7148 - val_reconstruction_loss: 129.0486 - val_kl_loss: 5050.6665\n",
      "Epoch 632/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 5050.0968 - reconstruction_loss: 128.8621 - kl_loss: 4900.8799 - val_loss: 5183.0405 - val_reconstruction_loss: 128.5703 - val_kl_loss: 5054.4702\n",
      "Epoch 633/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 5142.8211 - reconstruction_loss: 128.6505 - kl_loss: 5119.6597 - val_loss: 5541.4243 - val_reconstruction_loss: 128.4785 - val_kl_loss: 5412.9463\n",
      "Epoch 634/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 5099.8324 - reconstruction_loss: 128.8322 - kl_loss: 4814.9297 - val_loss: 4853.5874 - val_reconstruction_loss: 128.7695 - val_kl_loss: 4724.8174\n",
      "Epoch 635/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 4836.4290 - reconstruction_loss: 128.8857 - kl_loss: 4692.4863 - val_loss: 4704.0386 - val_reconstruction_loss: 128.7591 - val_kl_loss: 4575.2803\n",
      "Epoch 636/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4874.5045 - reconstruction_loss: 128.7234 - kl_loss: 4778.5361 - val_loss: 4996.3135 - val_reconstruction_loss: 128.6558 - val_kl_loss: 4867.6587\n",
      "Epoch 637/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4909.0691 - reconstruction_loss: 128.7137 - kl_loss: 4775.5249 - val_loss: 5275.4312 - val_reconstruction_loss: 128.7163 - val_kl_loss: 5146.7148\n",
      "Epoch 638/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 5267.3798 - reconstruction_loss: 128.7116 - kl_loss: 5155.3081 - val_loss: 5318.5518 - val_reconstruction_loss: 128.7481 - val_kl_loss: 5189.8037\n",
      "Epoch 639/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4906.3528 - reconstruction_loss: 129.0289 - kl_loss: 3940.7832 - val_loss: 3498.6799 - val_reconstruction_loss: 128.4524 - val_kl_loss: 3370.2273\n",
      "Epoch 640/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 3947.7104 - reconstruction_loss: 128.7953 - kl_loss: 3674.6721 - val_loss: 3609.3655 - val_reconstruction_loss: 128.3127 - val_kl_loss: 3481.0527\n",
      "Epoch 641/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 3476.8717 - reconstruction_loss: 128.6165 - kl_loss: 3335.0991 - val_loss: 3469.2954 - val_reconstruction_loss: 128.4102 - val_kl_loss: 3340.8848\n",
      "Epoch 642/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 3469.9286 - reconstruction_loss: 128.5267 - kl_loss: 3519.4067 - val_loss: 4093.2446 - val_reconstruction_loss: 128.7712 - val_kl_loss: 3964.4731\n",
      "Epoch 643/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 3954.3630 - reconstruction_loss: 128.6518 - kl_loss: 3785.3604 - val_loss: 3486.6233 - val_reconstruction_loss: 128.5163 - val_kl_loss: 3358.1062\n",
      "Epoch 644/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 3352.6069 - reconstruction_loss: 128.5139 - kl_loss: 3259.1428 - val_loss: 3462.9080 - val_reconstruction_loss: 128.3149 - val_kl_loss: 3334.5935\n",
      "Epoch 645/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 3656.0010 - reconstruction_loss: 128.6143 - kl_loss: 3720.8477 - val_loss: 4064.0222 - val_reconstruction_loss: 128.8626 - val_kl_loss: 3935.1602\n",
      "Epoch 646/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 4264.1403 - reconstruction_loss: 128.8591 - kl_loss: 4415.7256 - val_loss: 4841.4067 - val_reconstruction_loss: 128.4578 - val_kl_loss: 4712.9497\n",
      "Epoch 647/1000\n",
      "111/111 [==============================] - 4s 32ms/step - loss: 4824.0589 - reconstruction_loss: 128.9677 - kl_loss: 4690.6187 - val_loss: 4896.9917 - val_reconstruction_loss: 128.8897 - val_kl_loss: 4768.1016\n",
      "Epoch 648/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 5027.3095 - reconstruction_loss: 128.8074 - kl_loss: 4781.5728 - val_loss: 5006.2437 - val_reconstruction_loss: 129.0199 - val_kl_loss: 4877.2241\n",
      "Epoch 649/1000\n",
      "111/111 [==============================] - 3s 26ms/step - loss: 4980.3030 - reconstruction_loss: 128.7931 - kl_loss: 4830.1611 - val_loss: 4941.9092 - val_reconstruction_loss: 128.9955 - val_kl_loss: 4812.9136\n",
      "Epoch 650/1000\n",
      "111/111 [==============================] - 3s 28ms/step - loss: 5156.2279 - reconstruction_loss: 128.8303 - kl_loss: 5203.4595 - val_loss: 5499.9014 - val_reconstruction_loss: 128.6666 - val_kl_loss: 5371.2344\n",
      "Epoch 651/1000\n",
      "111/111 [==============================] - 3s 29ms/step - loss: 5436.1730 - reconstruction_loss: 128.7190 - kl_loss: 5287.7930 - val_loss: 5254.8843 - val_reconstruction_loss: 128.8130 - val_kl_loss: 5126.0713\n",
      "Epoch 652/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 5226.4642 - reconstruction_loss: 128.6876 - kl_loss: 5090.9507 - val_loss: 5245.2778 - val_reconstruction_loss: 128.5156 - val_kl_loss: 5116.7646\n",
      "Epoch 653/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 5188.6708 - reconstruction_loss: 128.5598 - kl_loss: 5116.7832 - val_loss: 5289.6455 - val_reconstruction_loss: 128.5955 - val_kl_loss: 5161.0508\n",
      "Epoch 654/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 5368.3527 - reconstruction_loss: 128.4932 - kl_loss: 5144.1528 - val_loss: 5294.3579 - val_reconstruction_loss: 128.5136 - val_kl_loss: 5165.8428\n",
      "Epoch 655/1000\n",
      "111/111 [==============================] - 2s 23ms/step - loss: 5226.2053 - reconstruction_loss: 128.4948 - kl_loss: 5150.7241 - val_loss: 5306.9849 - val_reconstruction_loss: 128.4022 - val_kl_loss: 5178.5830\n",
      "Epoch 656/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 5211.4567 - reconstruction_loss: 128.5750 - kl_loss: 5158.1870 - val_loss: 5320.8960 - val_reconstruction_loss: 128.6206 - val_kl_loss: 5192.2764\n",
      "Epoch 657/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 5302.3772 - reconstruction_loss: 128.5116 - kl_loss: 5174.9033 - val_loss: 5322.7139 - val_reconstruction_loss: 128.4736 - val_kl_loss: 5194.2397\n",
      "Epoch 658/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 5225.3321 - reconstruction_loss: 128.4968 - kl_loss: 5118.3306 - val_loss: 5254.8271 - val_reconstruction_loss: 128.6559 - val_kl_loss: 5126.1709\n",
      "Epoch 659/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 5252.0093 - reconstruction_loss: 128.4856 - kl_loss: 5089.9590 - val_loss: 5218.7539 - val_reconstruction_loss: 128.4695 - val_kl_loss: 5090.2842\n",
      "Epoch 660/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 5268.7538 - reconstruction_loss: 128.4288 - kl_loss: 5067.7837 - val_loss: 5246.1924 - val_reconstruction_loss: 128.6715 - val_kl_loss: 5117.5200\n",
      "Epoch 661/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 5256.9989 - reconstruction_loss: 128.4272 - kl_loss: 5146.1792 - val_loss: 5319.7280 - val_reconstruction_loss: 128.4528 - val_kl_loss: 5191.2759\n",
      "Epoch 662/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4926.6795 - reconstruction_loss: 128.4892 - kl_loss: 4266.8428 - val_loss: 3924.6423 - val_reconstruction_loss: 128.5225 - val_kl_loss: 3796.1196\n",
      "Epoch 663/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 3916.4476 - reconstruction_loss: 128.2919 - kl_loss: 3778.7820 - val_loss: 4024.6516 - val_reconstruction_loss: 128.3890 - val_kl_loss: 3896.2625\n",
      "Epoch 664/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4106.3830 - reconstruction_loss: 128.2023 - kl_loss: 4003.0713 - val_loss: 4280.6304 - val_reconstruction_loss: 128.4311 - val_kl_loss: 4152.1997\n",
      "Epoch 665/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 4292.8740 - reconstruction_loss: 128.3767 - kl_loss: 4293.2021 - val_loss: 4420.5757 - val_reconstruction_loss: 128.5524 - val_kl_loss: 4292.0229\n",
      "Epoch 666/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4478.6138 - reconstruction_loss: 128.5269 - kl_loss: 4885.1055 - val_loss: 8449.2334 - val_reconstruction_loss: 129.6372 - val_kl_loss: 8319.5947\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 20ms/step - loss: 9085.9481 - reconstruction_loss: 129.4294 - kl_loss: 9441.7129 - val_loss: 9660.2949 - val_reconstruction_loss: 129.4812 - val_kl_loss: 9530.8135\n",
      "Epoch 668/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 8016.3274 - reconstruction_loss: 129.5417 - kl_loss: 5793.5688 - val_loss: 4044.7903 - val_reconstruction_loss: 129.5270 - val_kl_loss: 3915.2634\n",
      "Epoch 669/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 4001.1147 - reconstruction_loss: 129.3596 - kl_loss: 3887.4653 - val_loss: 4087.0701 - val_reconstruction_loss: 128.8333 - val_kl_loss: 3958.2363\n",
      "Epoch 670/1000\n",
      "111/111 [==============================] - 2s 23ms/step - loss: 3971.7896 - reconstruction_loss: 129.2644 - kl_loss: 3782.0349 - val_loss: 3717.8147 - val_reconstruction_loss: 128.9785 - val_kl_loss: 3588.8362\n",
      "Epoch 671/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4371.7198 - reconstruction_loss: 129.2905 - kl_loss: 4356.4683 - val_loss: 4565.1943 - val_reconstruction_loss: 129.1318 - val_kl_loss: 4436.0630\n",
      "Epoch 672/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4553.9902 - reconstruction_loss: 129.0410 - kl_loss: 4476.8569 - val_loss: 4636.2686 - val_reconstruction_loss: 128.5965 - val_kl_loss: 4507.6729\n",
      "Epoch 673/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4706.8247 - reconstruction_loss: 128.9016 - kl_loss: 4510.4756 - val_loss: 4623.8032 - val_reconstruction_loss: 128.8714 - val_kl_loss: 4494.9316\n",
      "Epoch 674/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 4748.1214 - reconstruction_loss: 128.6812 - kl_loss: 4499.3975 - val_loss: 4620.3247 - val_reconstruction_loss: 128.5163 - val_kl_loss: 4491.8081\n",
      "Epoch 675/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 4748.3067 - reconstruction_loss: 128.6528 - kl_loss: 4496.4497 - val_loss: 4615.3745 - val_reconstruction_loss: 128.5376 - val_kl_loss: 4486.8364\n",
      "Epoch 676/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4678.6089 - reconstruction_loss: 128.6878 - kl_loss: 4494.9395 - val_loss: 4617.4331 - val_reconstruction_loss: 128.6986 - val_kl_loss: 4488.7339\n",
      "Epoch 677/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4604.0606 - reconstruction_loss: 128.7288 - kl_loss: 4477.7568 - val_loss: 4605.5498 - val_reconstruction_loss: 128.8096 - val_kl_loss: 4476.7397\n",
      "Epoch 678/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 4599.7864 - reconstruction_loss: 128.5799 - kl_loss: 4492.8374 - val_loss: 4617.2310 - val_reconstruction_loss: 128.5356 - val_kl_loss: 4488.6953\n",
      "Epoch 679/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4593.0776 - reconstruction_loss: 128.5638 - kl_loss: 4430.4883 - val_loss: 4445.7295 - val_reconstruction_loss: 128.4003 - val_kl_loss: 4317.3291\n",
      "Epoch 680/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4453.9937 - reconstruction_loss: 128.6040 - kl_loss: 4315.4282 - val_loss: 4438.1401 - val_reconstruction_loss: 128.6571 - val_kl_loss: 4309.4829\n",
      "Epoch 681/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4407.9255 - reconstruction_loss: 128.6001 - kl_loss: 4310.9019 - val_loss: 4436.7148 - val_reconstruction_loss: 128.7360 - val_kl_loss: 4307.9785\n",
      "Epoch 682/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4433.3541 - reconstruction_loss: 128.6183 - kl_loss: 4279.1006 - val_loss: 4208.4302 - val_reconstruction_loss: 128.6710 - val_kl_loss: 4079.7585\n",
      "Epoch 683/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4184.6127 - reconstruction_loss: 128.6027 - kl_loss: 4068.6013 - val_loss: 4192.3882 - val_reconstruction_loss: 128.5882 - val_kl_loss: 4063.8003\n",
      "Epoch 684/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 4229.1301 - reconstruction_loss: 128.5080 - kl_loss: 4067.8362 - val_loss: 4189.6772 - val_reconstruction_loss: 128.4480 - val_kl_loss: 4061.2302\n",
      "Epoch 685/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 4274.2563 - reconstruction_loss: 128.5074 - kl_loss: 4067.2366 - val_loss: 4192.2856 - val_reconstruction_loss: 128.4297 - val_kl_loss: 4063.8555\n",
      "Epoch 686/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 4265.1366 - reconstruction_loss: 128.4320 - kl_loss: 4066.9507 - val_loss: 4189.8760 - val_reconstruction_loss: 128.6164 - val_kl_loss: 4061.2603\n",
      "Epoch 687/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 4289.7718 - reconstruction_loss: 128.5757 - kl_loss: 4136.2690 - val_loss: 4294.3564 - val_reconstruction_loss: 128.8149 - val_kl_loss: 4165.5410\n",
      "Epoch 688/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4281.6084 - reconstruction_loss: 128.5008 - kl_loss: 4216.4194 - val_loss: 4385.5034 - val_reconstruction_loss: 128.5884 - val_kl_loss: 4256.9150\n",
      "Epoch 689/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 4385.2117 - reconstruction_loss: 128.4743 - kl_loss: 4256.4585 - val_loss: 4377.5220 - val_reconstruction_loss: 128.7000 - val_kl_loss: 4248.8213\n",
      "Epoch 690/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 4290.1003 - reconstruction_loss: 128.5124 - kl_loss: 4258.5601 - val_loss: 4391.0371 - val_reconstruction_loss: 128.5945 - val_kl_loss: 4262.4429\n",
      "Epoch 691/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4306.9881 - reconstruction_loss: 128.5657 - kl_loss: 4167.5464 - val_loss: 4206.7803 - val_reconstruction_loss: 128.8334 - val_kl_loss: 4077.9473\n",
      "Epoch 692/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4243.5068 - reconstruction_loss: 128.4956 - kl_loss: 4079.3508 - val_loss: 4228.4619 - val_reconstruction_loss: 128.7945 - val_kl_loss: 4099.6670\n",
      "Epoch 693/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 4260.5514 - reconstruction_loss: 128.4325 - kl_loss: 4109.6567 - val_loss: 4243.1143 - val_reconstruction_loss: 128.6778 - val_kl_loss: 4114.4365\n",
      "Epoch 694/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 4350.9451 - reconstruction_loss: 128.4666 - kl_loss: 4114.5659 - val_loss: 4246.9731 - val_reconstruction_loss: 128.9570 - val_kl_loss: 4118.0161\n",
      "Epoch 695/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4225.1575 - reconstruction_loss: 128.4195 - kl_loss: 4112.1421 - val_loss: 4241.4653 - val_reconstruction_loss: 128.5251 - val_kl_loss: 4112.9404\n",
      "Epoch 696/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 4272.7107 - reconstruction_loss: 128.5063 - kl_loss: 4108.7212 - val_loss: 4212.8374 - val_reconstruction_loss: 128.5781 - val_kl_loss: 4084.2595\n",
      "Epoch 697/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4191.7965 - reconstruction_loss: 128.4851 - kl_loss: 4093.9080 - val_loss: 4231.1797 - val_reconstruction_loss: 128.7612 - val_kl_loss: 4102.4175\n",
      "Epoch 698/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4198.6798 - reconstruction_loss: 128.4082 - kl_loss: 4084.0906 - val_loss: 4204.2920 - val_reconstruction_loss: 128.4615 - val_kl_loss: 4075.8306\n",
      "Epoch 699/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4206.9158 - reconstruction_loss: 128.3722 - kl_loss: 4066.5574 - val_loss: 4201.8799 - val_reconstruction_loss: 128.6418 - val_kl_loss: 4073.2380\n",
      "Epoch 700/1000\n",
      "111/111 [==============================] - 2s 17ms/step - loss: 4215.0514 - reconstruction_loss: 128.4431 - kl_loss: 4068.5996 - val_loss: 4206.4624 - val_reconstruction_loss: 128.6235 - val_kl_loss: 4077.8384\n",
      "Epoch 701/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 4150.1200 - reconstruction_loss: 128.4304 - kl_loss: 4083.7402 - val_loss: 4240.8477 - val_reconstruction_loss: 128.7005 - val_kl_loss: 4112.1455\n",
      "Epoch 702/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 4189.2427 - reconstruction_loss: 128.4951 - kl_loss: 4110.0352 - val_loss: 4229.6787 - val_reconstruction_loss: 128.6801 - val_kl_loss: 4100.9980\n",
      "Epoch 703/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 4119.6568 - reconstruction_loss: 128.4993 - kl_loss: 4089.1389 - val_loss: 4235.6880 - val_reconstruction_loss: 128.5565 - val_kl_loss: 4107.1318\n",
      "Epoch 704/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 4203.0939 - reconstruction_loss: 128.4156 - kl_loss: 4103.7588 - val_loss: 4243.9741 - val_reconstruction_loss: 128.7536 - val_kl_loss: 4115.2212\n",
      "Epoch 705/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 4155.4033 - reconstruction_loss: 128.4622 - kl_loss: 4115.1118 - val_loss: 4252.6333 - val_reconstruction_loss: 128.7376 - val_kl_loss: 4123.8965\n",
      "Epoch 706/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 4164.5827 - reconstruction_loss: 128.3824 - kl_loss: 4092.7937 - val_loss: 4228.1265 - val_reconstruction_loss: 128.4309 - val_kl_loss: 4099.6953\n",
      "Epoch 707/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 4137.7932 - reconstruction_loss: 128.5239 - kl_loss: 4099.9351 - val_loss: 4265.4165 - val_reconstruction_loss: 128.5226 - val_kl_loss: 4136.8936\n",
      "Epoch 708/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 4217.6789 - reconstruction_loss: 128.4854 - kl_loss: 4125.5747 - val_loss: 4265.5830 - val_reconstruction_loss: 128.5387 - val_kl_loss: 4137.0435\n",
      "Epoch 709/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 4142.7197 - reconstruction_loss: 128.4443 - kl_loss: 4148.4312 - val_loss: 4297.5400 - val_reconstruction_loss: 128.8964 - val_kl_loss: 4168.6431\n",
      "Epoch 710/1000\n",
      "111/111 [==============================] - 3s 29ms/step - loss: 4260.8972 - reconstruction_loss: 128.4841 - kl_loss: 4151.0034 - val_loss: 4298.5859 - val_reconstruction_loss: 128.6563 - val_kl_loss: 4169.9292\n",
      "Epoch 711/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 4352.3648 - reconstruction_loss: 128.5354 - kl_loss: 4194.7358 - val_loss: 4300.6133 - val_reconstruction_loss: 128.5368 - val_kl_loss: 4172.0757\n",
      "Epoch 712/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4374.1964 - reconstruction_loss: 128.5073 - kl_loss: 4150.0376 - val_loss: 4264.7046 - val_reconstruction_loss: 128.5100 - val_kl_loss: 4136.1943\n",
      "Epoch 713/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 4233.5865 - reconstruction_loss: 128.3473 - kl_loss: 4123.1802 - val_loss: 4267.5845 - val_reconstruction_loss: 128.6339 - val_kl_loss: 4138.9507\n",
      "Epoch 714/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 4327.6143 - reconstruction_loss: 128.4897 - kl_loss: 4125.1743 - val_loss: 4241.7881 - val_reconstruction_loss: 128.6333 - val_kl_loss: 4113.1553\n",
      "Epoch 715/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 4295.8218 - reconstruction_loss: 128.4734 - kl_loss: 4101.8599 - val_loss: 4235.9077 - val_reconstruction_loss: 128.4496 - val_kl_loss: 4107.4580\n",
      "Epoch 716/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4222.3649 - reconstruction_loss: 128.4671 - kl_loss: 4105.4150 - val_loss: 4248.3745 - val_reconstruction_loss: 128.7708 - val_kl_loss: 4119.6030\n",
      "Epoch 717/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 4270.9221 - reconstruction_loss: 129.0506 - kl_loss: 4155.6577 - val_loss: 4300.1201 - val_reconstruction_loss: 130.8422 - val_kl_loss: 4169.2773\n",
      "Epoch 718/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 4383.8359 - reconstruction_loss: 130.2893 - kl_loss: 4265.9355 - val_loss: 4461.2847 - val_reconstruction_loss: 130.2774 - val_kl_loss: 4331.0073\n",
      "Epoch 719/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 4147.6003 - reconstruction_loss: 130.1719 - kl_loss: 4298.8535 - val_loss: 5653.7700 - val_reconstruction_loss: 129.7635 - val_kl_loss: 5524.0068\n",
      "Epoch 720/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 6187.9386 - reconstruction_loss: 129.7730 - kl_loss: 7573.7573 - val_loss: 10934.0010 - val_reconstruction_loss: 129.5992 - val_kl_loss: 10804.4004\n",
      "Epoch 721/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 11667.9620 - reconstruction_loss: 129.5581 - kl_loss: 11743.2363 - val_loss: 11497.1729 - val_reconstruction_loss: 129.1456 - val_kl_loss: 11368.0303\n",
      "Epoch 722/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 11486.2759 - reconstruction_loss: 129.5454 - kl_loss: 10472.7012 - val_loss: 3530.1719 - val_reconstruction_loss: 132.7142 - val_kl_loss: 3397.4578\n",
      "Epoch 723/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 2739.8116 - reconstruction_loss: 130.3618 - kl_loss: 2471.1423 - val_loss: 2539.7222 - val_reconstruction_loss: 129.0933 - val_kl_loss: 2410.6289\n",
      "Epoch 724/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 2518.3406 - reconstruction_loss: 129.1669 - kl_loss: 2433.9001 - val_loss: 2552.4788 - val_reconstruction_loss: 128.9875 - val_kl_loss: 2423.4910\n",
      "Epoch 725/1000\n",
      "111/111 [==============================] - 4s 34ms/step - loss: 2568.3251 - reconstruction_loss: 128.9303 - kl_loss: 2439.1545 - val_loss: 2557.5837 - val_reconstruction_loss: 128.5379 - val_kl_loss: 2429.0457\n",
      "Epoch 726/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 2561.0967 - reconstruction_loss: 128.6531 - kl_loss: 2429.8662 - val_loss: 2538.1431 - val_reconstruction_loss: 128.7035 - val_kl_loss: 2409.4397\n",
      "Epoch 727/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 2523.7215 - reconstruction_loss: 128.5603 - kl_loss: 2417.6541 - val_loss: 2531.2927 - val_reconstruction_loss: 128.6322 - val_kl_loss: 2402.6602\n",
      "Epoch 728/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 2502.5439 - reconstruction_loss: 128.7291 - kl_loss: 2439.8350 - val_loss: 2568.6628 - val_reconstruction_loss: 128.2420 - val_kl_loss: 2440.4207\n",
      "Epoch 729/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 2529.9592 - reconstruction_loss: 128.5755 - kl_loss: 2448.3125 - val_loss: 2569.5347 - val_reconstruction_loss: 128.8209 - val_kl_loss: 2440.7134\n",
      "Epoch 730/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 2574.5879 - reconstruction_loss: 128.5920 - kl_loss: 2435.8965 - val_loss: 2552.4712 - val_reconstruction_loss: 128.5808 - val_kl_loss: 2423.8906\n",
      "Epoch 731/1000\n",
      "111/111 [==============================] - 3s 23ms/step - loss: 2543.8032 - reconstruction_loss: 128.4988 - kl_loss: 2437.1216 - val_loss: 2562.6531 - val_reconstruction_loss: 128.2504 - val_kl_loss: 2434.4028\n",
      "Epoch 732/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 2565.1891 - reconstruction_loss: 128.5395 - kl_loss: 2435.8164 - val_loss: 2554.8179 - val_reconstruction_loss: 129.1493 - val_kl_loss: 2425.6685\n",
      "Epoch 733/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 2580.6719 - reconstruction_loss: 128.4793 - kl_loss: 2427.2922 - val_loss: 2551.1021 - val_reconstruction_loss: 128.3783 - val_kl_loss: 2422.7239\n",
      "Epoch 734/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 2562.2729 - reconstruction_loss: 128.4885 - kl_loss: 2420.0620 - val_loss: 2726.7271 - val_reconstruction_loss: 128.7948 - val_kl_loss: 2597.9316\n",
      "Epoch 735/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 2860.0759 - reconstruction_loss: 129.2220 - kl_loss: 2782.2771 - val_loss: 3096.6140 - val_reconstruction_loss: 129.0915 - val_kl_loss: 2967.5217\n",
      "Epoch 736/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 3197.6123 - reconstruction_loss: 129.0292 - kl_loss: 2999.9175 - val_loss: 2524.4768 - val_reconstruction_loss: 128.7964 - val_kl_loss: 2395.6804\n",
      "Epoch 737/1000\n",
      "111/111 [==============================] - 3s 26ms/step - loss: 2436.0959 - reconstruction_loss: 129.0242 - kl_loss: 2316.2825 - val_loss: 2514.3125 - val_reconstruction_loss: 129.0953 - val_kl_loss: 2385.2175\n",
      "Epoch 738/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 2641.1227 - reconstruction_loss: 129.3259 - kl_loss: 2536.2170 - val_loss: 2650.3198 - val_reconstruction_loss: 128.8235 - val_kl_loss: 2521.4961\n",
      "Epoch 739/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 21ms/step - loss: 2615.5668 - reconstruction_loss: 129.1672 - kl_loss: 2497.1633 - val_loss: 2580.3047 - val_reconstruction_loss: 128.7368 - val_kl_loss: 2451.5684\n",
      "Epoch 740/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 2576.9305 - reconstruction_loss: 128.9616 - kl_loss: 2653.8206 - val_loss: 3005.5962 - val_reconstruction_loss: 128.6244 - val_kl_loss: 2876.9719\n",
      "Epoch 741/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 3196.6467 - reconstruction_loss: 129.1459 - kl_loss: 3302.6736 - val_loss: 3732.6785 - val_reconstruction_loss: 129.0987 - val_kl_loss: 3603.5803\n",
      "Epoch 742/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 3686.3666 - reconstruction_loss: 129.3237 - kl_loss: 3394.8496 - val_loss: 2325.2168 - val_reconstruction_loss: 130.8233 - val_kl_loss: 2194.3936\n",
      "Epoch 743/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 2537.7273 - reconstruction_loss: 129.9206 - kl_loss: 2537.3196 - val_loss: 2696.0332 - val_reconstruction_loss: 128.7699 - val_kl_loss: 2567.2634\n",
      "Epoch 744/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 2670.5514 - reconstruction_loss: 129.1262 - kl_loss: 2586.6628 - val_loss: 2730.7561 - val_reconstruction_loss: 128.7250 - val_kl_loss: 2602.0308\n",
      "Epoch 745/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 2812.7711 - reconstruction_loss: 129.0418 - kl_loss: 2745.8955 - val_loss: 2923.5071 - val_reconstruction_loss: 128.5953 - val_kl_loss: 2794.9119\n",
      "Epoch 746/1000\n",
      "111/111 [==============================] - 2s 22ms/step - loss: 2895.1797 - reconstruction_loss: 128.9267 - kl_loss: 2793.6555 - val_loss: 2936.4329 - val_reconstruction_loss: 128.8821 - val_kl_loss: 2807.5503\n",
      "Epoch 747/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 2948.2884 - reconstruction_loss: 128.9108 - kl_loss: 2798.7424 - val_loss: 2926.8999 - val_reconstruction_loss: 128.7830 - val_kl_loss: 2798.1169\n",
      "Epoch 748/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 2886.0362 - reconstruction_loss: 128.7289 - kl_loss: 2691.0276 - val_loss: 2535.7620 - val_reconstruction_loss: 128.2941 - val_kl_loss: 2407.4675\n",
      "Epoch 749/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 2541.1995 - reconstruction_loss: 128.7664 - kl_loss: 2394.9534 - val_loss: 2516.3865 - val_reconstruction_loss: 128.5087 - val_kl_loss: 2387.8774\n",
      "Epoch 750/1000\n",
      "111/111 [==============================] - 2s 16ms/step - loss: 2554.7258 - reconstruction_loss: 128.7267 - kl_loss: 2407.4441 - val_loss: 2529.6887 - val_reconstruction_loss: 128.4079 - val_kl_loss: 2401.2810\n",
      "Epoch 751/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 2530.0413 - reconstruction_loss: 128.6366 - kl_loss: 2405.3892 - val_loss: 2532.1292 - val_reconstruction_loss: 128.5394 - val_kl_loss: 2403.5894\n",
      "Epoch 752/1000\n",
      "111/111 [==============================] - 2s 18ms/step - loss: 2561.3230 - reconstruction_loss: 128.6421 - kl_loss: 2404.9246 - val_loss: 2531.6724 - val_reconstruction_loss: 128.6651 - val_kl_loss: 2403.0076\n",
      "Epoch 753/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 2551.9828 - reconstruction_loss: 128.7247 - kl_loss: 2398.5400 - val_loss: 2500.6409 - val_reconstruction_loss: 128.4169 - val_kl_loss: 2372.2241\n",
      "Epoch 754/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 2506.2200 - reconstruction_loss: 128.6862 - kl_loss: 2375.3323 - val_loss: 2505.9749 - val_reconstruction_loss: 128.5265 - val_kl_loss: 2377.4485\n",
      "Epoch 755/1000\n",
      "111/111 [==============================] - 2s 19ms/step - loss: 2554.4804 - reconstruction_loss: 128.5568 - kl_loss: 2421.0305 - val_loss: 2569.0627 - val_reconstruction_loss: 128.5746 - val_kl_loss: 2440.4885\n",
      "Epoch 756/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 2646.3404 - reconstruction_loss: 128.6742 - kl_loss: 2464.2754 - val_loss: 2594.5669 - val_reconstruction_loss: 128.3814 - val_kl_loss: 2466.1855\n",
      "Epoch 757/1000\n",
      "111/111 [==============================] - 3s 24ms/step - loss: 2584.8250 - reconstruction_loss: 128.6659 - kl_loss: 2481.4893 - val_loss: 2625.4875 - val_reconstruction_loss: 128.6885 - val_kl_loss: 2496.7991\n",
      "Epoch 758/1000\n",
      "111/111 [==============================] - 3s 25ms/step - loss: 2664.6904 - reconstruction_loss: 128.8289 - kl_loss: 2461.9224 - val_loss: 2600.8906 - val_reconstruction_loss: 128.2811 - val_kl_loss: 2472.6091\n",
      "Epoch 759/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 2363.1861 - reconstruction_loss: 128.6758 - kl_loss: 2076.5808 - val_loss: 2105.1182 - val_reconstruction_loss: 128.4089 - val_kl_loss: 1976.7094\n",
      "Epoch 760/1000\n",
      "111/111 [==============================] - 2s 20ms/step - loss: 2157.2818 - reconstruction_loss: 128.6254 - kl_loss: 1966.3184 - val_loss: 2115.4666 - val_reconstruction_loss: 128.5125 - val_kl_loss: 1986.9542\n",
      "Epoch 761/1000\n",
      "111/111 [==============================] - 2s 21ms/step - loss: 2088.7273 - reconstruction_loss: 128.5132 - kl_loss: 1973.7040 - val_loss: 2113.6860 - val_reconstruction_loss: 128.1490 - val_kl_loss: 1985.5369\n",
      "Epoch 762/1000\n",
      "111/111 [==============================] - ETA: 0s - loss: 2072.6709 - reconstruction_loss: 128.4645 - kl_loss: 1973.4271"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-e9e58d88b16e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 callbacks=[mc])\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = rnn_vae.fit(X_train, X_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNNVAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_Encoder (RNNEncoder)    multiple                  1019456   \n",
      "_________________________________________________________________\n",
      "LSTM_Decoder (RNNDecoder)    multiple                  1057306   \n",
      "=================================================================\n",
      "Total params: 2,076,768\n",
      "Trainable params: 2,076,762\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotting import plot_loss_history\n",
    "\n",
    "plot_loss_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 25,  0, 25, 25,  0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25,  0,  0, 25, 25,  0, 25, 25, 25,  0, 25, 25,  0,  0, 25,\n",
       "        25, 25, 25, 25, 25,  0, 25, 25,  0, 25,  0, 25, 25, 25,  0, 25],\n",
       "       [ 0, 25,  0, 25, 25,  0, 25, 25, 25, 25, 25,  0, 25,  0, 25, 25,\n",
       "         0, 25, 25,  0, 25,  0, 25, 25, 25, 25,  0, 25, 25,  0, 25,  0,\n",
       "         0, 25,  0, 25, 25, 25, 25,  0,  0,  0, 25, 25,  0, 25, 25,  0,\n",
       "        25, 25, 25, 25,  0, 25, 25, 25, 25,  0, 25, 25, 25, 25,  0,  0],\n",
       "       [ 0, 25, 25, 25, 25,  0,  0, 25, 25, 25, 25,  0,  0, 25, 25, 25,\n",
       "         0, 25, 25,  0,  0, 25, 25,  0, 25, 25, 25,  0, 25, 25,  0,  0,\n",
       "         0,  0, 25, 25, 25, 25,  0,  0, 25,  0, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25,  0,  0, 25, 25, 25,  0,  0,  0, 25,  0,  0],\n",
       "       [ 0, 25,  0, 25, 25, 25,  0, 25, 25, 25, 25, 25, 25,  0, 25, 25,\n",
       "         0, 25, 25, 25, 25, 25,  0, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25,  0, 25,  0,  0,  0, 25,  0,  0, 25, 25,  0, 25,  0,\n",
       "        25, 25, 25, 25,  0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  0],\n",
       "       [ 0, 25,  0, 25, 25, 25, 25,  0,  0, 25,  0,  0, 25,  0, 25, 25,\n",
       "         0, 25, 25, 25, 25,  0, 25, 25,  0,  0, 25, 25,  0, 25, 25,  0,\n",
       "         0, 25, 25,  0, 25, 25,  0, 25, 25,  0,  0, 25, 25,  0, 25, 25,\n",
       "         0, 25, 25, 25,  0, 25, 25,  0, 25, 25, 25,  0, 25, 25,  0, 25],\n",
       "       [ 0, 25, 25, 25, 25,  0, 25, 25, 25, 25, 25, 25,  0, 25,  0, 25,\n",
       "         0,  0,  0, 25, 25,  0,  0, 25,  0,  0,  0,  0, 25,  0, 25, 25,\n",
       "        25,  0,  0,  0,  0,  0,  0, 25,  0,  0, 25,  0, 25, 25, 25,  0,\n",
       "         0, 25,  0,  0,  0,  0,  0, 25,  0, 25, 25,  0, 25, 25, 25, 25],\n",
       "       [ 0, 25, 25, 25, 25,  0, 25, 25, 25, 25,  0,  0, 25,  0, 25, 25,\n",
       "         0, 25, 25, 25, 25,  0, 25, 25, 25,  0,  0, 25, 25, 25,  0,  0,\n",
       "        25, 25,  0, 25, 25, 25, 25, 25, 25,  0, 25, 25,  0, 25,  0,  0,\n",
       "        25,  0, 25, 25,  0, 25, 25,  0, 25, 25,  0, 25, 25,  0, 25,  0],\n",
       "       [ 0, 25, 25, 25,  0, 25, 25, 25, 25, 25, 25, 25,  0, 25,  0, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  0, 25, 25,  0, 25, 25,\n",
       "        25, 25, 25,  0, 25, 25,  0, 25, 25,  0, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  0, 25, 25,  0, 25, 25],\n",
       "       [ 0, 25, 25, 25,  0,  0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "       [ 0, 25,  0, 25, 25,  0, 25, 25, 25, 25, 25,  0,  0,  0, 25, 25,\n",
       "         0,  0, 25,  0, 25,  0,  0, 25,  0, 25, 25, 25, 25, 25,  0, 25,\n",
       "        25,  0,  0, 25,  0,  0,  0, 25, 25,  0, 25,  0, 25, 25,  0, 25,\n",
       "         0,  0, 25, 25,  0, 25,  0, 25, 25, 25, 25,  0,  0,  0, 25, 25]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_vae.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rnn_vae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-7f6833e8046f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rnn_vae' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(X_train.reshape(-1), rnn_vae(X_train).numpy().argmax(-1).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_models.vae.variationalautoencoders import CNNVAE\n",
    "\n",
    "encoder_filter_sizes = (128, 64, 32)\n",
    "encoder_dilation_rates = 1\n",
    "latent_dim = 32\n",
    "decoder_filter_sizes = encoder_filter_sizes[::-1]\n",
    "decoder_dilation_rates = 1\n",
    "decoder_dense_unit = latent_dim\n",
    "\n",
    "\n",
    "cnn_vae = CNNVAE(encoder_filter_sizes, latent_dim, decoder_filter_sizes, decoder_dense_unit, timesteps, vocab_size, embed_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"{cnn_vae.encoder.name}_{cnn_vae.decoder.name}_{now()}\"\n",
    "learning_rate = 5e-3\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "mc = ModelCheckpoint(f'keras_weights/{name}.h5', monitor='val_loss')\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_vae.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 == 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "111/111 [==============================] - 3s 13ms/step - loss: 149.2375 - reconstruction_loss: 135.1208 - kl_loss: 0.1639 - val_loss: 127.9562 - val_reconstruction_loss: 127.9298 - val_kl_loss: 0.0264\n",
      "Epoch 2/200\n",
      "111/111 [==============================] - 1s 8ms/step - loss: 127.3822 - reconstruction_loss: 126.9662 - kl_loss: 0.1181 - val_loss: 124.0640 - val_reconstruction_loss: 123.8930 - val_kl_loss: 0.1711\n",
      "Epoch 3/200\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 122.8744 - reconstruction_loss: 121.4774 - kl_loss: 0.2994 - val_loss: 119.3597 - val_reconstruction_loss: 119.0047 - val_kl_loss: 0.3550\n",
      "Epoch 4/200\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 118.5082 - reconstruction_loss: 117.4563 - kl_loss: 0.5420 - val_loss: 116.1138 - val_reconstruction_loss: 115.3740 - val_kl_loss: 0.7398\n",
      "Epoch 5/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 115.6613 - reconstruction_loss: 114.1188 - kl_loss: 0.7842 - val_loss: 113.8319 - val_reconstruction_loss: 112.9462 - val_kl_loss: 0.8857\n",
      "Epoch 6/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 113.0959 - reconstruction_loss: 111.7399 - kl_loss: 0.9632 - val_loss: 111.7922 - val_reconstruction_loss: 110.7916 - val_kl_loss: 1.0006\n",
      "Epoch 7/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 110.7273 - reconstruction_loss: 108.9253 - kl_loss: 1.0520 - val_loss: 107.9333 - val_reconstruction_loss: 106.8150 - val_kl_loss: 1.1183\n",
      "Epoch 8/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 108.4664 - reconstruction_loss: 106.3098 - kl_loss: 1.2983 - val_loss: 106.3840 - val_reconstruction_loss: 105.0796 - val_kl_loss: 1.3044\n",
      "Epoch 9/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 105.9070 - reconstruction_loss: 103.9056 - kl_loss: 1.4820 - val_loss: 105.4151 - val_reconstruction_loss: 103.8654 - val_kl_loss: 1.5498\n",
      "Epoch 10/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 104.3026 - reconstruction_loss: 101.6391 - kl_loss: 1.6441 - val_loss: 102.6385 - val_reconstruction_loss: 100.9531 - val_kl_loss: 1.6854\n",
      "Epoch 11/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 101.9592 - reconstruction_loss: 99.5941 - kl_loss: 1.8049 - val_loss: 102.4660 - val_reconstruction_loss: 100.6715 - val_kl_loss: 1.7945\n",
      "Epoch 12/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 100.2191 - reconstruction_loss: 98.0681 - kl_loss: 1.9769 - val_loss: 99.7421 - val_reconstruction_loss: 97.6855 - val_kl_loss: 2.0567\n",
      "Epoch 13/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 97.2882 - reconstruction_loss: 95.1993 - kl_loss: 2.1071 - val_loss: 98.6093 - val_reconstruction_loss: 96.4178 - val_kl_loss: 2.1915\n",
      "Epoch 14/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 96.1631 - reconstruction_loss: 93.8464 - kl_loss: 2.2668 - val_loss: 95.9618 - val_reconstruction_loss: 93.8547 - val_kl_loss: 2.1071\n",
      "Epoch 15/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 94.5483 - reconstruction_loss: 92.1990 - kl_loss: 2.4010 - val_loss: 95.6437 - val_reconstruction_loss: 93.3856 - val_kl_loss: 2.2580\n",
      "Epoch 16/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 93.4581 - reconstruction_loss: 90.5236 - kl_loss: 2.5356 - val_loss: 93.6588 - val_reconstruction_loss: 91.0285 - val_kl_loss: 2.6303\n",
      "Epoch 17/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 91.3235 - reconstruction_loss: 88.9860 - kl_loss: 2.6295 - val_loss: 93.3114 - val_reconstruction_loss: 90.8125 - val_kl_loss: 2.4989\n",
      "Epoch 18/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 91.5262 - reconstruction_loss: 88.2113 - kl_loss: 2.6921 - val_loss: 92.5597 - val_reconstruction_loss: 89.7794 - val_kl_loss: 2.7803\n",
      "Epoch 19/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 89.7540 - reconstruction_loss: 86.9697 - kl_loss: 2.8292 - val_loss: 91.8275 - val_reconstruction_loss: 89.1061 - val_kl_loss: 2.7214\n",
      "Epoch 20/200\n",
      "111/111 [==============================] - 1s 8ms/step - loss: 88.4410 - reconstruction_loss: 85.9430 - kl_loss: 2.8518 - val_loss: 91.0029 - val_reconstruction_loss: 88.0944 - val_kl_loss: 2.9085\n",
      "Epoch 21/200\n",
      "111/111 [==============================] - 1s 9ms/step - loss: 87.8169 - reconstruction_loss: 85.3933 - kl_loss: 2.9396 - val_loss: 91.0976 - val_reconstruction_loss: 88.0831 - val_kl_loss: 3.0145\n",
      "Epoch 22/200\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 87.5209 - reconstruction_loss: 84.5121 - kl_loss: 3.0101 - val_loss: 90.0038 - val_reconstruction_loss: 87.3118 - val_kl_loss: 2.6920\n",
      "Epoch 23/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 86.3990 - reconstruction_loss: 83.9789 - kl_loss: 3.0288 - val_loss: 90.2281 - val_reconstruction_loss: 87.1181 - val_kl_loss: 3.1100\n",
      "Epoch 24/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 85.7118 - reconstruction_loss: 82.9597 - kl_loss: 3.0783 - val_loss: 89.8191 - val_reconstruction_loss: 86.7557 - val_kl_loss: 3.0634\n",
      "Epoch 25/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 86.3992 - reconstruction_loss: 82.9013 - kl_loss: 3.1080 - val_loss: 88.7288 - val_reconstruction_loss: 85.7609 - val_kl_loss: 2.9679\n",
      "Epoch 26/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 84.1049 - reconstruction_loss: 82.1052 - kl_loss: 3.1671 - val_loss: 90.6795 - val_reconstruction_loss: 87.4005 - val_kl_loss: 3.2791\n",
      "Epoch 27/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 84.1918 - reconstruction_loss: 81.3578 - kl_loss: 3.2181 - val_loss: 89.5536 - val_reconstruction_loss: 86.2553 - val_kl_loss: 3.2983\n",
      "Epoch 28/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 83.7241 - reconstruction_loss: 80.7272 - kl_loss: 3.2622 - val_loss: 89.2776 - val_reconstruction_loss: 86.2786 - val_kl_loss: 2.9990\n",
      "Epoch 29/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 84.2124 - reconstruction_loss: 80.8457 - kl_loss: 3.2533 - val_loss: 89.4660 - val_reconstruction_loss: 86.3668 - val_kl_loss: 3.0992\n",
      "Epoch 30/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 82.6032 - reconstruction_loss: 79.9028 - kl_loss: 3.3269 - val_loss: 88.1302 - val_reconstruction_loss: 84.8668 - val_kl_loss: 3.2634\n",
      "Epoch 31/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 82.0865 - reconstruction_loss: 79.4850 - kl_loss: 3.3717 - val_loss: 88.6028 - val_reconstruction_loss: 85.2889 - val_kl_loss: 3.3139\n",
      "Epoch 32/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 81.6598 - reconstruction_loss: 79.0177 - kl_loss: 3.3951 - val_loss: 88.3520 - val_reconstruction_loss: 85.0050 - val_kl_loss: 3.3470\n",
      "Epoch 33/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 82.1542 - reconstruction_loss: 79.2347 - kl_loss: 3.4299 - val_loss: 88.0369 - val_reconstruction_loss: 84.5471 - val_kl_loss: 3.4898\n",
      "Epoch 34/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 80.7730 - reconstruction_loss: 78.2503 - kl_loss: 3.4952 - val_loss: 87.6687 - val_reconstruction_loss: 84.1949 - val_kl_loss: 3.4738\n",
      "Epoch 35/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 81.1831 - reconstruction_loss: 77.7434 - kl_loss: 3.4959 - val_loss: 88.1655 - val_reconstruction_loss: 84.7262 - val_kl_loss: 3.4393\n",
      "Epoch 36/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 80.7066 - reconstruction_loss: 77.5836 - kl_loss: 3.5387 - val_loss: 86.8885 - val_reconstruction_loss: 83.2388 - val_kl_loss: 3.6496\n",
      "Epoch 37/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 80.1069 - reconstruction_loss: 77.1656 - kl_loss: 3.5590 - val_loss: 87.4465 - val_reconstruction_loss: 84.0848 - val_kl_loss: 3.3617\n",
      "Epoch 38/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 79.8939 - reconstruction_loss: 76.7515 - kl_loss: 3.5486 - val_loss: 87.0130 - val_reconstruction_loss: 83.7213 - val_kl_loss: 3.2917\n",
      "Epoch 39/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 79.0182 - reconstruction_loss: 76.6538 - kl_loss: 3.6045 - val_loss: 87.6742 - val_reconstruction_loss: 84.0943 - val_kl_loss: 3.5799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 79.8994 - reconstruction_loss: 76.4796 - kl_loss: 3.6430 - val_loss: 88.2332 - val_reconstruction_loss: 84.8003 - val_kl_loss: 3.4329\n",
      "Epoch 41/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 79.1697 - reconstruction_loss: 76.1277 - kl_loss: 3.6277 - val_loss: 87.2792 - val_reconstruction_loss: 83.4605 - val_kl_loss: 3.8187\n",
      "Epoch 42/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 79.0086 - reconstruction_loss: 75.9857 - kl_loss: 3.6249 - val_loss: 86.9361 - val_reconstruction_loss: 83.3412 - val_kl_loss: 3.5949\n",
      "Epoch 43/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 78.8473 - reconstruction_loss: 75.9335 - kl_loss: 3.7135 - val_loss: 87.0960 - val_reconstruction_loss: 83.2386 - val_kl_loss: 3.8574\n",
      "Epoch 44/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 77.8314 - reconstruction_loss: 75.6541 - kl_loss: 3.7024 - val_loss: 87.5152 - val_reconstruction_loss: 83.7793 - val_kl_loss: 3.7359\n",
      "Epoch 45/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 78.5963 - reconstruction_loss: 75.6863 - kl_loss: 3.6973 - val_loss: 86.6290 - val_reconstruction_loss: 83.1477 - val_kl_loss: 3.4813\n",
      "Epoch 46/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 77.5579 - reconstruction_loss: 74.5293 - kl_loss: 3.7509 - val_loss: 87.4434 - val_reconstruction_loss: 83.9610 - val_kl_loss: 3.4823\n",
      "Epoch 47/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 77.9125 - reconstruction_loss: 74.7893 - kl_loss: 3.7549 - val_loss: 88.2586 - val_reconstruction_loss: 84.5628 - val_kl_loss: 3.6958\n",
      "Epoch 48/200\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 78.2320 - reconstruction_loss: 74.6865 - kl_loss: 3.7753 - val_loss: 88.1365 - val_reconstruction_loss: 84.3156 - val_kl_loss: 3.8209\n",
      "Epoch 49/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 79.0069 - reconstruction_loss: 74.4012 - kl_loss: 3.8112 - val_loss: 87.8153 - val_reconstruction_loss: 84.1274 - val_kl_loss: 3.6879\n",
      "Epoch 50/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 76.8476 - reconstruction_loss: 73.6040 - kl_loss: 3.8127 - val_loss: 87.2283 - val_reconstruction_loss: 83.6231 - val_kl_loss: 3.6053\n",
      "Epoch 51/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 77.4482 - reconstruction_loss: 73.7818 - kl_loss: 3.8454 - val_loss: 87.7315 - val_reconstruction_loss: 83.9756 - val_kl_loss: 3.7559\n",
      "Epoch 52/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 76.1322 - reconstruction_loss: 73.5245 - kl_loss: 3.8499 - val_loss: 87.3399 - val_reconstruction_loss: 83.5498 - val_kl_loss: 3.7901\n",
      "Epoch 53/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 76.6531 - reconstruction_loss: 74.0300 - kl_loss: 3.9196 - val_loss: 87.1564 - val_reconstruction_loss: 83.3676 - val_kl_loss: 3.7888\n",
      "Epoch 54/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 77.1322 - reconstruction_loss: 73.1303 - kl_loss: 3.9061 - val_loss: 86.7179 - val_reconstruction_loss: 83.0158 - val_kl_loss: 3.7021\n",
      "Epoch 55/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 75.7494 - reconstruction_loss: 73.1057 - kl_loss: 3.9334 - val_loss: 86.6592 - val_reconstruction_loss: 82.9216 - val_kl_loss: 3.7376\n"
     ]
    }
   ],
   "source": [
    "hist = cnn_vae.fit(X_train, X_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[mc, es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNNVAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_Encoder (CNNEncoder)    multiple                  53952     \n",
      "_________________________________________________________________\n",
      "CNN_Decoder (CNNDecoder)     multiple                  54266     \n",
      "=================================================================\n",
      "Total params: 108,224\n",
      "Trainable params: 108,218\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('FirstOut.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 100, 100, 100, 100,   0, 100,  19, 100,   0,  24, 100,  19,\n",
       "        100,   0,  19, 100,   0,  19, 100,   0,   0, 100,  19, 100, 100,\n",
       "         19, 100,   0,   0,   0,  19,   0,   0,  19, 100,   0, 100, 100,\n",
       "         19, 100,   0,  19, 100,  19,   0, 100,  19, 100,   0,  19, 100,\n",
       "         24,   0, 100,  19, 100,  24,  19, 100,   0, 100,   0,  19],\n",
       "       [  0,   0, 100,  24, 100,  19,   0,  24,  24,  19,   0,   0,  19,\n",
       "        100,  24,  24,  19,  24,   0,  24,   0,   0,   0,  19,   0,  19,\n",
       "        100, 100,   0,   0,   0,  24,   0,  19, 100,  19,   0,  19,   0,\n",
       "         19,   0,  24,   0, 100,   0, 100, 100,  19,  24,  19,   0, 100,\n",
       "         24,  19,   0,  19,   0,  24,   0,   0,   0, 100, 100,  24],\n",
       "       [  0,  24,   0,   0,   0, 100, 100,  24, 100,   0,  24, 100,  19,\n",
       "          0, 100,  19, 100, 100,  24, 100,  24,   0,   0,  19, 100,  24,\n",
       "         24, 100,   0,   0, 100,   0, 100, 100,  19, 100, 100, 100, 100,\n",
       "         19,   0,   0,   0,   0,  19,   0, 100,  24, 100,   0,  19, 100,\n",
       "         19, 100,   0,  19,   0,   0,  19, 100,   0,   0, 100,  24],\n",
       "       [  0, 100, 100, 100, 100, 100,   0, 100, 100, 100, 100, 100,  19,\n",
       "          0,  24,  24, 100,   0, 100, 100, 100, 100, 100, 100, 100,   0,\n",
       "          0, 100,  24,   0,   0, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "        100,   0,  19, 100,  19,   0,   0,   0, 100, 100, 100, 100, 100,\n",
       "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,   0],\n",
       "       [  0, 100, 100, 100, 100, 100, 100, 100, 100, 100,   0, 100, 100,\n",
       "        100, 100, 100,   0, 100, 100, 100, 100, 100, 100,   0,  24,  24,\n",
       "        100,   0, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "        100,   0,   0,   0,   0,   0, 100,   0,   0, 100,  24,   0, 100,\n",
       "          0,  19,   0,   0,  24,   0,  19,   0, 100, 100, 100,  19],\n",
       "       [  0,  19, 100,  24,   0, 100, 100,   0,   0,   0,  24,   0,   0,\n",
       "        100, 100, 100, 100,   0,   0,   0,   0,  24, 100,   0,   0,   0,\n",
       "          0,   0,  24,  24, 100, 100, 100,   0, 100,  24,  24, 100,  19,\n",
       "          0,   0,   0,  24, 100,  19,   0,   0, 100, 100,   0,   0, 100,\n",
       "         24, 100, 100,  24, 100,  24,   0,   0,  24,   0, 100, 100],\n",
       "       [  0,   0,   0, 100, 100, 100,   0, 100,   0,   0, 100, 100,   0,\n",
       "          0, 100,   0, 100,   0,   0, 100,   0, 100,   0, 100,   0, 100,\n",
       "        100,  19, 100,  24, 100,  24, 100, 100,   0, 100,   0,   0, 100,\n",
       "         24, 100,   0, 100,   0,   0,   0,  19,  19,  24, 100,   0, 100,\n",
       "        100,   0, 100, 100,  24,  24, 100,  24, 100,   0,  19, 100],\n",
       "       [  0,   0, 100,  19, 100,   0,  24, 100,  19,  24,   0,  24,   0,\n",
       "          0,   0,  19, 100, 100, 100,  19,   0,   0,  19, 100,  24,  24,\n",
       "          0,  24,  24, 100,   0,  19, 100,   0, 100,  19, 100,   0,   0,\n",
       "        100,  24,   0,  24,   0,  24,   0,   0,  24, 100,   0, 100,  19,\n",
       "        100, 100,  19,   0,  19,  24,  19,  24,  19,   0, 100,  19],\n",
       "       [  0, 100,  19, 100,   0,   0,  19,   0, 100,  19,   0,  19,   0,\n",
       "          0, 100,  19, 100, 100, 100, 100, 100, 100, 100,   0,   0,   0,\n",
       "        100,   0,   0, 100, 100,  24,   0, 100,  19, 100, 100,  19,  19,\n",
       "         24,   0,  24, 100,  19,   0,   0,  24,  19, 100, 100,  24, 100,\n",
       "          0,  19, 100, 100,  19,   0,   0,  24, 100,   0, 100,  19],\n",
       "       [  0, 100, 100,   0, 100, 100,   0, 100,   0,   0, 100,   0,   0,\n",
       "        100,   0, 100, 100,   0, 100,  24,  24,   0,   0, 100,   0,   0,\n",
       "        100,  19,   0, 100,  19, 100, 100,   0, 100,  19,   0,   0,   0,\n",
       "        100,   0,   0, 100,   0,   0, 100, 100,  19,   0,  24, 100,  24,\n",
       "          0, 100,  19,   0,   0,   0, 100,   0,   0, 100,   0,   0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_vae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1fcea78bff4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn_vae' is not defined"
     ]
    }
   ],
   "source": [
    "samples = cnn_vae.sample(10)\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_nn_output_to_midi(samples, name, **{'BPM':125, 'N_qb': 8, 'frame_factor': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_models.vae.variationalautoencoders import CNNEncoderDenseDecoder\n",
    "\n",
    "encoder_filter_sizes = (128, 64, 32, 16)\n",
    "encoder_dilation_rates = 1\n",
    "latent_dim = 32\n",
    "decoder_intermediate_dims = encoder_filter_sizes[::-1]\n",
    "\n",
    "cnn_dense_vae = CNNEncoderDenseDecoder(encoder_filter_sizes, latent_dim, decoder_intermediate_dims, timesteps, vocab_size, embed_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"{cnn_dense_vae.encoder.name}_{cnn_dense_vae.decoder.name}_{now()}\"\n",
    "learning_rate = 5e-3\n",
    "epochs = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(f'keras_weights/{name}.h5', monitor='val_loss')\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_dense_vae.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "111/111 [==============================] - 1s 10ms/step - loss: 77.5294 - reconstruction_loss: 75.3512 - kl_loss: 3.2941 - val_loss: 86.8447 - val_reconstruction_loss: 83.5869 - val_kl_loss: 3.2578\n",
      "Epoch 2/50\n",
      "111/111 [==============================] - 1s 8ms/step - loss: 77.2322 - reconstruction_loss: 75.0413 - kl_loss: 3.3191 - val_loss: 86.8128 - val_reconstruction_loss: 83.5393 - val_kl_loss: 3.2735\n",
      "Epoch 3/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 78.3786 - reconstruction_loss: 75.0661 - kl_loss: 3.3408 - val_loss: 86.3398 - val_reconstruction_loss: 83.0130 - val_kl_loss: 3.3268\n",
      "Epoch 4/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 77.4726 - reconstruction_loss: 74.4860 - kl_loss: 3.3794 - val_loss: 86.4708 - val_reconstruction_loss: 83.1370 - val_kl_loss: 3.3338\n",
      "Epoch 5/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 76.9498 - reconstruction_loss: 74.3294 - kl_loss: 3.4104 - val_loss: 87.7626 - val_reconstruction_loss: 84.2431 - val_kl_loss: 3.5195\n",
      "Epoch 6/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 76.5603 - reconstruction_loss: 74.3224 - kl_loss: 3.3861 - val_loss: 87.3228 - val_reconstruction_loss: 83.9085 - val_kl_loss: 3.4143\n",
      "Epoch 7/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 76.4757 - reconstruction_loss: 73.8012 - kl_loss: 3.4281 - val_loss: 85.5340 - val_reconstruction_loss: 82.2296 - val_kl_loss: 3.3044\n",
      "Epoch 8/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 75.5592 - reconstruction_loss: 73.3908 - kl_loss: 3.4292 - val_loss: 86.3857 - val_reconstruction_loss: 83.0733 - val_kl_loss: 3.3125\n",
      "Epoch 9/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 75.7620 - reconstruction_loss: 73.3760 - kl_loss: 3.4721 - val_loss: 87.3105 - val_reconstruction_loss: 83.8001 - val_kl_loss: 3.5103\n",
      "Epoch 10/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 76.1064 - reconstruction_loss: 73.3779 - kl_loss: 3.4858 - val_loss: 86.3151 - val_reconstruction_loss: 82.8458 - val_kl_loss: 3.4693\n",
      "Epoch 11/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 75.8849 - reconstruction_loss: 73.2425 - kl_loss: 3.5166 - val_loss: 86.4733 - val_reconstruction_loss: 83.0368 - val_kl_loss: 3.4366\n",
      "Epoch 12/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 75.9192 - reconstruction_loss: 72.8040 - kl_loss: 3.5229 - val_loss: 88.0939 - val_reconstruction_loss: 84.4966 - val_kl_loss: 3.5973\n",
      "Epoch 13/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 75.3649 - reconstruction_loss: 72.8091 - kl_loss: 3.5260 - val_loss: 87.1922 - val_reconstruction_loss: 83.5703 - val_kl_loss: 3.6219\n",
      "Epoch 14/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 75.1999 - reconstruction_loss: 72.3191 - kl_loss: 3.5479 - val_loss: 86.3488 - val_reconstruction_loss: 82.7285 - val_kl_loss: 3.6203\n",
      "Epoch 15/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 75.4632 - reconstruction_loss: 72.1980 - kl_loss: 3.5485 - val_loss: 86.9354 - val_reconstruction_loss: 83.4156 - val_kl_loss: 3.5198\n",
      "Epoch 16/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 75.0746 - reconstruction_loss: 72.1562 - kl_loss: 3.5448 - val_loss: 87.7274 - val_reconstruction_loss: 84.2157 - val_kl_loss: 3.5116\n",
      "Epoch 17/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 75.2781 - reconstruction_loss: 72.1552 - kl_loss: 3.5941 - val_loss: 85.6368 - val_reconstruction_loss: 82.2098 - val_kl_loss: 3.4270\n"
     ]
    }
   ],
   "source": [
    "hist = cnn_dense_vae.fit(X_train, X_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[mc, es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  4],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 14, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 14,  0, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 12],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  0, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  0, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  4],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  0, 14,  0, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 11],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
       "       [ 0, 12, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 12],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  6],\n",
       "       [ 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = cnn_dense_vae.sample(10)\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_models.wavenet import WaveNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sizes = (16, 17, 18, 19, 20, 21)\n",
    "\n",
    "wnet = WaveNET(filter_sizes, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"{wnet.name}_{now()}\"\n",
    "learning_rate = 5e-3\n",
    "epochs = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(f'keras_weights/{name}.h5', monitor='val_loss')\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnet.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "111/111 [==============================] - 1s 12ms/step - loss: 0.4542 - val_loss: 0.1369\n",
      "Epoch 2/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0712 - val_loss: 0.0461\n",
      "Epoch 3/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0415 - val_loss: 0.0390\n",
      "Epoch 4/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0393 - val_loss: 0.0395\n",
      "Epoch 5/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0387 - val_loss: 0.0375\n",
      "Epoch 6/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0387 - val_loss: 0.0386\n",
      "Epoch 7/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0383 - val_loss: 0.0375\n",
      "Epoch 8/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0379 - val_loss: 0.0380\n",
      "Epoch 9/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0378 - val_loss: 0.0366\n",
      "Epoch 10/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0377 - val_loss: 0.0369\n",
      "Epoch 11/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0375 - val_loss: 0.0378\n",
      "Epoch 12/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0375 - val_loss: 0.0366\n",
      "Epoch 13/50\n",
      "111/111 [==============================] - 1s 8ms/step - loss: 0.0373 - val_loss: 0.0369\n",
      "Epoch 14/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0373 - val_loss: 0.0370\n",
      "Epoch 15/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0375 - val_loss: 0.0371\n",
      "Epoch 16/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0372 - val_loss: 0.0373\n",
      "Epoch 17/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0373 - val_loss: 0.0367\n",
      "Epoch 18/50\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 0.0373 - val_loss: 0.0369\n",
      "Epoch 19/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0373 - val_loss: 0.0369\n",
      "Epoch 20/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.0371 - val_loss: 0.0368\n",
      "Epoch 21/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.8990 - val_loss: 0.4881\n",
      "Epoch 22/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 0.2235 - val_loss: 0.0806\n"
     ]
    }
   ],
   "source": [
    "hist = wnet.fit(x=np.concatenate((X_train[:,-1:], X_train[:,:-1]), axis=1), y=X_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(np.concatenate((X_test[:,-1:], X_test[:,:-1]), axis=1), X_test),\n",
    "                callbacks=[mc, es]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = wnet(np.concatenate((X_train[:,-1:], X_train[:,:-1]), axis=1)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3536, 64, 26)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9903006575226244"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from preprocessing import one_hot_encode\n",
    "\n",
    "accuracy_score(X_train.reshape(-1), out.argmax(-1).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3536, 64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
