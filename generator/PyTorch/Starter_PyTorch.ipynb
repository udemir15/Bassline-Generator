{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "#from decoders import (StackedUnidirectionalLSTMDecoder, StackedUnidirLSTMDenseDecoder, \n",
    "#                      StackedUnidirectionalLSTMDecoderwithEmbedding)\n",
    "#from encoders import StackedUnidirectionalLSTMEncoder, StackedBidirectionalLSTMEncoder\n",
    "#from models import AutoEncoder\n",
    "from dataloaders import load_data, create_loaders\n",
    "from training import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import encoders\n",
    "import decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_path = '/projects/bassline_transcription/data/datasets'\n",
    "M = 8 \n",
    "\n",
    "data_params = {'dataset_path': dataset_path,\n",
    "               'scale_type': 'min',\n",
    "               'M': M,\n",
    "               'batch_size': 8}\n",
    "\n",
    "X = load_data(data_params)\n",
    "\n",
    "K = X.max()+1 # ???????\n",
    "sequence_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder_params = {'num_embeddings': K,\n",
    "                  'embedding_dim': 16, #??\n",
    "                  'hidden_size': 128,\n",
    "                  'dropout': 0,  \n",
    "                  'num_layers': 4,              \n",
    "                  'batch_size': data_params['batch_size'],\n",
    "                  'device':device}\n",
    "\n",
    "decoder_params = {'input_size': encoder_params['hidden_size'],\n",
    "                  'output_size': K,\n",
    "                 'num_layers': encoder_params['num_layers'], \n",
    "                 'dropout': 0,\n",
    "                 'batch_size': data_params['batch_size'],\n",
    "                 'sequence_length': sequence_length,\n",
    "                 'device':device}\n",
    "\n",
    "train_params = {'batch_size': data_params['batch_size'],\n",
    "                'N_epochs': 10}\n",
    "\n",
    "all_params = {'encoder_params': encoder_params, 'decoder_params':decoder_params, 'train_params':train_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_params = {'num_embeddings': K,\n",
    "                  'embedding_dim': 16, \n",
    "                  'hidden_size': 128,\n",
    "                  'dropout': 0.2,  \n",
    "                  'num_layers': 2,              \n",
    "                  'batch_size': data_params['batch_size'],\n",
    "                  'device':device}\n",
    "\n",
    "decoder_params = {'num_embeddings': K,\n",
    "                  'embedding_dim': 16,\n",
    "                  'hidden_size': 64,                  \n",
    "                  'num_layers': encoder_params['num_layers'], \n",
    "                  'dropout': 0.2,\n",
    "                  'batch_size': data_params['batch_size'],\n",
    "                  'sequence_length': sequence_length,\n",
    "                  'device':device}\n",
    "\n",
    "train_params = {'batch_size': data_params['batch_size'],\n",
    "                'N_epochs': 10}\n",
    "\n",
    "all_params = {'encoder_params': encoder_params, 'decoder_params':decoder_params, 'train_params':train_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_path = os.path.join('models', model_name+'.pt')\n",
    "\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'test_loss': test_loss\n",
    "            }, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = StackedUnidirectionalLSTMEncoder(**encoder_params)\n",
    "encoder = encoders.StackedBidirectionalLSTMEncoder(**encoder_params).to(device)\n",
    "\n",
    "#StackedUnidirectionalLSTMDecoder(**decoder_params)\n",
    "#decoder = StackedUnidirLSTMDenseDecoder(**decoder_params)\n",
    "decoder = decoders.StackedUnidirectionalLSTMDecoderwithEmbedding(**decoder_params).to(device)\n",
    "\n",
    "#model = models.AutoEncoder(encoder, decoder).to(device)\n",
    "model = models.AE(encoder, decoder, device).to(device)\n",
    "\n",
    "print(model)\n",
    "print('Number of parameters: {}'.format(sum([parameter.numel() for parameter in model.parameters()])))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_loader, test_loader = create_loaders(X, data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_losses, test_losses = main(model, train_loader, test_loader, optimizer, criterion, train_params, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from training import train, test\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "#wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = test(model, test_loader, criterion, device)\n",
    "\n",
    "for epoch in tqdm(range(train_params['N_epochs'])):\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    if epoch+1 % 5:\n",
    "        print('Epoch: {}, train_loss:{:.6f}'.format(epoch+1, train_loss))\n",
    "\n",
    "test_loss = test(model, test_loader, criterion, device)\n",
    "print('Test Loss After Training: {:.6f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='NeuralBasslineGenerator'\n",
    "\n",
    "model_name = dt.datetime.strftime(dt.datetime.now(),\"%H_%M__%d_%m_%Y\")\n",
    "\n",
    "with wandb.init(project=project_name, name=model_name, config=all_params):\n",
    "\n",
    "    test_loss = test(model, test_loader, criterion, device)\n",
    "    wandb.log({'test_loss': test_loss})\n",
    "\n",
    "    for epoch in tqdm(range(train_params['N_epochs'])):\n",
    "\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "        wandb.log({'train_loss': train_loss})\n",
    "\n",
    "        if epoch+1 % 5:\n",
    "            print('Epoch: {}, train_loss:{:.6f}'.format(epoch+1, train_loss))\n",
    "\n",
    "    test_loss = test(model, test_loader, criterion, device)\n",
    "    print('Test Loss After Training: {:.6f}'.format(test_loss))\n",
    "    wandb.log({'test_loss': test_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
