{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.backend import argmax, cast\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Input, Embedding, RepeatVector, Reshape, Conv1D, MaxPooling1D, UpSampling1D, Bidirectional, Lambda, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_df = pd.read_csv(\"Datasets/bassline_representations_min.csv\", header=None)\n",
    "major_df = pd.read_csv(\"Datasets/bassline_representations_maj.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((208, 64), (69, 64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minor_df.shape, major_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((minor_df, major_df))\n",
    "minor_data = minor_df.values\n",
    "major_data = major_df.values\n",
    "\n",
    "timesteps = major_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = np.unique(all_data)\n",
    "vocab = np.arange(len(notes))\n",
    "\n",
    "n2v_mapping = dict(zip(notes, vocab))\n",
    "v2n_mapping = dict(zip(vocab, notes))\n",
    "\n",
    "vocab_size = len(n2v_mapping)\n",
    "\n",
    "def replace_with_dict(ar, dic):\n",
    "    # Extract out keys and values\n",
    "    k = np.array(list(dic.keys()))\n",
    "    v = np.array(list(dic.values()))\n",
    "\n",
    "    # Get argsort indices\n",
    "    sidx = k.argsort()\n",
    "\n",
    "    # Drop the magic bomb with searchsorted to get the corresponding\n",
    "    # places for a in keys (using sorter since a is not necessarily sorted).\n",
    "    # Then trace it back to original order with indexing into sidx\n",
    "    # Finally index into values for desired output.\n",
    "    return v[sidx[np.searchsorted(k,ar,sorter=sidx)]]\n",
    "\n",
    "minor_data = replace_with_dict(minor_data, n2v_mapping).astype(int)\n",
    "major_data = replace_with_dict(major_data, n2v_mapping).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_bassline_train, real_bassline_test, _, _ = train_test_split(minor_data, minor_data, test_size=0.1, random_state=42)\n",
    "real_bassline_train, real_bassline_val, _, _ = train_test_split(real_bassline_train, real_bassline_train, test_size=1/9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_real_train = real_bassline_train.shape[0]\n",
    "num_real_val = real_bassline_val.shape[0]\n",
    "num_real_test = real_bassline_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_bassline_train = np.random.randint(np.min(vocab), np.max(vocab) + 1, size=(num_real_train, timesteps))\n",
    "random_bassline_val = np.random.randint(np.min(vocab), np.max(vocab) + 1, size=(num_real_val, timesteps))\n",
    "random_bassline_test = np.random.randint(np.min(vocab), np.max(vocab) + 1, size=(num_real_test, timesteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_random_train = random_bassline_train.shape[0]\n",
    "num_random_val = random_bassline_val.shape[0]\n",
    "num_random_test = random_bassline_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.row_stack((random_bassline_train, real_bassline_train))\n",
    "X_val = np.row_stack((random_bassline_val, real_bassline_val))\n",
    "X_test = np.row_stack((random_bassline_test, real_bassline_test))\n",
    "\n",
    "y_train = np.concatenate((np.zeros(num_random_train), np.ones(num_real_train))).astype(np.int8)\n",
    "y_val = np.concatenate((np.zeros(num_random_val), np.ones(num_real_val))).astype(np.int8)\n",
    "y_test = np.concatenate((np.zeros(num_random_test), np.ones(num_real_test))).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = pd.read_csv('../generator/FirstOut.csv').values\n",
    "\n",
    "generated = replace_with_dict(generated, n2v_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: hidden_dims x Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NBD_dense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 64  # Length of your sequences\n",
    "embed_size = 32\n",
    "hidden_dims = (64, 1)\n",
    "dropout = 0\n",
    "\n",
    "inputs = Input(shape=(timesteps,))\n",
    "embedded = Embedding(vocab_size, embed_size)(inputs)\n",
    "flattened = Flatten()(embedded)\n",
    "x = Dense(hidden_dims[0], activation='relu')(flattened)\n",
    "if len(hidden_dims) > 2:\n",
    "    for hidden_dim in hidden_dims[1:-1]:\n",
    "        x = Dense(hidden_dim, activation='relu')(x)\n",
    "res = Dense(hidden_dims[-1], activation='sigmoid')(x)\n",
    "\n",
    "discriminator = Model(inputs, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "\n",
    "mc = ModelCheckpoint(f'Models/{name}.hdf5', monitor='val_loss')\n",
    "\n",
    "optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "discriminator.compile(optimizer, loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = discriminator.fit(X_train, y_train,\n",
    "                epochs=10,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "plt.plot(hist.history['loss'], label='training')\n",
    "plt.plot(hist.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'figures/{name}', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = load_model(f'Models/{name}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = discriminator.predict(X_train, batch_size=32) >= 0.5\n",
    "accuracy_score(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds = discriminator.predict(X_val, batch_size=32) >= 0.5\n",
    "accuracy_score(y_val, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = discriminator.predict(X_test, batch_size=32) >= 0.5\n",
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_preds = discriminator.predict(generated, batch_size=32) >= 0.5\n",
    "generated_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: hidden_dims x LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NBD_lstm_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 64  # Length of your sequences\n",
    "embed_size = 32\n",
    "hidden_dims = (16, 8, 1)\n",
    "dropout = 0\n",
    "\n",
    "inputs = Input(shape=(timesteps,))\n",
    "embedded = Embedding(vocab_size, embed_size)(inputs)\n",
    "x = LSTM(hidden_dims[0], return_sequences=True, dropout=dropout)(embedded)\n",
    "for hidden_dim in hidden_dims[1:-1]:\n",
    "    x = LSTM(hidden_dim, return_sequences=True, dropout=dropout)(x)\n",
    "#flattened = Flatten()(x)\n",
    "res = LSTM(hidden_dims[-1], activation='sigmoid')(x)\n",
    "\n",
    "discriminator = Model(inputs, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "\n",
    "mc = ModelCheckpoint(f'Models/{name}.hdf5', monitor='val_loss')\n",
    "\n",
    "optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "discriminator.compile(optimizer, loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = discriminator.fit(X_train, y_train,\n",
    "                epochs=50,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "plt.plot(hist.history['loss'], label='training')\n",
    "plt.plot(hist.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'figures/{name}', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "discriminator = load_model(f'Models/{name}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = discriminator.predict(X_train, batch_size=32) >= 0.5\n",
    "accuracy_score(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds = discriminator.predict(X_val, batch_size=32) >= 0.5\n",
    "accuracy_score(y_val, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = discriminator.predict(X_test, batch_size=32) >= 0.5\n",
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_preds = discriminator.predict(generated, batch_size=32) >= 0.5\n",
    "generated_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: (hidden_dims - 1) x LSTM + Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NBD_lstm_dense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 64  # Length of your sequences\n",
    "embed_size = 32\n",
    "hidden_dims = (16, 8, 1)\n",
    "dropout = 0\n",
    "\n",
    "inputs = Input(shape=(timesteps,))\n",
    "embedded = Embedding(vocab_size, embed_size)(inputs)\n",
    "x = LSTM(hidden_dims[0], return_sequences=True, dropout=dropout)(embedded)\n",
    "for hidden_dim in hidden_dims[1:-1]:\n",
    "    x = LSTM(hidden_dim, return_sequences=True, dropout=dropout)(x)\n",
    "flattened = Flatten()(x)\n",
    "res = Dense(hidden_dims[-1], activation='sigmoid')(flattened)\n",
    "\n",
    "discriminator = Model(inputs, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "\n",
    "mc = ModelCheckpoint(f'Models/{name}.hdf5', monitor='val_loss')\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "discriminator.compile(optimizer, loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = discriminator.fit(X_train, y_train,\n",
    "                epochs=50,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "plt.plot(hist.history['loss'], label='training')\n",
    "plt.plot(hist.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'figures/{name}', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = load_model(f'Models/{name}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = discriminator.predict(X_train, batch_size=32) >= 0.5\n",
    "accuracy_score(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds = discriminator.predict(X_val, batch_size=32) >= 0.5\n",
    "accuracy_score(y_val, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = discriminator.predict(X_test, batch_size=32) >= 0.5\n",
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_preds = discriminator.predict(generated, batch_size=32) >= 0.5\n",
    "generated_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: (filter_sizes - 1) x CONV + Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NBD_conv_dense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 64  # Length of your sequences\n",
    "embed_size = 32\n",
    "filter_sizes = (16, 8, 1)\n",
    "kernel_sizes = (3, 3)\n",
    "dropout = 0\n",
    "\n",
    "inputs = Input(shape=(timesteps,))\n",
    "embedded = Embedding(vocab_size, embed_size)(inputs)\n",
    "x = Conv1D(filter_sizes[0], kernel_sizes[0], padding='same')(embedded)\n",
    "for filter_size, kernel_size in zip(filter_sizes[1:-1], kernel_sizes[1:]):\n",
    "    x = Conv1D(filter_size, kernel_size, padding='same')(x)\n",
    "flattened = Flatten()(x)\n",
    "res = Dense(filter_sizes[-1], activation='sigmoid')(flattened)\n",
    "\n",
    "discriminator = Model(inputs, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "\n",
    "mc = ModelCheckpoint(f'Models/{name}.hdf5', monitor='val_loss')\n",
    "\n",
    "optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "discriminator.compile(optimizer, loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = discriminator.fit(X_train, y_train,\n",
    "                epochs=50,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "plt.plot(hist.history['loss'], label='training')\n",
    "plt.plot(hist.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'figures/{name}', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = load_model(f'Models/{name}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = discriminator.predict(X_train, batch_size=32) >= 0.5\n",
    "accuracy_score(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds = discriminator.predict(X_val, batch_size=32) >= 0.5\n",
    "accuracy_score(y_val, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = discriminator.predict(X_test, batch_size=32) >= 0.5\n",
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_preds = discriminator.predict(generated, batch_size=32) >= 0.5\n",
    "generated_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
